
# Redis
## 一. 缓存
### 1. 缓存穿透
#### 原因
查询一个缓存和数据库都没有的数据时，会穿过缓存直接查询数据库，且不会写回到缓存中
#### 解决
（1） 允许缓存存储null值，若不存在数据的key过多会导致缓存内存占用较大
（2）添加布隆过滤器，判断一个元素是否存在于集合中，实现原理是，布隆过滤器是一个bitmap，存储二进制的数组，加载数据到缓存中时，对key进行多次hash函数运算将得到的索引对应的元素置为1，当进行查询缓存时，会对key进行相同的hash运算判断结果索引处的值是否都是1，如果不是则直接返回缓存中没有这个key的数据，但是查询的key进行hash运算的结果会和其他key的运算结果有重复，导致不存在数据的key误判为有数据，产生误差
```java
        Config config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");
        RedissonClient redisson = Redisson.create(config);
        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("userBloom");
        //初始化布隆过滤器
        // 参数: 预期插入数量(1000000), 误判率(0.01 = 1%)
        bloomFilter.tryInit(1_000_000L, 0.01);
        // 添加数据
        bloomFilter.add("user:1001");
        bloomFilter.add("user:1002");
        // 判断是否存在
        System.out.println("user:1001 exists? " + bloomFilter.contains("user:1001"));
        System.out.println("user:2000 exists? " + bloomFilter.contains("user:2000"));
        //  关闭客户端
        redisson.shutdown();
```
在具体使用时，初始化就把所有合法的key加入过滤器，查询的时候先用过滤器判断有没有，如果没有就确实没有返回null，如果有要去检查是否误判，然后从redis去取，如果有就确实有直接返回，如果没有可能key过期或者还有没有放入缓存，这时再从数据库里查，如果数据库里有就返回并给redis里存一份，如果确实没有redis里就存一个有较短ttl的null
在给数据库添加新数据时，也向过滤器里添加key、向redis里添加（k，v）
### 2. 缓存击穿
#### 原因
热点key刚好过期，且有大量请求进入查询这个key的数据，导致数据库压力过大宕机
#### 解决
（1）添加互斥锁（分布式锁） 线程一---->缓存中key过期---->添加互斥锁---->查询数据库并写回缓存---->释放锁
其他线程只能不断重试  > 查询缓存+尝试抢夺互斥锁  这个过程
低可用，高一致
（2）逻辑删除  维护缓存数据中的过期字段，当线程发现缓存数据已经过期会添加互斥锁，并开启异步线程进行数据库的查询，写回缓存并重置过期时间，释放锁，线程在开启异步线程之后会直接返回旧数据，其他线程若没有抢占到互斥锁也会直接返回旧数据，高可用，低一致
### 3. 缓存雪崩或服务器宕机
#### 原因
大量key在同一时间同时过期，大量请求涌入，导致数据库压力过大宕机
#### 解决
（1）给不同的key设置随机的TTL
（2）设计多级缓存
（3）降级限流，流量削峰，减少服务器压力
（4）部署集群，提高服务高可用性
### 4. 双写一致性
#### 原因
缓存数据和数据库数据不一致
#### 解决
强一致：（1）延迟双删   先删缓存，再更新数据库，延迟一定时间后再次删除缓存，有延迟时间是因为主从库数据同步需要一定时间，保证二次删除缓存后进入数据库查询的数据是最新的，因为延迟的时间不好把握，所以仍然会有一定的不一致
		先删缓存再更新数据库  线程 一在删除完缓存后，数据库更新未完成，线程二进入，会因缓存被删进入数据库查询出旧数据并写回缓存，产生脏数据
		先更新再删缓存  线程一更新的数据恰好在缓存中已经过期，在线程一更新数据完成之前，线程二进入，会因缓存过期进入数据库查询得到旧数据，在将数据写回缓存之前，线程一完成更新并删除了缓存，存入缓存的仍然是旧的，产生脏数据
	（2）添加读写锁  通过redisson获得同一个读写锁，读锁可以共享读，但是不能写，写锁既不能读也不能写，保证强一致
	
延迟一致：（1）添加消息中间件  当数据在业务层进行修改，发送消息到MQ，并由监听修改消息队列的业务更新缓存
		（2）Canal  使用Canal监听数据库的binglog日志，并将更新数据发送给业务，由业务进行更新缓存	

### 5.  持久化
#### RDB
定时对内存数据进行快照保存到磁盘中（在redis.conf文件中配置为多少时间有多少个key被修改就保存一次），数据存储在物理内存中，主进程操作的是虚拟内存，由页表将虚拟内存和物理内存进行映射，当进行bgsave时，会fork主进程得到子进程，子进程会拷贝一份主进程的页表，得到映射关系，读取物理内存的数据并写进磁盘中，当主进程进行写操作时，会将物理内存 的数据的状态改为readonly，并将要修改的数据拷贝一份，主进程的页表重新进行映射，对拷贝的数据进行读写，避免脏数据
体积小，恢复速度快，系统资源占用高，数据完整性较低
#### AOF
将写命令直接保存在aof文件中（在redis.conf中进行配置开启，配置为立即记录写命令/每秒记录一次/由操作系统决定记录时间），由于只有最后一次的写命令才有效，所以有aof文件重写机制，保存最有效的写命令，触发机制有当前aof文件相比之前增长了百分之多少/相比于之前增长了多大体积
体积大，恢复速度慢，系统资源占用低，数据完整性相对较高
### 6. 数据过期策略
#### 惰性删除
key过期后先不进行删除，只有当查询这个key时才进行过期判断，如果过期直接删除，没有过期则返回值
#### 定期删除
定时遍历一些key进行过期检查，删除其中过期的
slow模式，默认是10HZ，每次清理耗时不超过25ms，尽量少去影响主进程操作（在配置文件中调整hz选项进行调整）
fast模式，两次间隔大于2ms，每次不超过1ms
### 7. 数据淘汰策略

当Redis内存已经达到上限，进行的数据删除的策略
- **allkeys-lru**：在所有 key 中，淘汰最近最少使用的 key（保留热点数据）。
- **allkeys-lfu**：在所有 key 中，淘汰访问频率最低的 key。
- **volatile-lru**：只在设置了过期时间的 key 中淘汰最近最少使用的。
- **volatile-lfu**：只在设置了过期时间的 key 中淘汰访问频率最低的。
- **volatile-ttl**：淘汰 TTL 最近要过期的 key。
- **volatile-random / allkeys-random**：随机淘汰。
默认使用的是不接受新的key，当内存已经达到上限，存入新数据会直接报错
一般使用的是allkeys-lru，删除最近最少访问的key，保留热点数据
#### 如何保留热点数据
- **冷启动预热**
    - 系统刚上线或缓存重建时，提前把热点数据（例如热门商品、配置项）加载进 Redis。
    - 避免冷启动期间大量请求直接打到数据库。
- **动态识别热点**
    - 例如 **阿里巴巴的 HotKey 框架**，可以在 **毫秒级别**发现某个 key 请求量暴涨，然后推送到应用 JVM 本地缓存。
    - 这样热点 key 会被快速拦截，不用频繁走 Redis。
- **淘汰策略兜底**
    - 即便没识别出来热点，Redis 自身的 **LRU/LFU 策略**也能保证把“冷数据”淘汰掉，尽量让热点 key 留下来。
- **本地缓存兜底**
    - 极高频率的 key，可以用 **Caffeine、Guava Cache、Ehcache** 等 JVM 缓存来兜住。
    - HotKey 框架也支持把热点 key 下发到 JVM 缓存，进一步降低 Redis 压力。

## 二. 分布式锁
### 1.  setnx
```java
// nx的意思是如果键存在就不执行否则才执行，ex设置过期时间
set lock value NX EX 10;
```
通过redis命令存值设置锁并设置过期时间，保证原子性和锁会最终释放
会因业务执行时间过长导致提前解锁，通过根据业务和手动续锁来解决
### 2. redisson
#### 获取锁
通过redission添加分布式锁，底层是setnx和lua脚本执行redis命令保证原子性
```java
Rlock lock=redissonClient.getLock("lt");
boolen isLock=lock.tryLock(10,30,TimeUnit.SECOND);
boolen isLock=lock.tryLock(10,TimeUnit.SECOND);
boolen isLock=lock.tryLock();
```
没有抢占到锁的线程会循环不断尝试获取锁
会有一个watch dog线程监听当前抢占到锁的线程，并不断给锁续期（默认是10秒续期一次），直到手动释放锁，或者线程挂了按照默认的ttl自动释放

方法一：参数10是其他线程尝试获取锁的最大循环时间，参数30是最终锁的过期自动释放时间，不会自动续期，到期直接释放
方法二：同上，因为没有自动释放时间会自动续期
方法三：默认是每隔10秒给锁重新续期到30秒

#### 锁重试
```java
public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException {  
	//重试时间转换成毫秒
    long time = unit.toMillis(waitTime);  
    //当前时间
    long current = System.currentTimeMillis();  
    //线程标识，用于获取锁或重入锁
    long threadId = Thread.currentThread().getId();  
    //尝试获取锁，方法内部使用lua脚本，尝试setnx，锁不存在则成功，否则判断线程
    //标识是否和threadId一致，如果一致则可以重入并刷新ttl，否则失败
    Long ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId);  
    //脚本返回null就是成功
    if (ttl == null) {  
        return true;  
    } else {  
	    //否则判断获取锁所使用的时间是否超过了最大重试时间
        time -= System.currentTimeMillis() - current;  
        //超过了就退出
        if (time <= 0L) {  
            this.acquireFailed(waitTime, unit, threadId);  
            return false;  
        } else {  
	        //重试时间没有用完，则在这里阻塞订阅锁的释放
            current = System.currentTimeMillis();  
            CompletableFuture<RedissonLockEntry> subscribeFuture = this.subscribe(threadId);  
  
            try {  
                subscribeFuture.get(time, TimeUnit.MILLISECONDS);  
            } catch (TimeoutException var21) {  
	            //如果并发等待锁的线程数很多，且 subscriptionsPerConnection/ subscriptionConnectionPoolSize 太小，就会报这个错
                if (!subscribeFuture.completeExceptionally(new RedisTimeoutException("Unable to acquire subscription lock after " + time + "ms. Try to increase 'subscriptionsPerConnection' and/or 'subscriptionConnectionPoolSize' parameters."))) {  
                    subscribeFuture.whenComplete((res, ex) -> {  
                        if (ex == null) {  
	                        //报错后取消订阅
                            this.unsubscribe(res, threadId);  
                        }  
  
                    });  
                }  
  
                this.acquireFailed(waitTime, unit, threadId);  
                return false;  
            } catch (ExecutionException var22) {  
                LOGGER.error(var22.getMessage(), var22);  
                this.acquireFailed(waitTime, unit, threadId);  
                return false;  
            }  
  
            try {  
	            //等到了锁的释放，判断等待释放后，重试时间是否有剩余
                time -= System.currentTimeMillis() - current; 
                //没有剩余就退出 
                if (time <= 0L) {  
                    this.acquireFailed(waitTime, unit, threadId);  
                    boolean var24 = false;  
                    return var24;  
                } else {  
                    boolean var16;  
                    //循环：获取->等待的过程
                    do {  
                        long currentTime = System.currentTimeMillis();
                        //  重试获取
                        ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId);  
                        //成功
                        if (ttl == null) {  
                            var16 = true;  
                            return var16;  
                        }  
						//再次计算时间
                        time -= System.currentTimeMillis() - currentTime;  
                        if (time <= 0L) {  
                            this.acquireFailed(waitTime, unit, threadId);  
                            var16 = false;  
                            return var16;  
                        }  
  
                        currentTime = System.currentTimeMillis();  
                        if (ttl >= 0L && ttl < time) {  
                            ((RedissonLockEntry)this.commandExecutor.getNow(subscribeFuture)).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);  
                        } else {  
                            ((RedissonLockEntry)this.commandExecutor.getNow(subscribeFuture)).getLatch().tryAcquire(time, TimeUnit.MILLISECONDS);  
                        }  
  
                        time -= System.currentTimeMillis() - currentTime;  
                    } while(time > 0L);  //剩余时间要大于0
  
                    this.acquireFailed(waitTime, unit, threadId);  
                    var16 = false;  
                    return var16;  
                }  
            } finally {  //最后取消订阅，释放资源
                this.unsubscribe((RedissonLockEntry)this.commandExecutor.getNow(subscribeFuture), threadId);  
            }  
        }  
    }  
}
```

#### watch dog机制
##### 代码
```java
//在成功加锁之后执行这个方法
protected void scheduleExpirationRenewal(long threadId) {
	//ExpirationEntry是RedissonLock内部的一个静态类
    ExpirationEntry entry = new ExpirationEntry();  
    //将当前线程id存入这个entry内部的ConcurrentLinkedQueue内，如果不是重入，则在内部的ConcurrentHashMap以线程id为键存入1，否则value+1
    entry.addThreadId(threadId);  
    //EXPIRATION_RENEWAL_MAP是Redisson内部的一个静态ConcurrentMap<String, ExpirationEntry>，按照锁的名称将这个entry存入，得到老的entry（getEntryName得到的就是锁的名称）
    ExpirationEntry oldEntry = (ExpirationEntry)EXPIRATION_RENEWAL_MAP.putIfAbsent(this.getEntryName(), entry);  
    //如果老的entry不为空，说明这次是锁重入，添加当前线程id
    if (oldEntry != null) {  
        oldEntry.addThreadId(threadId);  
    } else {  
	    //否则新建一个续期任务
        try {  
            this.renewExpiration();  
        } finally {  
            if (Thread.currentThread().isInterrupted()) {  
                this.cancelExpirationRenewal(threadId, (Boolean)null);  
            }  
  
        }  
    }  
  
}
```
```java
private void renewExpiration() {  
	//从map中取出锁的entry
    ExpirationEntry ee = (ExpirationEntry)EXPIRATION_RENEWAL_MAP.get(this.getEntryName());  
    if (ee != null) {  
	    //新建一个延迟任务，定时一到执行任务，不需要放到线程池里去执行！！！
        Timeout task = this.getServiceManager().newTimeout(new TimerTask() {  
            public void run(Timeout timeout) throws Exception {  
	            //在任务里取出锁的entry
                ExpirationEntry ent = (ExpirationEntry)RedissonBaseLock.EXPIRATION_RENEWAL_MAP.get(RedissonBaseLock.this.getEntryName());  
                if (ent != null) {  
	                //得到第一个获取锁的线程
                    Long threadId = ent.getFirstThreadId();  
                    if (threadId != null) {  
	                    //将这个线程id传入异步执行器去执行，也就是发送续期命令
                        CompletionStage<Boolean> future = RedissonBaseLock.this.renewExpirationAsync(threadId);  
                        future.whenComplete((res, e) -> {  
	                        //续期发生错误出现异常（如线程挂了），移出任务
                            if (e != null) {  
                                if (!RedissonBaseLock.this.getServiceManager().isShuttingDown(e)) {  
                                    RedissonBaseLock.log.error("Can't update lock {} expiration", RedissonBaseLock.this.getRawName(), e);  
                                    RedissonBaseLock.EXPIRATION_RENEWAL_MAP.remove(RedissonBaseLock.this.getEntryName());  
                                }  
                            } else {  
                                if (res) {  
	                                //如果成功，递归创建任务
                                    RedissonBaseLock.this.renewExpiration();  
                                } else {  //如果失败则可能锁被别人抢走，或重入次数减为0，取消这个锁的续期任务
                                    RedissonBaseLock.this.cancelExpirationRenewal((Long)null, (Boolean)null);  
                                }  
  
                            }  
                        });  
                    }  
                }  
            }  
            //定时时间，看门狗时间的1/3
        }, this.internalLockLeaseTime / 3L, TimeUnit.MILLISECONDS);  
        ee.setTimeout(task);  
    }  
}
```
```java
//发送脚本给线程的锁续期，先判断是否是当前线程持有锁，如果是则正常续期
protected CompletionStage<Boolean> renewExpirationAsync(long threadId) {  
    return this.commandExecutor.syncedEval(this.getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('pexpire', KEYS[1], ARGV[1]); return 1; end; return 0;", Collections.singletonList(this.getRawName()), new Object[]{this.internalLockLeaseTime, this.getLockName(threadId)});  
}
```
##### 工作方式
- 加锁：将锁键写入 Redis，并附带“**持锁者标识**”（一般是 `clientId:threadId`）和**可重入计数**。同时给键设置 TTL（默认 30s）
- 注册续期任务：Redisson会为这把锁在JVM内注册一个续期任务，放到一个单例的定时任务线程池里面周期执行，并非一把锁专门一个线程执行续期任务
- 续期操作：
	- 默认看门狗超时参数`lockWatchdogTimeout = 30s`，最大续期任务定时时间
	- 每隔1/3个超时时间，约10s，执行一次续期
	- 在续期前会在redis里校验持有锁者的表示是否是当前线程
	- 如果是则将ttl重新设为30s（发送`PEXPIRE key 30000`命令，但是是lua脚本，保证原子性）
	- 如果不是（如释放，或被其他线程抢走）则停止续期任务
- 释放锁：
	- 主动释放：业务结束手动`lock.unlock()`，锁的可重入数减为0后，删除键并取消续期任务
	- 被动释放：进程挂了/线程死亡 → 无人续期 → **30s 后自动过期**

```txt
持锁线程 --------------------> 仍然存活 ------------------------> 释放锁/崩溃
        |   加锁(TTL=30s)
        |----10s---->(续期: TTL 重置到 30s)
        |----10s---->(续期: TTL 重置到 30s)
        |----10s---->(续期: TTL 重置到 30s)
        ...
        |  (若线程挂了：没有续期)
        |-----------------------------> 30s 达到 -> 锁键过期 -> 其他实例可获锁

```
##### 常见问题
- 如果 JVM **长时间停顿**超过 `lockWatchdogTimeout`，续期任务可能没有机会按时执行，锁会过期，导致并发进入临界区，可以将 `lockWatchdogTimeout`设置大一些
- 如果网络分区或者长时间网络波动可能会导致续期命令无法发送，redis接收不到续期的请求，ttl时间一到锁就自动释放了
- 在获取锁时如果显示指定了锁的存活时间，watch dog便不会工作


#### 锁的可重入
```java
add1(){
	getLock("lt");
	add2();
	...
	unlock();
}
add2(){
	getLock("lt");
	...
	unlock();
}
```
redis里通过hash结构存储当前线程占有锁的情况

| lock | Thread | value |
| ---- | :----: | :---: |
| lt   |  thr1  |   2   |

redis会判断尝试获取锁的线程和锁的线程标识是否一致，对锁的重入累加value值，每当有一个重入的锁进行释放，value值减一
#### 主从一致性
当线程占有锁之后，主节点会将锁的信息同步给从节点，但是如果完成同步之前，主节点宕机，从节点当选主节点没有锁的信息，其他线程也会抢占到锁，导致两个线程都持有锁
redisson无法解决主从一致性
RedLock可以。通过将锁的信息**同时**存到一半数量以上的节点保证锁的信息不会丢失，性能会很差
zookeeper可以保持强一致
或者使用multiLock
##### multiLock
只有在多个独立 Redis 节点上都加锁成功，才算加锁成功
```java
public RLock getMultiLock(RLock... locks) {  
    return new RedissonMultiLock(locks);  
}
```
```java
public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) {
    long newLeaseTime = -1; // 如果没指定 leaseTime，就用看门狗
    long time = unit.toMillis(waitTime);
    long current = System.currentTimeMillis();

    // 依次对每个子锁 tryLock
    int acquiredLocks = 0;
    for (RLock lock : locks) {
        if (lock.tryLock(time, newLeaseTime, TimeUnit.MILLISECONDS)) {
            acquiredLocks++;
        } else {
            break;
        }
        // 每加一个锁，减去耗时
        time -= System.currentTimeMillis() - current;
        if (time <= 0) {
            break;
        }
    }

    // 判断是否满足成功条件
    if (acquiredLocks == locks.size()) { // MultiLock 必须全成功
        return true;
    }

    // 如果失败，释放已加上的锁
    unlock(acquiredLocks);
    return false;
}
```
###### 加锁
1. 依次向所有 Redis 节点发送加锁命令（通常是 Lua 脚本）
2. 记录每个节点加锁成功的时间
3. 如果所有节点的redis加锁成功，则认为整个 MultiLock 成功
4. 如果未达到成功节点数，释放所有已经加上的锁（回滚）
###### 解锁
- 向所有节点发送解锁命令（即使有的节点没加上锁，也要尝试解）
- 这样即使部分节点挂了，剩下的节点也会释放锁

#### 信号量
```java
//获取信号量对象
RSemaphore semaphore =redissonClient.getSemaphore("String");
//给信号量对象设置信号量
semaphore.trySetPermits(int);
//扣除指定数量的信号量
semaphore.tryAcquire(num,100, TimeUnit.MILLISECONDS)
```

## 三. 集群

### 1. 主从复制
单点redis并发能力有限，通过搭建主从集群实现读写分离，主节点负责写操作，从节点负责读，主节点将数据修改同步给从节点

Replication Id：判断数据集是否一致，每个主节点有自己唯一的id，从节点继承主节点的id
offset：偏移量，记录已经执行到或更新到的repl baklog 文件的位置
#### 全量同步
从节点请求连接主节点并发送rpid和offset，主节点根据rpid判断从节点是不是第一次同步，如果是，则进行bgsave，生成RDB文件，并在生成文件期间将进行操作的命令记录在repl baklog文件中，之后主节点将RDB文件发送给从节点，从节点清除本地数据，加载RDB文件，之后主节点发送repl baklog的命令，从节点执行命令
#### 增量同步
如果不是第一次同步，则主节点会根据发送offset和自己的offset比较，发送两者相差的命令给从节点，让从节点进行执行
但是repl_baklog文件有存储上限，写满之后会覆盖最早的数据，如果从节点宕机时间太久，部分没有同步的数据被覆盖，则无法实现增量同步，只能进行全量同步
### 2. 哨兵机制
在主从复制的基础上添加哨兵集群监控节点情况，提高可用性
#### 选主原理
哨兵会定时向节点发送ping命令，如果节点返回pang说明节点健康
如果某个哨兵向主节点发送命令没有响应，属于主观主节点宕机，如果右超过一半数量以上的哨兵认为主节点主观宕机，则主节点客观宕机，哨兵会通知客户端新的主节点更改的消息
和主节点断开连接时间越短的从节点，offset越大的从节点越容易当选主节点，当旧 主节点恢复会成为当前主节点的从节点
#### 脑裂
当主节点和从节点和哨兵处于不同网络下时，客户端仍然能连接到旧主节点，哨兵认为主节点宕机，会从从节点中重新选举主节点，旧主节点收到的数据无法同步到其他节点，当网络恢复，旧主节点降级为新主节点的从节点，和新主节点进行数据同步，清空了本地数据，丢失了网络中断时客户端的数据
可以通过配置最小从节点数量和主从同步最大延迟时间来让修改数据命令直接拒绝解决
### 3. 分片集群
#### 原理
集群中有多个主节点，每个主节点有多个从节点，主节点之间互相进行心跳检测充当哨兵作用
每个主节点存储不同的数据，通过将一万多个hash槽分配给集群中的主节点，并对请求的key进行有效值的hash运算，将客户端的请求路由到相应的主节点
```bash
set name value lt;
set {aaa}name value lt;
```
{ }内的值就是计算hash值的有效值，如果没有，key就是有效值
## 四. 执行速度
#### 原因
redis是基于内存存储的，读写速度很快
redis是单线程的，避免了不必要的上下文切换
采用了I/O多路复用的模型
#### I/O模型
- Liunx系统将一个进程分为了用户空间和内核空间
- 用户空间只能执行受限的命令，内核空间可以直接调用所有系统资源
- 这样做是防止普通应用程序直接写入或者操作关键设备导致系统崩溃，即使用户空间崩溃也不会直接毁掉系统
- 内核空间对外暴漏统一的接口，让用户空间访问资源，防止用户空间破坏系统内部状态
- 内核空间直接管理硬件和内存，避免每个进程都重复实现这些功能
- 为了提高性能会在用户空间和内核空间内加入缓冲区
- 用户进程在写数据时会将自身数据拷贝一份到内核进程的缓冲区，然后写入硬件
- 在进行读数据时会将硬件数据加载到内核进程的缓冲区，然后将数据拷贝到用户进程缓冲区
- 所以影响redis速度的是网络传输，而不是执行效率
##### 阻塞式I/O
```txt
用户进程-----------调用recvfrom函数------------>内核进程
												|
												|
											  等待数据
											    |
											    |
   <-------------写入用户进程缓冲----------------数据就绪
```
阶段一：用户进程调用recvfrom函数，请求内核进程读取数据，如果没有则内核进程等待数据，此时用户进程处于阻塞状态
阶段二：当数据准备就绪后，用户进程会等待内核进程将数据拷贝到自己的缓冲区，此时用户进程依然是阻塞状态
##### 非阻塞式I/O
```txt
用户进程-----------调用recvfrom函数------------>内核进程
												|     循环此过程
												|
	  <-------------返回error-----------------等待数据
											    |
											    |
   <-------------写入用户进程缓冲----------------数据就绪
```
阶段一：用户进程调用recvfrom函数，如果没有数据，内核会直接返回error，用户进程会一直循环尝试请求数据，直到数据准备就绪，此时用户进程处于非阻塞状态
阶段二：当数据准备就绪后，用户进程等待数据拷贝，此时用户进程处于阻塞状态
##### I/O多路复用
```txt
用户进程-----------调用select函数-------------->内核进程
												|      
												|
											  等待数据   一旦某个socket数据就绪
											    |
											    |
   <-----------------readable----------------数据就绪
												|
												|
   <-------------写入用户进程缓冲--------------数据就绪
```
阶段一：用户进程调用select函数，发送要监听的socket集合，内核监听指定的socket集合，一个或者多个socket可读可写时，内核会返回readable，此阶段用户进程是阻塞状态
阶段二：用户进程循环遍历socket集合找到已经就绪的，并依次调用recvfrom函数读取数据，内核将数据拷贝到用户进程缓冲区
###### 实现方式
select，poll，epoll
前两者用户进程是不知道哪个socket就绪的，需要遍历寻找，后者在返回readable时会将socket信息写入用户进程缓冲区
#### redis的I/O模型
通过I/O多路复用和事件派发机制，还有连接应答处理器，命令回复处理器，命令请求处理器完成
6.0版本之后redis加入了多线程在命令回复处理器和命令请求处理器的接收参数和命令转化部分，执行部分依然是单线程的
## 五. Redis的消息队列
不同于jvm的阻塞队列，redis的消息队列依赖外部内存，而且部分类型的队列允许开启持久化保存消息到磁盘中，这样做可以减少jvm进程的内存压力
### 1. 基于LIst结构的消息队列
**核心命令**：`LPUSH` / `RPUSH` + `LPOP` / `RPOP` / `BLPOP` / `BRPOP`
#### 工作原理
- **生产者**：将消息推入列表（队列）末尾。
- **消费者**：从另一端弹出消息并删除消息。
- **阻塞模式**：`BLPOP` / `BRPOP` 可以阻塞等待消息到来（避免空轮询）
```bash
# 生产者
RPUSH myqueue "msg1"
RPUSH myqueue "msg2"

# 消费者（阻塞模式）
BLPOP myqueue 10   # 阻塞直到有消息，10表示阻塞等待的时间，如果是0，就是无限等待
```
- 支持阻塞消费
- 由于弹出消息后会将消息删除而且没有ack机制，如果在接收到消息后消费者出现异常，无法进行重试，导致漏消息
### 2. 基于发布订阅的消息队列
**核心命令**：`PUBLISH` / `SUBSCRIBE` / `PSUBSCRIBE`
#### 工作原理
- **生产者**向频道（channel）发布消息。
- **订阅者**实时接收该频道的消息
```bash
# 消费者
# 订阅多个频道
SUBSCRIBE news.sports news.weather
# 支持订阅与pattern格式匹配的所有频道
PSUBSCRIBE news.*

# 生产者
PUBLISH news.sports "Hello World"
```
- 天生阻塞式
- 支持一个消费者订阅多个频道，一个频道可以被多个消费者订阅
- 无法持久化，当订阅某个频道的消费者离线，错过的消息不能补发
### 3. 基于 Sorted Set 延迟队列
**核心命令**：`ZADD` / `ZRANGEBYSCORE` / `ZREM`
#### 工作原理
- 消息的**score**存放任务执行的时间戳。
- 定时扫描 `ZRANGEBYSCORE` 找到到期任务并处理。
- 处理后用 `ZREM` 删除任务
```bash
# 添加延迟任务（执行时间=当前时间+5秒）
ZADD delay_queue 1692000005 "task1"

# 消费者定时轮询，注意是定时轮询而不是阻塞
ZRANGEBYSCORE delay_queue -inf <current_time>
ZREM delay_queue "task1"
```
- 可实现**延迟队列**功能
- 可按时间顺序取任务
- 需要手动删除消息
- 需要轮询（可能浪费资源）。
- 没有 ACK 重试机制
### 4. 基于 Stream 的消息队列（Redis 5.0+）
**核心命令**：`XADD` / `XREAD` / `XGROUP` / `XREADGROUP` / `XACK`
#### 工作原理
- `Stream` 是 Redis 内置的**持久化、可回溯**消息队列结构。
- 支持**消费组（Consumer Group）**：多个消费者协作消费同一队列。
- 有**ACK 确认机制**，未确认的消息会放在 PEL（Pending Entries List）中，可以重新消费。
```bash
# 添加消息，*表示redis自动为消息生成唯一id，或者手动写（时间戳+自增值）
# 添加消息就是发送多个键值对
XADD mystream * name "Tom" action "login"

# 创建消费组
XGROUP CREATE mystream mygroup $ MKSTREAM

# 消费消息，>表示从下一个没被消费的消息开始
XREADGROUP GROUP mygroup consumer1 COUNT 1 STREAMS mystream >

# 读取pending-list里的消息
XPENDING mystream mygroup - + 10
XREADGROUP GROUP mygroup consumer1 COUNT 1 STREAMS mystream 0 # 处理list中的消息，注意参数不是>是0
```
- 支持持久化、回溯读取历史消息。
- 消费组机制可实现**多消费者分摊负载**。
- 有 ACK 和未确认消息重试，消费者获取消息后，消息会进入pending-list(每个消费者都有自己的list)中，当消费者ack之后才会从pending-list中移出，如果消费者挂了，还可以从list中重新获取消息消费
## 六. 实践
### 1. BigKey
- 通常以key的**大小**和key中成员的**数量**来判定，两种无论哪个大都属BigKey
- 会造成网络阻塞，同时请求较多的bigkey会导致带宽迅速被占满
- 数据倾斜，bigkey所在的redis实例，内存占用很大，会导致分片的内存资源无法达到均衡
- redis阻塞，对于list、zset、hash等数据结构的元素进行运算，会耗时很久
- cpu压力，对bigkey进行序列化和反序列化会使cpu的使用率飙升
- `redis-cli -a <password> --bigkeys`命令可以看到每种数据类型最大的bigkey
### 2. 使用合理的数据结构
- 存值的时候不仅会存具体的数值，还会存入key的原信息
- 所以不能对于什么数据都用String，会多于存储许多冗余信息占用内存
- 可以将数据拆分成hash结构，每个hash只存小于500条entry，entry太多反而不会做压缩处理
- 对于一个hash有很多的entry可以将其分组成多个hash，比如1000000个entry的hash，可以用entry的key对100取余，余数相同的拆分成一个新的hash，这样就可以拆分成10000个hash
### 3. 批处理
- 一次redis的命令，包括命令传输到redis，redis执行命令，redis返回处理结果
- redis处理普通命令的速度很快，所以耗时主要在网络传输上
- 采用批处理，一次性发送多条命令可以减少网络传输的时间，但是一次性不应传输太多，占用带宽太多很造成网络阻塞
- 使用`List<Object> executePipelined(RedisCallback<?> action)`方法可进行多种数据结构的批处理
- 以上处理方法只适用于单机，对于集群批处理，由于每个节点分配了指定数量的插槽，所以要求批处理的所有的key都要落在同一个插槽上
- 对于集群的批处理，可以将数据分成多个组，每组设置相同的有效hash_tg，将这几个组进行并行批处理
### 4. 慢查询
- 对于任何执行时间超过了阈值的命令都属于慢查询
- `slowlog-log-slower-than`配置，指定阈值单位微秒，超过阈值的命令会存储在慢查询日志中
- `slowlog-max-len`配置可以指定慢查询日志的大小，日志本质是一个队列，默认长度是128
- `slowlog get`可以查看慢查询日志
### 5. 集群问题
- 由于redis强调数据完整性，如果分片集群中的某个节点不可用整个集群也会拒绝使用，因为访问或者存储的key刚好落在不可用的节点的插槽上
- `cluster-required-full-coverage`配置设置为fasle就可以关闭整个集群不可用的规则，但是如果key是不可用节点上的插槽还是会报错
- 除此之外，分片集群的主节点充当了哨兵的功能，每次ping都会带上节点的插槽和集群状态信息，节点越多每次ping所携带的信息就会越多，会占用大量带宽，可能导致网络阻塞
## 七. 数据结构

### 1. 动态字符串SDS
redis底层采用c实现，存储的key和value也全是字符串，但是使用的不是c的原生字符串，因为原生的字符串不可修改且获取长度需要遍历计算，所以它自己构建了一个动态字符串SDS
```c
struct sdshdr8 {
    uint8_t len;  //最高8比特位，buf已经保存的字节数，不包含结束标识\0，最大255
    uint8_t alloc; //buf申请的总字节数，不包括结束标识
    unsigned char flags; /* 低 3 位存类型号 1，不同长度buf的结构体的类型不同 */
    char buf[];//指针，真正的元数据
} SDS_ATTR_PACKED;
struct sdshdr32 {
    uint32_t len;
    uint32_t alloc;
    unsigned char flags;
    char buf[];
} SDS_ATTR_PACKED;
struct sdshdr64 {
    uint64_t len;
    uint64_t alloc;
    unsigned char flags;
    char buf[];
} SDS_ATTR_PACKED;
```
- 本质上是一个结构体，不同的结构体的最大串长度不同
- 对于SDS可以动态扩容，如果要给字符串追加内容，追加后形成的新的字符串的大小不超过1m，申请的新空间会扩展为新字符串长度的2倍+1，如果超过，则为新字符串长度大小+1m+1
- 做到内存预分配，减少申请内存的操作，减少资源消耗

### 2. inset
是redis里set集合的一种实现方式，元素唯一且有序
```c
typedef struct intset {
    uint32_t encoding;   /* 编码方式：元素存储的整数宽度
                          * 可取值：INTSET_ENC_INT16：short / INTSET_ENC_INT32：int / INTSET_ENC_INT64：long */
    uint32_t length;     /* 集合中元素的个数 */
    int8_t contents[];   /* 指针，柔性数组，实际存储的整数数据，按照 encoding 类型解释 */
} intset;
```
- 规定元素宽度，可以保证用角标快速使用指针找到对应元素
- 会对元素进行升序排序
- 使用二分查找判断是否插入重复元素
- 如果添加的元素超过了宽度，会升级编码方式，重新申请空间，并将原来的数组的元素利用角标、指针、encoding计算出新的地址，倒序拷贝到正确位置。倒序拷贝后面的空间是空的，不会覆盖别的元素
### 3. dict
由三部分组成，哈希表、哈希节点（entry）、字典
```c
/* 哈希表节点（单向链表） */
typedef struct dictEntry {
    void *key;                  /* 键 */
    union {                     /* 值，可能是指针/uint64/int64/double */
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;     /* 指向下一个节点，解决哈希冲突（拉链法） */
} dictEntry;

/* 哈希表本体：一个 dict 其实有两个表，用来做渐进式 rehash */
typedef struct dictht {
    dictEntry **table;   /* 哈希表数组，存放 dictEntry* 的指针，每个元素指向一个dictEntry链表 */
    unsigned long size;  /* 哈希表大小（2^n） */
    unsigned long sizemask; /* size的掩码，用于快速计算索引 = hash值 & sizemask */
    unsigned long used;  /* 已存储的元素个数 */
} dictht;

/* 字典结构体 */
typedef struct dict {
    dictType *type;          /* 函数指针集合，不同类型的键值对有不同操作 */
    void *privdata;          /* 传递给 type 函数的私有数据 */

    dictht ht[2];            /* 两个哈希表，ht[0] 是主表，ht[1] 用于 rehash 时的临时空表 */
    long rehashidx;          /* 渐进式 rehash 索引，-1 表示没有进行 rehash */
    unsigned long iterators; /* 当前正在迭代的迭代器数量 */
} dict;
```
- 每次插入entry的时候都会检查负载因子（used/size），当负载因子满足条件的时候就会进行扩容
	- 当满足，负载因子>=1，且没有进行bgsave或aof的重写，因为这两个操作非常消耗cpu的性能
	- 当因子>5
- 每次扩容会将size扩容到大于等于used+1的最小的2的幂次
- 每次删除的时候，如果负载因子<0.1，会将哈希表收缩，如果现在的长度最小（默认为4），就不会收缩。如果进行收缩会将size收缩到大于等于当前used的最小的2的幂次
- 不论是扩容还是收缩，size和sizemask肯定会改变，要重新计算每个entry的位置rehash
	- 计算出新的size，申请空间，**创建出新的哈希表**，将其赋值给ht[1]，将rehashidx设置为0，表示正在rehash
	- 重新计算每个entry的位置，然后迁移到ht[1]
		- 实际上每次增删的时候都会进行扩容和收缩判断，如果满足条件会进行**一次**将ht[0]的rehashidx索引的数据迁移到ht[1]的操作，然后rehashidx++
		- 直到ht[0]的数据全部迁移完成
		- 而在没有rehash完成的时候，增删改查会在这两个哈希表里一起去找
	- 把ht[1]赋值给ht[0]，ht[1]初始化为空表，释放原来ht[0]所占的空间
### 4. ZipList
双端链表，但不是真正的链表，因为没有通过指针去找元素，是通过字节数进行遍历，可以在任意一端压入或者弹出，头插尾插、头删尾删操作复杂度为O(1)
```txt
<zlbytes><zltail><zllen><entry><entry>...<entry><zlend>
```
```c
/* ziplist 的整体结构 */
typedef struct ziplist {
    uint32_t zlbytes;   // 整个 ziplist 占用的字节数，自身占4字节
    uint32_t zltail;    // 最后一个 entry 距离起始地址的偏移量，自身占4字节
    uint16_t zllen;     // entry 的个数（如果超过 65535，需要遍历），自身占2字节
    unsigned char entry[]; // 各个节点 entry（变长）
    // 结尾标志 0xFF
} ziplist;

/* 每个 entry 的结构，不是固定长度，逻辑上可分为： */
typedef struct zlentry {
    unsigned int prevlen;   // 前一个 entry 的长度（自身1字节 or 5字节）
    unsigned char encoding; // 当前 entry 的编码方式（字符串 or 整数）
    unsigned char *content; // 真正的数据内容
} zlentry;
```
- 由于内存是碎片化的，很难找到一块很大连续的内存，所以ziplist不能存储太多的数据
- 没有使用指针，节省空间
- 所有数据以16进制存储
- 对于entry的encoding，00、01、10开头表示content是字符串，11开头表示是整数且此时encoding只占1字节，不仅如此encoding还记录了content所占的字节数
- 对于存整数的entry，如果数值过于小，会直接存在encoding里，不往content里面存了
- 连锁更新问题
	- 因为ziplist可以头插，所以假如在头部插入了一个超过254字节的entry，那么原来的头部entry的prevlen就要从1字节扩展为5字节，且自己因为扩展自己的字节数也超过了254字节
	- 那么后面的entry的prevlen也要进行扩展到5字节，以此类推，可能就会引发连锁更新的问题
	- 这种情况下需要因为ziplist的存储空间是连续的，所以要频繁的申请新空间做数据迁移，这会涉及到内核空间的切换，消耗大量cpu的资源
### 5. QuickList
- 在逻辑上，它是一个 **双向链表**，每个节点是一个 ziplist/listpack
- 在存储上，它避免了单个 ziplist 太大带来的 realloc/连锁更新问题，同时保留了紧凑存储的优势
- 还支持 **节点压缩（LZF 压缩）**，进一步节省内存
```c
/* quicklist 节点 */
typedef struct quicklistNode {
    struct quicklistNode *prev;  // 前一个节点
    struct quicklistNode *next;  // 后一个节点
    unsigned char *zl;           // 指向 ziplist 或 listpack 的指针
    unsigned int sz;             // 当前 ziplist 占用的字节数
    unsigned int count : 16;     // 当前 ziplist 内 entry 个数
    unsigned int encoding : 2;   // 编码方式：RAW=1 或 LZF=2
    unsigned int container : 2;  // 容器类型：NONE=1 或 ZIPLIST=2
    unsigned int recompress : 1; // 临时解压标志（访问数据时解压，之后需重新压缩）
    unsigned int attempted_compress : 1; // 测试压缩标记
    unsigned int extra : 10;     // 预留位
} quicklistNode;

/* quicklist 整体结构 */
typedef struct quicklist {
    quicklistNode *head;   // 头指针
    quicklistNode *tail;   // 尾指针
    unsigned long count;   // 所有 entry 的总数（全局元素个数）
    unsigned long len;     // quicklistNode 的节点个数（链表长度）
    int fill : 16;         // 节点 ziplist 的填充策略（负数=压缩因子，每个ziplist所占内存的大小（默认-2，8kb），正数=固定长度,每个ziplist里entry的最大数量）
    unsigned int compress : 16; // LZF 压缩深度参数（0=不压缩，>0=两端保留，其他压缩）
} quicklist;
```
### 6.SkipList
```c
/* 跳表整体 */
typedef struct zskiplist {
    struct zskiplistNode *header; // 头节点（不存数据，只做哨兵）
    struct zskiplistNode *tail;   // 尾节点（方便从尾部遍历）
    unsigned long length;         // 节点总数（不含 header）
    int level;                    // 当前最大层数（从 1 开始）
} zskiplist;

/* 跳表节点 */
typedef struct zskiplistNode {
    sds ele;                   // 成员对象（字符串）
    double score;              // 分值，用于排序
    struct zskiplistNode *backward;  // 后退指针（指向前一个节点，方便逆序遍历）
    struct zskiplistLevel {
        struct zskiplistNode *forward; // 每一层的前进指针
        unsigned long span;            // 跨度：到 forward 节点间隔多少个节点
    } level[];                 // 灵活数组：存放不同层的 forward 指针
} zskiplistNode;
```
- 元素按照升序排列
- 节点内包含一个指针数组
- 查找的时候从最高层级的指针开始寻找
### 7. RedisObject
每种数据类型最后都会被封装成一个redisobject对象
```c
/* redisObject 结构 */
typedef struct redisObject {
    unsigned type:4;     // 对象类型：string、list、set、zset、hash，对外暴漏的类型
    unsigned encoding:4; // 编码方式：raw、int、hashtable、ziplist、skiplist...
    unsigned lru:LRU_BITS; // LRU 时间戳（或 LFU 信息）
    int refcount;        // 引用计数
    void *ptr;           // 实际数据指针（指向具体底层实现的实现结构，比如 sds、ziplist、dict 等）
} robj;
```
- 小整数 `0~9999` 的 string 对象在 Redis 启动时会预分配成共享对象，直接复用，减少内存开销
## 八. 五种数据类型
### 1. String
- 基本编码方式有raw、embstr、int
- 对于raw
	- 基于SDS数据结构实现
	- 存储上限是512mb
	- 对于这种编码，会分别申请两块内存分别存储redisobject和SDS
- 对于embstr
	- 还是基于SDS数据结构实现
	- 当SDS的len小于44字节就会采用这种编码
	- 它只会申请一次内存，保存redisobject和SDS，两个结构是连在一起的，不会出现碎片
- 对于int
	- 存储的字符串是整数值的时候采用
	- 存储的是整数的二进制比特位
	- 一个指针刚好8字节，redisobject的ptr来存这个数字，不需要SDS
### 2. list
- 基于QuickList实现
### 3. set
- 元素唯一、乱序
- 编码方式是HashTable
	- 底层使用dict实现
	- dictEntry不存value，元素存在它的key里
- 当时存储的是整数且数据不多是采用InSet编码
	- 底层使用inset实现
	- 如果添加的元素不是整数或者元素个数超过了set-max-inset-entrys就会将编码方式转换成哈希
### 4. ZSet
- 有score，且member唯一，可排序
- SkipList编码
	- 底层使用dict+SkipList
	- dict用来快速查找member是否存在和member对应的score
	- SkipList用来做排序和score范围查询
	- 保存了两份数据，内存占用大
- ziplist编码
	- 当保存的元素的个数小于128，元素的大小小于64字节则使用ziplist编码
	- 底层使用ZipList，存不了键值对
	- 它将score和member放在两个紧挨着的zipentry里
### 5. Hash
- key唯一，键值对存储
- ziplist编码
	- 当数据较少时，元素数量小于512，大小小于64字节，使用这种编码（默认）
	- 底层使用ZipList，将key和value放到两个紧挨着的zipentry
- HashTable编码
	- 底层使用dict


# MySQL
## 一. 优化
### 1. 定位慢查询
#### 常见慢查询
聚合查询：聚合函数无法使用索引
多表联查：join字段如果没有索引或者索引覆盖不完全会触发回表查询
数据量过大
分页过深：例如
```sql
SELECT * FROM table 
ORDER BY xxx
LIMIT 1000000, 10;

```
实际上是对前1000010条数据进行顺序扫描加排序，然后丢掉前1000000条数据只保留10条，分页越深排序的数据就越多，order by字段如果有索引可以优化排序
#### 解决
##### 使用运维工具
如普罗米修斯，skywalking，监控方法的执行时间和各阶段耗时
##### 开启慢查询
在/etc/my.cnf中进行配置
```config
slow_query_log=1 # 开启慢查询日志
slow_query_time=2 # 指定超时时间，超过指定时间记录为慢查询
```
##### 分页过深的解决方案
###### 基于索引的“延迟关联分页 / Seek Method”
思路：不要用 `OFFSET`，而用 **最后一条记录的索引** 来查询下一页，但是不能跳页
```sql
-- 获取第一页
SELECT * FROM orders ORDER BY created_at DESC LIMIT 10;

-- 获取下一页
SELECT * FROM orders 
WHERE created_at < :last_created_at
ORDER BY created_at DESC LIMIT 10;
```
###### 覆盖索引 + 主键排序
当查询字段很多时，扫描整行成本高，可使用覆盖索引
```sql
SELECT id, created_at FROM orders
WHERE created_at < :last_created_at
ORDER BY created_at DESC
LIMIT 10;
```

### 2. 分析慢查询
通过explain关键字查看语句的执行情况
possible_key：可能用到的索引
key和key_len：实际用到的索引和索引的长度
type：语句的类型，可以通过它判断语句是否有优化空间，const通过主键查询，ref全索引扫描，all全盘扫描
extra：优化建议，如果是回表查询，可以添加索引或者修改返回字段
### 3. 索引
#### 什么是索引
帮助MySQL获取数据的数据结构，在innodb存储引擎中用B+树存储索引
提高查询效率，减少IO消耗
通过索引对数据进行排序，降低排序成本
#### 索引分类
| 分类角度     | 具体分类                  | 说明                                      | 示例                                                           |
| -------- | --------------------- | --------------------------------------- | ------------------------------------------------------------ |
| **数据结构** | B+Tree 索引             | 最常见，InnoDB 的默认索引结构，支持范围查询、排序。           | 主键索引、普通索引                                                    |
|          | Hash 索引               | 基于哈希表实现，等值查询效率高，不支持范围查询（Memory 引擎常见）。   | MEMORY 表的 Hash 索引                                            |
|          | R-Tree 索引             | 空间索引，主要用于地理位置数据（GIS）。                   | `SPATIAL INDEX`                                              |
|          | Full-text 索引          | 倒排索引结构，用于全文搜索。                          | `FULLTEXT INDEX`                                             |
| **存储方式** | 聚簇索引 (Clustered)      | 数据与索引存储在一起，每个表只能有一个，InnoDB 的主键索引就是聚簇索引。 | InnoDB 主键                                                    |
|          | 非聚簇索引 (Secondary)     | 索引和数据分开存储，索引叶子节点保存主键值，再回表查询。            | InnoDB 二级索引                                                  |
| **逻辑功能** | 主键索引 (Primary Key)    | 唯一且不为空，表中唯一。                            | `PRIMARY KEY(id)`                                            |
|          | 唯一索引 (Unique)         | 索引列值必须唯一，可以有 NULL。                      | `UNIQUE(email)`                                              |
|          | 普通索引 (Normal)         | 没有限制，单列或多列都行。                           | `INDEX(name)`                                                |
|          | 全文索引 (Fulltext)       | 支持自然语言搜索，适合大文本字段。                       | `FULLTEXT(content)`                                          |
|          | 空间索引 (Spatial)        | 用于存储 GIS 数据类型。                          | `SPATIAL INDEX(geo)`                                         |
| **字段数量** | 单列索引                  | 针对单个字段。                                 | `INDEX(name)`                                                |
|          | 联合索引 (组合索引)           | 多个字段组成一个索引，遵循**最左前缀原则**。                | `INDEX(name, age)`                                           |
| **覆盖情况** | 覆盖索引 (Covering Index) | 查询字段全部包含在索引中，无需回表。                      | `SELECT id, name FROM user WHERE name=?` 如果 `(name, id)` 有索引 |
|          | 非覆盖索引                 | 查询字段不完全在索引里，需要回表查询。                     | `SELECT * FROM user WHERE name=?`                            |
| **物理排序** | 有序索引                  | B+Tree 保证键值有序。                          | 默认 InnoDB 索引                                                 |
|          | 无序索引                  | Hash 索引无序，不支持范围查询。                      | MEMORY Hash 索引                                               |

#### B+树优势
- 每个父节点可以拥有多个子节点，分支更多则层级更少，查询路径更短
- 磁盘读写代价更少，B+树的非叶子节点只存储索引，叶子节点存储数据，且叶子节点是一个双向链表，适合进行范围查询和全库扫描
- B+树的节点大小通常与一个磁盘页对其（4kb），一个磁盘页可以一次性读入多个 key 和指针，快速定位key的位置，最大化利用磁盘带宽，这使得每次磁盘 I/O 能读取更多内容，从而**显著减少访问次数和等待时间**，减少IO
#### 聚集索引
又称聚簇索引，每张表只能有一个，特点是叶子节点挂着的是这一行的整行数据，如果表有主键，主键索引就是聚集索引，如果没有主键，第一个唯一索引就是聚集索引，如果没有合适的唯一索引，会自动生成一个隐藏的rowid字段作为聚集索引
#### 二级索引
又称非聚集索引，每张表有多个，叶子节点挂着的是对应的主键
#### 回表查询
如果二级索引没有需要查询的所有数据，需要通过叶子结点的id到聚簇索引查询需要的数据，通过创建覆盖索引来解决
#### 覆盖索引
在查询使用的索引中可以获得所有需要的字段
#### 超大分页查询
```sql
select * from sku a,(select id from sku order by id limit 9000000 10) b
where a.id=b.id;
```
通过覆盖索引加子查询进行优化
#### 创建索引原则
1.对于数据量大的表创建索引
2.有一些字段频繁用于查询条件，如where，order by
3.尽量使用区分度高，唯一的字段创建索引，如性别就不适合创建索引
4.对于较长的string字段创建前缀索引
5.尽量创建联合索引，减少单列索引，避免回表查询
6.控制数量
#### 索引失效
- 违法最左前缀法则，查询条件字段跳过了联合索引从左往右的某个字段
	- 需要注意的是，在8.0.13版本之后，MySQL优化了联合索引，引入了索引跳跃，例如创建了a，b两个字段的联合索引，但是`select a,b from ikun where b=1`违反了最左前缀法则，mysql会扫描a的所有取值并将其重新拼接进sql语句中，如`select a,b from ikun where a=2 and b=1`和`select a,b from ikun where a=1 and b=1`，通过范围扫描替换了原来索引失效导致的全表扫描
- 范围查询条件字段右边的查询条件字段无法使用索引
- 查询条件字段上进行了运算，字段的值改变无法使用索引
- 查询的字符串没加单引号，发生类型转换，原索引无法比较
- 以%开头的模糊查询会使索引失效
### 4.sql优化
#### 表的设计优化
选择合适的字段数据类型
#### sql语句优化
- 指定select的字段名称，避免使用 * 导致回表查询
- 避免索引失效的写法
- 用union all替换union，union会多一次过滤操作
- 尽量使用inner join不用left/right join，如果必须使用，要使用小表作为驱动（外表），减少内外表的连接次数，前提是大表给条件字段建了索引，不然就没什么区别
- 不要在where子句使用表达式
#### 主从复制，读写分离
见第二章
#### 分库分表
见第二章
## 二. 其他
### 1. 事务
原子性：不可分割，最小单位，全部成功或全部失败
一致性：事务完成后，所有数据必须保持一致
隔离性：事务在不受外界环境影响下并发执行
持续性：对数据库的修改是永久的
#### 并发问题
脏读：一个事务读到了另一个事务的未提交的数据
不可重复读：一个事务两次读取同一条记录，但两次数据不一致
幻读：事务在查询一条记录时，没有对应的数据，但是插入的时候却发现该条记录已经存在
#### 隔离级别
读未提交
读已提交：解决脏读
可重复读（默认）：解决脏读和不可重复读
串行化：可解决所有问题，一个事务完成之后再执行其他事务
#### undo log和redo log
缓冲池：主内存中的一个区域，里面可以存储磁盘上经常增删改查的数据，在进行操作时，先操作缓冲池里面的数据，然后以一定频率刷新到磁盘减少IO消耗，加快处理速度
数据页：innodb引擎中最小的管理单元，每个页16kb，里面存储的是行数据
##### redo log
由重做日志缓冲和重做日志文件组成，前者在主内存中后者在磁盘中，记录的是事务提交产生的数据页的物理修改，当重写日志缓冲区内容发生变化会将内容同步到日志文件中，当脏页刷新到磁盘发生错误时，可以用来数据恢复
##### undo log
记录逻辑日志，提供回滚和MVCC，当事务回滚时，可以通过逆操作恢复到原来的数据
#### MVCC
MySQL的多版本并发控制。指的是维护数据的多个版本，使读写操作没有冲突
##### 隐藏字段
每张表有两个隐藏字段
事务id：记录每一次操作的事务id，是自增的
回滚指针：指向上一个数据版本的事务版本记录地址
##### undo log
当数据被修改时，会将当前数据记录在undo log日志文件中，修改后的数据的回滚指针就会指向文件中上一版本的数据地址，形成版本控制链表，同时修改后数据的事务id会加1
##### readView
解决事务查询的数据版本问题
包含四个字段：创建readview的事务id，当前活跃的事务（未提交的事务）的id集合，最小活跃事务id，预制事务id（最大活跃事务id加1）
会根据四条规则和readview去版本控制链中查找对应版本的数据
在读已提交事务隔离级别下，事务的每次查询都会根据当前事务情况重新生成readview
在可重复读隔离级别下，各个事务内部的readview都是重用第一次生成的，但是使用时还是要根据规则比较来获取版本数据
### 2. 主从复制原理
主从复制的核心是binlog二进制日志文件
当主库的数据发生了修改，会专门有一个线程将修改的sql语句或者修改的数据记录在binlog日志文件中，从库有一个IO线程连接主库，并发起请求接收binlog文件内容，并将接收的内容写入自己的中继文件relay log中，然后有一个sql线程来重做中继文件的内容，实现数据同步，如果主从复制是行模式，那么二进制文件存储得就是对应行发生的数据变更，如果是sql模式记录的是使数据发生变化的sql语句
同时从库会记录主库的binlog文件名称和文件内偏移量，以便发生网络波动后能够定位binlog文件读取到的位置
#### binglog一致性问题
- 如果隔离级别设置不当，可能会出现以下情况：
	- **binlog 里的 SQL 顺序和事务里实际读取的数据不一致**
	- 主从复制时，主库执行 OK，但从库按 binlog 回放时得到不一样的结果
- 为什么可重复读可以解决
	- 一个事务在这种隔离级别下，使用的readView都是同一张
	- 无论并发事务提交了多少更新，当前事务读到的数据始终一致
	- **事务里 SQL 的执行结果稳定**，不会因为别的事务插队而变化
	- 记录到 binlog 里的语句和事务内实际执行时使用的数据一致

### 3. 分库分表
#### 垂直分库
根据不同的业务将不同的表存储到不同的库
#### 垂直分表
以字段为依据，根据字段属性将不同字段拆分到不同的表中，把不常用的或大字段拆分到单独的一张表
#### 水平分库
将一个库的数据拆分到多个库中，每个库都有相同的表但是存储的数据不一样，合起来才是完整的数据
根据id取模找到对应数据存储的数据库，hash运算取模分库，范围分库（一个库存到了上限再存到下一个库），时间分库（每个月的数据存到对应的一个数据库里）
```xml
<?xml version="1.0" encoding="UTF-8"?>
<mycat:schema xmlns:mycat="http://io.mycat/">

    <!-- 定义逻辑库 -->
    <schema name="order_db" checkSQLschema="false" sqlMaxLimit="1000">
        <!-- 逻辑表 -->
        <table name="order" dataNode="dn0,dn1,dn2,dn3"
               rule="sharding_rule" />
    </schema>

    <!-- 定义物理库和数据节点 -->
    <dataNode name="dn0" dataHost="ds0" database="order_db_0" />
    <dataNode name="dn1" dataHost="ds0" database="order_db_0" />
    <dataNode name="dn2" dataHost="ds1" database="order_db_1" />
    <dataNode name="dn3" dataHost="ds1" database="order_db_1" />

    <!-- 数据源配置 -->
    <dataHost name="ds0" maxCon="1000" minCon="10" balance="0"
              writeType="0" dbType="mysql" dbDriver="native">
        <heartbeat>select 1</heartbeat>
        <writeHost host="hostM1" url="127.0.0.1:3306" user="root" password="123456" />
    </dataHost>

    <dataHost name="ds1" maxCon="1000" minCon="10" balance="0"
              writeType="0" dbType="mysql" dbDriver="native">
        <heartbeat>select 1</heartbeat>
        <writeHost host="hostM2" url="127.0.0.2:3306" user="root" password="123456" />
    </dataHost>

</mycat:schema>
```
在代码层面通过使用mycat中间件，在mycat中配置物理库的逻辑库和库中的逻辑表（逻辑表和物理表的结构一样），代码面对逻辑表操作，请求实际上由mycat根据逻辑表的路由规则进行路由到对应的库中的物理表，结果由mycat进行整合返回给应用
#### 水平分表
将一张表的数据拆分到多个表中（可以在同一个库里）
减少锁表的几率
### 4. 主键问题
不推荐使用主键自增
#### 原因
自增主键是顺序的，容易被猜到，可能会被大量访问缓存中和数据库没有的数据遭受攻击
会向B+树的最后一页添加数据，页分裂，锁竞争，主内存的缓冲区数据刷脏压力全在末尾数据
对于分库分表，每个库都有自增主键很容易出现主键重复的情况
在数据迁移或合并的时候，因为id冲突需要重新映射主键
#### 解决
```java
//当前日期精确到天
LocalDate now = LocalDate.now(); 
//以当前日期为键的自增值
Long increment = redisTemplate.opsForValue().increment("icr" + "order" + ":" + now);  
//当前时间的时间戳
long timestamp = System.currentTimeMillis();  
//拼接成id，不能直接两个值相加加
long id=timestamp<<32 | increment;
```
可以通过redis的increment方法获取当前日期为键的自增值，加上当前时间点的时间戳，拼接成id值
之所以使用当前日期为键获取自增值，是因为redis对于一个键的自增值的最大值是2的64次方，所以不能重复使用一个键的自增值，所以要用当前日期做一个区分
### 5. 容量
- 一张表最大只能有4096列
- 每行数据最多65535个字节
- 某个字段如果允许为null，则会多占用一个字节记录是否为null
- varchar为变长字段,，用多少分配多少，会用一到两个字节记录长度

## 三. 锁
### 1. 锁的类别
#### 按粒度分

| 锁粒度    | 描述               | 应用场景          | 优缺点             |
| ------ | ---------------- | ------------- | --------------- |
| **表锁** | 锁整张表             | MyISAM、DDL 操作 | 开销小，锁冲突多，适合读多写少 |
| **行锁** | 锁单行记录            | InnoDB        | 并发高，开销大，需要索引支持  |
| **页锁** | 锁数据页（一次锁一页的多行记录） | BDB 存储引擎      | 粒度介于表锁与行锁之间，已少用 |

#### 按模式分
| 锁模式            | 描述                 | 使用场景                            |
| -------------- | ------------------ | ------------------------------- |
| **共享锁（S锁）**    | 允许多个事务同时读，不允许写     | `SELECT ... LOCK IN SHARE MODE` |
| **排他锁（X锁）**    | 允许当前事务读写，不允许其他事务读写 | `SELECT ... FOR UPDATE`、DML     |
| **意向共享锁（IS锁）** | 表示事务打算在某些行上加共享锁    | 由 InnoDB 自动加，用于加速表锁冲突检测         |
| **意向排他锁（IX锁）** | 表示事务打算在某些行上加排他锁    | 同上                              |
**注意**：意向锁是**表级锁**，行锁是**行级锁**，两者不冲突，意向锁只是为了让 InnoDB 快速判断“是否有人锁了行”，避免全表扫描
#### 按照锁的实现方式（InnoDB特有的）
##### 记录锁（Record Lock）
```sql
会给id为10的数据加上记录锁
SELECT * FROM t WHERE id = 10 FOR UPDATE;
```
- **定义**：锁住具体存在的记录（行）。
- **作用对象**：已存在的行数据。
- **作用场景**：事务对某条数据行执行了`SELECT ... FOR UPDATE`或`UPDATE`、`DELETE`等操作时，InnoDB会在该行上加记录锁，防止其他事务修改这条记录。
- **特征**：行级锁，精确定位某行，不锁表不锁页，支持较高并发
##### 间隙锁
```sql
InnoDB会锁住id=5那条记录的记录锁，以及5和10之间的间隙锁，阻止其他事务在5和10之间插入新数据
SELECT * FROM t WHERE id BETWEEN 5 AND 10 FOR UPDATE;
```
- **定义**：锁住两条记录之间的“间隙”范围，而不是具体行。
- **作用对象**：不存在的记录区间。
- **目的**：防止“幻读”（Phantom Read）——其他事务在这个间隙中插入新记录。
- **场景**：主要是`REPEATABLE READ`隔离级别下，为了防止幻读发生，InnoDB会锁住范围，比如`WHERE id > 5 AND id < 10`之间没有记录的区间
##### 临键锁
- **定义**：记录锁 + 间隙锁 的组合，锁住某条记录和它前面的间隙。
- **作用对象**：索引记录和该记录前面的间隙。
- **设计目的**：**彻底防止幻读**，兼顾锁粒度与一致性。
- **默认行为**：MySQL InnoDB在`REPEATABLE READ`隔离级别下的`SELECT ... FOR UPDATE`和`SELECT ... LOCK IN SHARE MODE`语句默认使用临键锁
- 举例：假设表的索引是有序的：`... < 5 < 10 < ...`，临键锁会锁定“间隙+记录”，比如对`id=10`加临键锁，实际上锁的是`(5,10]`这个范围内的“间隙”和`id=10`的记录本身。这意味着其他事务不能插入`id`在5到10之间的记录，也不能修改`id=10`
##### 插入意向锁
- **定义**：是一种表级的意向锁，表示事务想在某个间隙内插入新记录。
- **作用对象**：间隙，用于标识插入动作的意图。
- **特点**：它是轻量级的，事务并不会阻塞其他插入操作，只要不是在同一具体间隙冲突
- 多事务并发插入时，插入意向锁让数据库知道“我想插入这里”，但不会相互阻塞，避免死锁
### 2. 死锁
#### 排查死锁
```sql
SHOW ENGINE INNODB STATUS\G
```
这个命令会显示InnoDB最新检测到的死锁信息，包括涉及的事务、锁等待链、SQL语句
```sql
SELECT * FROM information_schema.innodb_lock_waits;
SELECT * FROM information_schema.innodb_locks;
```
查询当前等待的锁，可以看到事务等待链，辅助判断死锁风险
#### 解决死锁
- **保证事务内访问表和行的顺序一致**  
    多个事务如果按相同顺序访问相同资源，就不会出现循环等待。  
    例如：所有事务都先锁A再锁B，避免一个锁A一个锁B，形成互等。
- **减少事务持锁时间**  
    尽量把事务逻辑简化、缩短，避免长事务导致锁时间长。
- **降低隔离级别**  
    在可接受的范围内使用`READ COMMITTED`替代`REPEATABLE READ`，减少间隙锁和锁竞争。
- **避免范围锁的无谓使用**  
    尽量使用精准索引条件避免全表扫描或大范围锁定

# Spring
## 一. Bean
### 1. IOC容器
#### 原理及流程
基本思想是控制反转，将对象的创建和管理由程序员变成了IOC容器，由它来创建对象，注入依赖，管理生命周期，bean的创建和初始化是串行执行的，一个bean完成全部流程才会继续下一个
##### 入口
在创建ApplicationContext对象的时候底层就已经初始化好了ioc容器，并生成了bean
```java
AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);
```
```java
public AnnotationConfigApplicationContext(Class<?>... componentClasses) { 
	//无参构造，做准备
    this();  
    //注册配置类，读取配置类的注解、扫描包，这才知道要去哪里找定义的bean
    this.register(componentClasses);  
    //从一堆 BeanDefinition 出发，完成 BeanFactory 的准备、BeanDefinition 的扩展解析、BeanPostProcessor 的注册，再到 Bean 的实例化和初始化，最终让容器进入“就绪运行状态”
    this.refresh();  
}
```
```java
//无参构造
public AnnotationConfigApplicationContext() {  
    StartupStep createAnnotatedBeanDefReader = this.getApplicationStartup().start("spring.context.annotated-bean-reader.create"); 
	//创建bean定义对象的读取器 
    this.reader = new AnnotatedBeanDefinitionReader(this);  
    createAnnotatedBeanDefReader.end();  
    //创建类路径bean定义扫描对象
    this.scanner = new ClassPathBeanDefinitionScanner(this);  
}
```
##### 配置类注册（AnnotationConfigApplicationContext#register）
配置类的注册部分和其他类的注册流程是一样的只是时机更早
```java
public void register(Class<?>... componentClasses) {  
    //用bean定义对象的读取器注册配置类
    this.reader.register(componentClasses);  
    registerComponentClass.end();  
}
```
```java
public void register(Class<?>... componentClasses) {  
    Class[] var2 = componentClasses;  
    int var3 = componentClasses.length;  
  
    for(int var4 = 0; var4 < var3; ++var4) {  
        Class<?> componentClass = var2[var4];  
        //循环注册每一个传入的配置类
        this.registerBean(componentClass);  
    }  
  
}
```
```java
public void registerBean(Class<?> beanClass) {  
    this.doRegisterBean(beanClass, (String)null, (Class[])null, (Supplier)null, (BeanDefinitionCustomizer[])null);  
}
```
```java
private <T> void doRegisterBean(Class<T> beanClass, @Nullable String name, @Nullable Class<? extends Annotation>[] qualifiers, @Nullable Supplier<T> supplier, @Nullable BeanDefinitionCustomizer[] customizers) { 
	//创建出配置类的BeanDefinition
    AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(beanClass);  
    //判断是否应该跳过该配置类的注册，例如使用了条件注解
    if (!this.conditionEvaluator.shouldSkip(abd.getMetadata())) {  
	    //设置属性，用于告诉Spring容器："这个Bean定义是一个配置类候选项，需要特殊处理"
        abd.setAttribute(ConfigurationClassUtils.CANDIDATE_ATTRIBUTE, Boolean.TRUE);  
        //设置bean对象供应商，即谁来创建具体的bean实例
        abd.setInstanceSupplier(supplier);
        //解析作用域  
        ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); 
        //设置作用域 
        abd.setScope(scopeMetadata.getScopeName());  
        //设置bean名称，如果传入了就用，没传就用默认的生成器生成一个
        String beanName = name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry);  
        //通用注解处理，如primary、lazy、Fallback、DependsOn等，会将对象的对应属性设置为true
        AnnotationConfigUtils.processCommonDefinitionAnnotations(abd);  
        int var10;  
        int var11;  
		//包装BeanDefinition成一个完整的持有者，包含beanName和BeanDefinition对象等各种信息，在各种Bean解析器和处理器之间传递Bean定义信息，在向Bean工厂注册Bean时，使用BeanDefinitionHolder作为统一的数据结构
        BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName);  
        //根据作用域来延迟实际Bean的获取，确保在正确的时机获取到对应作用域的实例
        definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry);  
        //向注册表中注册封装好的BeanDefinitionHolder
        BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);  
    }  
}
```
```java
public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException {  
  //尝试从容器中取出对应bean名称的BeanDefinition
    BeanDefinition existingDefinition = (BeanDefinition)this.beanDefinitionMap.get(beanName);  
    if (existingDefinition != null) {  
	    //如果不为空，但是不允许覆盖则报错
        if (!this.isBeanDefinitionOverridable(beanName)) {  
            throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition);  
        }  
		//允许覆盖则直接put进去覆盖，并记录覆盖日志
        this.logBeanDefinitionOverriding(beanName, beanDefinition, existingDefinition);  
        this.beanDefinitionMap.put(beanName, beanDefinition);  
    } else {  
	    //如果为空则检查别名
        if (this.isAlias(beanName)) {  
            String aliasedName = this.canonicalName(beanName);  
            //如果不允许覆盖会报错
            if (!this.isBeanDefinitionOverridable(aliasedName)) {  
	            //如果已经有了以这个别名为名称的definition同样报错，只是时机更早
                if (this.containsBeanDefinition(aliasedName)) {  
                    throw new BeanDefinitionOverrideException(beanName, beanDefinition, this.getBeanDefinition(aliasedName));  
                }  
  
                throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, "Cannot register bean definition for bean '" + beanName + "' since there is already an alias for bean '" + aliasedName + "' bound.");  
            }   
			//从别名列表里移出这个bean的别名
            this.removeAlias(beanName);  
        }  
		//如果bean正在创建中，则加锁，否则不加
		//就是通过AbstractBeanFactory这个类里的alreadyCreated这个set是不是空进行判断
        if (this.hasBeanCreationStarted()) {  
            synchronized(this.beanDefinitionMap) {  
	            //注册
                this.beanDefinitionMap.put(beanName, beanDefinition);  
                //更新beanNames集合
                List<String> updatedDefinitions = new ArrayList(this.beanDefinitionNames.size() + 1);  
                updatedDefinitions.addAll(this.beanDefinitionNames);  
                updatedDefinitions.add(beanName);  
                this.beanDefinitionNames = updatedDefinitions;  
                //移除手动用ApplicationContext创建出来的单例bean
                this.removeManualSingletonName(beanName);  
            }  
        } else {  
            this.beanDefinitionMap.put(beanName, beanDefinition);  
            this.beanDefinitionNames.add(beanName);  
            this.removeManualSingletonName(beanName);  
        }  
  
        this.frozenBeanDefinitionNames = null;  
    }  
}
```
##### 容器启动（AnnotationConfigApplicationContext#refresh）
```java
	public void refresh() throws BeansException, IllegalStateException {
    // 1. 预处理，标记容器正在活跃中，注册全局事件监听者
    prepareRefresh();
    // 2. 获取 BeanFactory（核心容器）
    ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory();
    // 3. BeanFactory 的准备工作，设置参数、注册依赖等
    prepareBeanFactory(beanFactory);
    // 4. 注册BeanDefinition（核心），扫描注解将类转化成BeanDefinition放入beanDefinitionMap中
    invokeBeanFactoryPostProcessors(beanFactory);
    // 5. 注册BeanPostProcessor后处理器
    registerBeanPostProcessors(beanFactory);
    // 6. 实例化单例Bean
    finishBeanFactoryInitialization(beanFactory);
    // 7. 完成 refresh
    finishRefresh();
}

```
##### BeanDefinition 解析（AnnotationConfigApplicationContext#refresh#invokeBeanFactoryPostProcessors）
```java
//注册
protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) {  
//执行BeanFartory后置处理器，在内部进行扫描注解转化成BeanDefinition对象
    PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, this.getBeanFactoryPostProcessors());  
	.....
}
```
```java
public static void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory, List<BeanFactoryPostProcessor> beanFactoryPostProcessors){
	......
	//获取所有后置处理器的迭代器
	Iterator var6 = beanFactoryPostProcessors.iterator();  
  //依次构造注解扫描的核心处理器
  //由这些处理器扫描指定包下的特定注解
while(var6.hasNext()) {  
    BeanFactoryPostProcessor postProcessor = (BeanFactoryPostProcessor)var6.next();  
    if (postProcessor instanceof BeanDefinitionRegistryPostProcessor registryProcessor) {  
        registryProcessor.postProcessBeanDefinitionRegistry(registry);  
        registryProcessors.add(registryProcessor);  
    } else {  
        regularPostProcessors.add(postProcessor);  
    }  
    ......
}

}
```
```txt
具体的流程如下
invokeBeanFactoryPostProcessors()
├── 处理 BeanDefinitionRegistryPostProcessor
│   └── ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry()
│       └── processConfigBeanDefinitions()
│           └── ConfigurationClassParser.parse()
│               └── ComponentScanAnnotationParser.parse()
│                   └── ClassPathBeanDefinitionScanner.doScan()
│                       └── 扫描类路径，识别@Component等注解
│                       └── 将扫描到的类转换为BeanDefinition

```
1. ConfigurationClassPostProcessor扫描@Configuration类
2. 解析@ComponentScan注解获取扫描路径
3. 使用ClassPathBeanDefinitionScanner扫描类路径
4. 识别带有@Component、@Service、@Repository、@Controller等注解的类
5. 将这些类转换为BeanDefinition并注册到BeanDefinitionRegistry
##### 实例化 Bean(AnnotationConfigApplicationContext#refresh#finishBeanFactoryInitialization)
```java
protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {
	......
	//完成所有单例bean的初始化
	beanFactory.preInstantiateSingletons();
	......
}
```
```java
public void preInstantiateSingletons() throws BeansException{
	//获取beanNames列表
	List<String> beanNames = new ArrayList(this.beanDefinitionNames);  
	List<CompletableFuture<?>> futures = new ArrayList();
	Iterator var3;  
	String beanName;  
	try {  
		//获取bean名称列表迭代器
	    var3 = beanNames.iterator();  
  
	    while(var3.hasNext()) {  
	        beanName = (String)var3.next();  
	        //获取对应的bean定义对象
	        RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); 
	        //筛选出非抽象的单例bean进行异步创建 
	        if (!mbd.isAbstract() && mbd.isSingleton()) {  
	            CompletableFuture<?> future = this.preInstantiateSingleton(beanName, mbd);  
            if (future != null) {  
                futures.add(future);  
	            }  
	        }  
	    }  
	} finally {  
	    this.mainThreadPrefix = null;  
	    this.preInstantiationThread.remove();  
	}
}
```
```java
private CompletableFuture<?> preInstantiateSingleton(String beanName, RootBeanDefinition mbd) {  
    if (mbd.isBackgroundInit()) {  
        Executor executor = this.getBootstrapExecutor();  
        if (executor != null) {  
            String[] dependsOn = mbd.getDependsOn();  
            //如果存在依赖的bean优先保证依赖的bean先创建，为后序的依赖注入做准备
            if (dependsOn != null) {  
                String[] var5 = dependsOn;  
                int var6 = dependsOn.length;  
  
                for(int var7 = 0; var7 < var6; ++var7) {  
                    String dep = var5[var7];  
                    //通过getBean触发bean的创建！！！
                    this.getBean(dep);  
                }  
            }  
			//异步创建实例
            CompletableFuture<?> future = CompletableFuture.runAsync(() -> {  
                this.instantiateSingletonInBackgroundThread(beanName);  
            }, executor);  
            this.addSingletonFactory(beanName, () -> {  
                try {  
                    future.join();  
                } catch (CompletionException var2) {  
                    ReflectionUtils.rethrowRuntimeException(var2.getCause());  
                }  
  
                return future;  
            });  
            //如果不是懒加载则返回future，否则返回null，到时候按需加载
            return !mbd.isLazyInit() ? future : null;  
        }  
    }  
    return null;  
}
```
```java
private void instantiateSingletonInBackgroundThread(String beanName) {  
    this.preInstantiationThread.set(DefaultListableBeanFactory.PreInstantiation.BACKGROUND);  
  
    try {  
	    //创建单例bean
        this.instantiateSingleton(beanName);  
    } 
}
```
```java
private void instantiateSingleton(String beanName) {  
    if (this.isFactoryBean(beanName)) {  
        Object bean = this.getBean("&" + beanName);  
        if (bean instanceof SmartFactoryBean) {  
            SmartFactoryBean<?> smartFactoryBean = (SmartFactoryBean)bean;  
            if (smartFactoryBean.isEagerInit()) {  
                this.getBean(beanName);  
            }  
        }  
    } else {  
	    //通过getBean触发bean的创建
        this.getBean(beanName);  
    }  
}
```
```java
public Object getBean(String name) throws BeansException {  
    return this.doGetBean(name, (Class)null, (Object[])null, false);  
}
```
```java
//创建bean并解决依赖循环
protected <T> T doGetBean(String name, @Nullable Class<T> requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException {  
	//获取bean名称
    String beanName = this.transformedBeanName(name);  
    //从三级缓存中尝试获取bean，详情代码在此代码块之后
    Object sharedInstance = this.getSingleton(beanName);  
    Object beanInstance;  
    //如果缓存里有
    if (sharedInstance != null && args == null) {  
	    //检查是否已经有处理过的对应的Bean实例可以直接返回
        beanInstance = this.getObjectForBeanInstance(sharedInstance, name, beanName, (RootBeanDefinition)null);  
    } else {  //如果缓存里没有
	    //如果bean正在创建中，抛出创建异常
        if (this.isPrototypeCurrentlyInCreation(beanName)) {  
            throw new BeanCurrentlyInCreationException(beanName);  
        }  
		//获取父类工厂
        BeanFactory parentBeanFactory = this.getParentBeanFactory();  
        //如果父类工厂不为空
        if (parentBeanFactory != null && !this.containsBeanDefinition(beanName)) {  
            String nameToLookup = this.originalBeanName(name);  
            //如果工厂是这个类的子类，则调用自己的doGetBean方法
            if (parentBeanFactory instanceof AbstractBeanFactory) {  
                AbstractBeanFactory abf = (AbstractBeanFactory)parentBeanFactory;  
                return abf.doGetBean(nameToLookup, requiredType, args, typeCheckOnly);  
            }  
			//否则调用。。。
            return parentBeanFactory.getBean(nameToLookup);  
        }  
	   //如果没有父类工厂
        try {  
            RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName);  
            this.checkMergedBeanDefinition(mbd, beanName, args);  
            //再次判断是否有依赖属性
            String[] dependsOn = mbd.getDependsOn();  
            String[] prototypeInstance; 
            //如果有 
            if (dependsOn != null) {  
                prototypeInstance = dependsOn;  
                int var13 = dependsOn.length;  
				//遍历依赖项
                for(int var14 = 0; var14 < var13; ++var14) {  
                    String dep = prototypeInstance[var14];  
                    //如果有的依赖项也依赖了当前bean，抛出循环依赖异常
                    //其实就是去dependentBeanMap找
                    if (this.isDependent(beanName, dep)) {  
                        throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'");  
                    }  
				  //将依赖bean注册到DefaultSingletonBeanRegistry的Map<String, Set<String>> dependentBeanMap中
                    this.registerDependentBean(dep, beanName);  
  
                    try {  
	                    //再次创建依赖bean
                        this.getBean(dep);  
                    }
                }  
            }  
			//依赖bean创建完成之后
			//如果当前bean是单例的
            if (mbd.isSingleton()) {  
	            //真正开始创建单例bean
                sharedInstance = this.getSingleton(beanName, () -> {  
                    try {  
	                    //创建bean的方法是自己的createBean这个方法
                        return this.createBean(beanName, mbd, args);  
                    } catch (BeansException var5) {  
                        this.destroySingleton(beanName);  
                        throw var5;  
                    }  
                });  
                //检查是否已经有处理过的对应的Bean实例可以直接返回
                beanInstance = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd);  
            } else if (mbd.isPrototype()) {  //如果是原型bean
                prototypeInstance = null;  
  
                Object prototypeInstance;  
                try {  
	                //调用bean的前置方法
                    this.beforePrototypeCreation(beanName);  
                    //仍然是自己的createBean方法去创建
                    prototypeInstance = this.createBean(beanName, mbd, args);  
                } finally {  
	                //后置方法
                    this.afterPrototypeCreation(beanName);  
                }  
			   //检查是否已经有处理过的对应的Bean实例可以直接返回
                beanInstance = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);  
            } else {  
	            //其他作用域的bean
                String scopeName = mbd.getScope();   
            }  
        }  
    }  
  
    return this.adaptBeanInstance(name, beanInstance, requiredType);  
}
```
```java
//来到DefaultSingletonBeanRegistry中，检查三级缓存
//首先看看DefaultSingletonBeanRegistry中的成员变量
//锁，保证bean的单例注册/销毁
final Lock singletonLock = new ReentrantLock();  
//一级缓存，保存已经完成了初始化的bean实例
private final Map<String, Object> singletonObjects = new ConcurrentHashMap(256);  
//三级缓存，保存 Bean 的 `ObjectFactory`（通常是代理工厂或 lambda），用于延迟创建或者解决循环依赖
private final Map<String, ObjectFactory<?>> singletonFactories = new ConcurrentHashMap(16);  
//二级缓存，半成品bean
private final Map<String, Object> earlySingletonObjects = new ConcurrentHashMap(16);  
//已经注册了的bean单例名称列表
private final Set<String> registeredSingletons = Collections.synchronizedSet(new LinkedHashSet(256));  
//正在创建中的bean
private final Set<String> singletonsCurrentlyInCreation = ConcurrentHashMap.newKeySet(16);  
//被排除在“正在创建中”检查之外的 Bean
private final Set<String> inCreationCheckExclusions = ConcurrentHashMap.newKeySet(16);  
//那些bean正在宽松创建中，宽松创建即多个线程共同创建同一个bean
private final Set<String> singletonsInLenientCreation;  
//哪些线程正在等待宽松创建完成
private final Map<Thread, Thread> lenientWaitingThreads;  
//记录当前那些线程正在创建bean
private final Map<String, Thread> currentCreationThreads; 
//创建好的单例bean集合
private final Map<String, DisposableBean> disposableBeans;
//bean的包含关系，如 Bean A 包含 Bean B（inner bean）
private final Map<String, Set<String>> containedBeanMap; 
//bean的依赖关系，key被那些val（set集合）依赖
private final Map<String, Set<String>> dependentBeanMap;  
//同上，key依赖了那些val（set集合）
private final Map<String, Set<String>> dependenciesForBeanMap;

protected Object getSingleton(String beanName, boolean allowEarlyReference) {  
	//先看一级缓存
    Object singletonObject = this.singletonObjects.get(beanName);  
    //一级缓存没有
    if (singletonObject == null && this.isSingletonCurrentlyInCreation(beanName)) {  
	    //看二级缓存
        singletonObject = this.earlySingletonObjects.get(beanName);  
        //二级缓存没有
        if (singletonObject == null && allowEarlyReference) {  
	        //如果上不了锁，不阻塞直接返回
            if (!this.singletonLock.tryLock()) {  
                return null;  
            }  
  
            try {  
	            //如果能上锁，再看一次一级缓存
                singletonObject = this.singletonObjects.get(beanName);  
                //没有
                if (singletonObject == null) {  
                //再看一遍二级缓存
                    singletonObject = this.earlySingletonObjects.get(beanName);  
                    //没有
                    if (singletonObject == null) {  
	                    //看有没有创建这个bean的工厂，即看看三级缓存
                        ObjectFactory<?> singletonFactory = (ObjectFactory)this.singletonFactories.get(beanName);  
                        //不为null，则获取bean
                        if (singletonFactory != null) {  
                            singletonObject = singletonFactory.getObject();  
                        }  
                    }  
                }  
            } finally {  
            //解锁
                this.singletonLock.unlock();  
            }  
        }  
    }  
  
    return singletonObject;  
}
```
```java
//创建bean的方法，上面的是从缓存里找bean的方法，是在DefaultSingletonBeanRegistry里的，两个不一样，要注意
public Object getSingleton(String beanName, ObjectFactory<?> singletonFactory) {  
    Assert.notNull(beanName, "Bean name must not be null");  
    //当前线程
    Thread currentThread = Thread.currentThread();  
    //判断线程是否有权限
    Boolean lockFlag = this.isCurrentThreadAllowedToHoldSingletonLock();  
    //是否需要上锁，如果线程有权限则不上，没有则上
    boolean acquireLock = !Boolean.FALSE.equals(lockFlag); 
    //如果需要上锁，那么上锁的结果是否成功 
    boolean locked = acquireLock && this.singletonLock.tryLock();  
  
    try {  
	    //从一级缓存缓存中取
        Object singletonObject = this.singletonObjects.get(beanName);  
        Object var191;  
        //没有
        if (singletonObject == null) {  
	        //需要上锁但是没成功
            if (acquireLock && !locked) {  
                if (Boolean.TRUE.equals(lockFlag)) {  
	                //再次尝试锁一次
                    this.lenientCreationLock.lock();  
                    try {  
	                    //标记bean为宽松创建
                        this.singletonsInLenientCreation.add(beanName);  
                    } finally {  
                        this.lenientCreationLock.unlock();  
                    }  
                } else {  
                    this.singletonLock.lock();  
                    locked = true;  
                    //加锁再从缓存里取一次
                    singletonObject = this.singletonObjects.get(beanName);  
                    //不为空就返回了
                    if (singletonObject != null) {  
                        var191 = singletonObject;  
                        return var191;  
                    }  
                }  
            }  
            
            try {  
	            //再从缓存里取一次
                singletonObject = this.singletonObjects.get(beanName);  
                if (singletonObject == null) {  
	                //让当前线程去创建bean
                    this.currentCreationThreads.put(beanName, currentThread);  
  
                    try {  
                    //开始创建！！！，这个getObject方法也就是AbstractBeanFactory的createBean方法。
                        singletonObject = singletonFactory.getObject();  
                    } finally {  
                        this.currentCreationThreads.remove(beanName);  
                    }  

                    newSingleton = true;  
                }  
            }
            //注册单例对象 
            addSingleton(beanName, singletonObject);
            .....
}
```
```java
protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException {  
 
    Object beanInstance;  
    try {  
	    //触发InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation
	    //如果某个 BeanPostProcessor（比如 AOP 的代理创建器 AbstractAutoProxyCreator）决定要“替换掉”这个 bean 的正常创建流程，它就会在这里直接返回一个 代理对象
	    //比如使用了@Transactional注解，就会在这里创建出代理类返回
        beanInstance = this.resolveBeforeInstantiation(beanName, mbdToUse);  
        if (beanInstance != null) {  
            return beanInstance;  
        }  
    }  
    try {  
	    //这个是绝大多数普通bean的创建
        beanInstance = this.doCreateBean(beanName, mbdToUse, args);  
        return beanInstance;  
    }
}
```
```java
protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException {  
    BeanWrapper instanceWrapper = null;  
    if (mbd.isSingleton()) {  
	    //从缓存里面找
        instanceWrapper = (BeanWrapper)this.factoryBeanInstanceCache.remove(beanName);  
    }  
	//缓存没有则创建
    if (instanceWrapper == null) {  
        instanceWrapper = this.createBeanInstance(beanName, mbd, args);  
    }  
	//得到真正的实例
    Object bean = instanceWrapper.getWrappedInstance();  
    Class<?> beanType = instanceWrapper.getWrappedClass();  
	//后置处理
    synchronized(mbd.postProcessingLock) {  
	    ......
    }  
  
    Object exposedObject = bean;  
  
    try {  
	    //依赖注入
        this.populateBean(beanName, mbd, instanceWrapper);  
        //生命周期钩子调用
        exposedObject = this.initializeBean(beanName, exposedObject, mbd);  
    } 
    try {  
	    //如果有必要注册成一次性bean，即放到DefaultSingletonBeanRegistry的 Map<String, DisposableBean> disposableBeans;
        this.registerDisposableBeanIfNecessary(beanName, bean, mbd);  
        return exposedObject;  
    } 
}
```
```java
protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) {  
	//获取bean的Class对象
    Class<?> beanClass = this.resolveBeanClass(mbd, beanName, new Class[0]);  
    //如果class对象不为空，但是不允许修改且不允许公开访问，则报错
    if (beanClass != null && !Modifier.isPublic(beanClass.getModifiers()) && !mbd.isNonPublicAccessAllowed()) {  
        throw new BeanCreationException();  
    } else {  
        if (args == null) {  
	        //参数为空，从供应商获取
            Supplier<?> instanceSupplier = mbd.getInstanceSupplier();  
            if (instanceSupplier != null) {  
                return this.obtainFromSupplier(instanceSupplier, beanName, mbd);  
            }  
        }  
		//参数不为空，且有有参构造函数，则通过反射调用有参构造创建出来
        if (mbd.getFactoryMethodName() != null) {  
            return this.instantiateUsingFactoryMethod(beanName, mbd, args);  
        } else {  
	        //没有有参构造函数
            boolean resolved = false;  
            boolean autowireNecessary = false;  
            //也没有参数
            if (args == null) {  
                synchronized(mbd.constructorArgumentLock) {  
	                //是否已经解析了构造函数
                    if (mbd.resolvedConstructorOrFactoryMethod != null) {  
	                    //标记完成解析
                        resolved = true;  
	                    //判断是否有必要依赖注入
                        autowireNecessary = mbd.constructorArgumentsResolved;  
                    }  
                }  
            }  
  
            if (resolved) {  
	            //如果需要依赖注入，则进行反射的构造函数自动装配，否则无参构造一个简单实例
                return autowireNecessary ? this.autowireConstructor(beanName, mbd, (Constructor[])null, (Object[])null) : this.instantiateBean(beanName, mbd);  
            } else {  
	            //如果没有解析则先解析，在构造函数自动装配或者无参构造简单实例
                Constructor<?>[] ctors = this.determineConstructorsFromBeanPostProcessors(beanClass, beanName);  
                if (ctors == null && mbd.getResolvedAutowireMode() != 3 && !mbd.hasConstructorArgumentValues() && ObjectUtils.isEmpty(args)) {  
                    ctors = mbd.getPreferredConstructors();  
                    return ctors != null ? this.autowireConstructor(beanName, mbd, ctors, (Object[])null) : this.instantiateBean(beanName, mbd);  
                } else {  
                    return this.autowireConstructor(beanName, mbd, ctors, args);  
                }  
            }  
        }  
    }  
}
```

##### 依赖注入（DI核心）
```java
protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {  
	//如果为空或者为record，则不允许注入依赖
    if (bw == null) {  
        if (mbd.hasPropertyValues()) {  
            throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance");  
        }  
    } else if (bw.getWrappedClass().isRecord()) {  
        if (mbd.hasPropertyValues()) {  
            throw new BeanCreationException();  
        }  
    } else {  
  
        PropertyValues pvs = mbd.hasPropertyValues() ? mbd.getPropertyValues() : null;  
        int resolvedAutowireMode = mbd.getResolvedAutowireMode();  
        if (resolvedAutowireMode == 1 || resolvedAutowireMode == 2) {  
            MutablePropertyValues newPvs = new MutablePropertyValues((PropertyValues)pvs);  
            //取出bean定义中的依赖，根据依赖名称或类型去容器找依赖
            if (resolvedAutowireMode == 1) {  
                this.autowireByName(beanName, mbd, bw, newPvs);  
            }  
  
            if (resolvedAutowireMode == 2) {  
                this.autowireByType(beanName, mbd, bw, newPvs);  
            }  
		  
            pvs = newPvs;  
        }  
		//@Autowired、@Resource 等注解生效的地方
        if (this.hasInstantiationAwareBeanPostProcessors()) {  
            if (pvs == null) {  
	            //扫描字段/方法上的 `@Autowired`，然后把依赖 Bean 加入到 `pvs` 中
                pvs = mbd.getPropertyValues();  
            }  
        if (pvs != null) { 
	        //将收集好的依赖利用反射注入 
            this.applyPropertyValues(beanName, mbd, bw, (PropertyValues)pvs);  
        }  
  
    }  
}
```
在找依赖的过程中仍然是从三级缓存里去找，从一级开始依次寻找，如果一二级都没有，则使用三级缓存的beanFactory，根据依赖的类型去创建，然后收集进pvs里进行批量注入，另外会将创建出来的依赖放进二级缓存里
##### BeanPostProcessor 扩展（AOP钩子）
```java
protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) {  
    this.invokeAwareMethods(beanName, bean);  
    Object wrappedBean = bean;  
    if (mbd == null || !mbd.isSynthetic()) {  
	    //前置处理器调用
        wrappedBean = this.applyBeanPostProcessorsBeforeInitialization(bean, beanName);  
    }  
  
    try {  
	    //自身初始化方法调用
        this.invokeInitMethods(beanName, wrappedBean, mbd);  
    } 
    if (mbd == null || !mbd.isSynthetic()) {  
	    //后置处理器调用，将前置处理和初始化方法结束后的结果继续处理，形成责任链模式
        wrappedBean = this.applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);  
    }  
    return wrappedBean;  
}
```
执行bean内部的`@PostConstruct` / @afterPropertiesSet这类init方法，对bean进行最后的初始化，如果bean没有实现postProcessAfterInitialization方法，spring的AOP组件其实已经实现了，它会判断是否要为这个bean生成代理对象，例如是否使用了事务注解
由此可见，代理对象的创建或BeanPostProceess的调用是一个责任链默认，前置处理器返回的东西会继续被处理，如果bean实现的方法返回的是代理对象，spring就不会继续为这个bean代理，所以如果生成代理的逻辑有问题会导致逻辑重复，代理嵌套或终止spring自带的事务代理
```java
// spring的aop组件默认postProcessAfterInitialization方法实现源码
@Override
public Object postProcessAfterInitialization(Object bean, String beanName) {
    // 1. 跳过基础类型、自己不代理自己等判断
    if (shouldSkip(bean, beanName)) {
        return bean;
    }
    // 2. 根据配置创建代理
    Object cacheKey = getCacheKey(bean.getClass(), beanName);
    Object proxy = this.cachedProxy(cacheKey);
    if (proxy == null) {
        proxy = createProxy(bean, beanName);
        cacheProxy(cacheKey, proxy);
    }
    return proxy;
}
protected Object createProxy(Object bean, String beanName) {
    Class<?> beanClass = bean.getClass();
    // 1. 先获取所有要织入的切面（Advisor）
    List<Advisor> advisors = findEligibleAdvisors(beanClass, beanName);

    if (advisors.isEmpty()) {
        return bean;
    }

    // 2. 根据代理策略创建代理
    ProxyFactory proxyFactory = new ProxyFactory();
    proxyFactory.copyFrom(this);
    proxyFactory.setTarget(bean);
    proxyFactory.setInterfaces(beanClass.getInterfaces());
    proxyFactory.addAdvisors(advisors);
    proxyFactory.setProxyTargetClass(isProxyTargetClass());

    // 3. 生成代理对象（JDK动态代理或CGLIB代理）
    return proxyFactory.getProxy(getProxyClassLoader());
}
```
```java
//将存储的处理遍历取出进行处理
for (BeanPostProcessor processor : postProcessors) {
    currentBean = processor.postProcessAfterInitialization(currentBean, beanName);
}
```

##### 单例池管理
`disposableBeans` 是 Spring 的单例池：
```java
//创建好的单例bean集合
private final Map<String, DisposableBean> disposableBeans;
```
所有创建好的 Bean 会放进去，后续直接取：
```java
getSingleton(beanName);
```
将bean存储在内存中，后续需要直接从内存里取出
### 2. 单例bean线程安全
- 对于bean中的无状态成员属性（无法修改状态的属性）是线程安全的，可以修改的成员属性，在多线程情况下会有线程安全
- 解决方案
	- 可以让bean的方法提供可变成员属性，每次调用都生成一个新的
	- 将成员属性设置成final，不允许修改
	- 使用线程安全的数据结构，如`ConcurrentHashMap`、`CopyOnWriteArrayList`、`AtomicXXX`
	- 如果这个 Bean 内部确实需要存放和线程强相关的数据，可以把它改成 `@Scope("prototype")` 或 `@RequestScope`，每次注入、getBean、请求时（单次会话）拿到的都是一个新的bean，避免并发共享
- 之所以spring允许注入非线程安全的成员属性，是因为spring本身不行负责线程安全，且在有些场景下需要bean拥有一个可变的成员属性，如缓存、任务列表、连接池等
### 3. 三级缓存
Spring IOC 容器里用于管理 Bean 的缓存，主要有**三级缓存**，当需要依赖注入时从一级开始寻找
需要注意到，三级缓存只能解决bean初始化的循环依赖问题，在创建bean时，如果有**有参构造器**是无法解决的，因为在创建实例阶段缓存里是没有东西的，无法注入依赖，但是可以通过懒加载，也就是需要的时候再去注入，可以将bean的创建延迟到初始化时用三级缓存的函数和一二级的缓存bean解决
```java
// 一级缓存：真正初始化完的单例
private final Map<String, Object> singletonObjects = new ConcurrentHashMap<>();

// 二级缓存：半成品对象（已经提前暴露的引用）
private final Map<String, Object> earlySingletonObjects = new HashMap<>();

// 三级缓存：ObjectFactory（延迟生成代理的工厂）
private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<>();
```
```java
public class A{
	privite B b;
	public A(@lazy B b){
		this.b=b;
	}
}
```
#### 一级缓存
singletonObjects：存储真正**完成了初始化（内部依赖已经注入）的bean实例**
#### 二级缓存
earlySingletonObjects：**没有完成初始化的bean实例**，这种是不能拿来直接用的（不能作为依赖直接注入到其他bean里），只能提前暴露引用，解决循环依赖问题
暴露引用，这个引用可能是原始对象或代理对象，可能是由三级缓存的函数生产的
#### 三级缓存
```java
// 提前暴露引用（三级缓存）
if (mbd.isSingleton()) {
	//getEarlyBeanReference延迟调用的函数，生成对象引用（可能是代理对象或者原始对象）
    addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, bean));
}
```
singletonFactories：ObjectFactory，提供创建 Bean 的工厂，用于**产生**提前暴露对象（如代理）

### 4. AOP
面向切面编程，用于将那些与业务无关的，但对多个对象产生影响的代码，抽取成公共块复用，降低代码耦合
可以通过环绕通知记录日志等
Spring的声明式事务就是使用AOP对方法进行了拦截，来开启事务，提交或回滚事务
### 5. 事务失效
#### 异常捕获处理
如果在方法内部将异常捕获后，**自行处理且没有继续向外抛出**，那么在发生异常后，代理对象的catch部分是无法被触发的，导致事务失效
#### 抛出检查异常
事务默认是catch运行时异常，如果**抛出的是检查时异常**，就无法正常检测
#### 非public方法
**只有方法是public方法，事务才能生效**，AOP本身只能拦截public方法，因为jdk动态代理的是接口，而接口里的方法都是public，CGLIB代理虽然可以代理类，但默认也只拦截 public 方法，因为 Spring 规范里事务注解是用于业务逻辑层（Service 层）公共 API 的事务控制。且无论那种代理，本质上都是调用了目标对象或者父类的方法然后加上前后通知，如果方法是私有的便无法调用
#### 同一个类中非事务方法调用事务方法
```java
@Service
public class MyService {
    public void a() {
        // 这里直接调用 b()
        b();
    }

    @Transactional
    public void b() {
        
    }
}
```
在该类的动态代理类中，对于a方法的代理，内部走的直接是`this.b()`，而不是代理对象的b方法
### 6. @Component和@Bean的区别
| 方式                            | 默认作用域                   | 说明                               |
| ----------------------------- | ----------------------- | -------------------------------- |
| `@Component`                  | 单例（singleton）           | 被扫描后自动注入容器，默认就是单例                |
| `@Bean`（在 `@Configuration` 里） | 单例（singleton）           | 返回的对象同样是单例                       |
| `@Bean`（在 **普通类** 里）          | 看起来是单例，其实每次调用都会 new（⚠️） | 因为没走 **CGLIB 增强代理**，方法之间不共享同一个实例 |
- Component用在类上，@Bean用在方法上，将返回值注入到ioc
- 定义在Configuration里的bean是单例的，无论是注入还是调用方法得到都是同一个
- 定义在Component里的bean，注入时是单例，调用方法返回的是新的
### 7. JDK动态代理和CGLIB代理
| 对比维度                   | JDK 动态代理                                 | CGLIB 动态代理                                            |
| ---------------------- | ---------------------------------------- | ----------------------------------------------------- |
| 📌 **代理原理**            | 基于 Java 反射生成实现接口的代理类                     | 基于 ASM 字节码技术生成目标类的子类（继承）                              |
| 🎯 **是否需要接口**          | ✅ 是，必须实现接口                               | ❌ 否，可以是普通类                                            |
| 🧱 **代理类结构**           | 动态创建的实现接口的类（如 `$Proxy0`）                 | 动态创建的子类，继承了原类（如 `UserService$$EnhancerByCGLIB$$xxxx`） |
| 🔁 **方法调用原理**          | 将方法调用转发到 `InvocationHandler.invoke(...)` | 重写方法，通过 `MethodProxy.invokeSuper(...)` 调用父类方法         |
| 🔍 **调用真实方法方式**        | 使用反射调用（性能稍慢）                             | 直接调用 `super.原方法()`（比反射快）                              |
| ⚠️ **final 支持情况**      | ✅ 可以代理 final 类的方法（因为是反射）                 | ❌ 不能代理 final 类或 final 方法（不能被继承）                       |
| 🧱 **生成类继承结构**         | 不继承目标类                                   | 继承目标类（目标类不能是 final）                                   |
| 🧱 **目标类字段继承情况**       | 不可访问目标类字段                                | 可继承字段（可以访问父类protected/public字段）                       |
| 💥 **类加载机制**           | 使用 Java 自带的 `ProxyGenerator` 创建类字节码      | 使用 CGLIB + ASM 操作字节码创建类                               |
| 🔥 **性能（JDK >= 1.8）**  | 快（JDK 1.8之后优化了反射机制）                      | 更快（使用的是字节码直接调用）                                       |
| 🧪 **Spring AOP 默认策略** | Spring 默认使用 JDK 代理（如果目标类实现了接口）           | 如果目标类没有实现接口，则自动降级为 CGLIB                              |
| ⚙️ **是否支持注解代理**        | 支持（通过接口实现调用）                             | 支持（可以代理类上的注解）                                         |
| 🛠️ **是否支持类注入字段**      | 不支持（代理类与目标类无继承关系）                        | 支持，因其是目标类的子类                                          |
| 📚 **常见应用框架支持**        | Java标准、Spring AOP、MyBatis Mapper 动态代理    | Spring AOP、Hibernate懒加载、AspectJ 等                     |
#### JDK动态代理（代理的目标必须实现了某个接口）
```java
public interface IUserService {
    void login(String username);
}

public class UserService implements IUserService {
    @Override
    public void login(String username) {
        System.out.println(username + " 登录系统");
    }
}

//生成代理对象逻辑
public class JdkProxyFactory {
    public static Object getProxy(Object target) {
        return Proxy.newProxyInstance(
		        //原类的类加载器，用于生成代理对象的字节码，通过字节码利用反射创建出真正的代理对象
                target.getClass().getClassLoader(),
                //目标类实现的接口类
                target.getClass().getInterfaces(),
                //代理对象内方法逻辑的生成器
                new InvocationHandler() {
                    @Override
                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                        System.out.println("[JDK前置] 方法：" + method.getName());
                        Object result = method.invoke(target, args);
                        System.out.println("[JDK后置]");
                        return result;
                    }
                }
        );
    }
}
```
目标要代理的类，必须实现一个接口
JDK动态代理的本质就是生成一个同样**实现了相同接口**的对象，对象内部有目标类的对象，这个代理对象实现的方法逻辑里调用了原类的方法，并加上了前后环绕
#### CGLIB代理（Springboot在2.x之后默认使用的是CGLIB代理）
```java
public class CglibProxyFactory {
    public static Object getProxy(Object target) {
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass()); // 继承目标类
        enhancer.setCallback(new MethodInterceptor() {
	        //重写方法逻辑
            @Override
            public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
                System.out.println("[CGLIB前置] 方法：" + method.getName());
                //执行原类方法
                Object result = proxy.invokeSuper(obj, args); // 注意：调用的是 super 而不是反射
                System.out.println("[CGLIB后置]");
                return result;
            }
        });
        return enhancer.create();
    }
}
```
CGLIB代理本质就是，生成一个**继承了目标对象**的代理对象，重写目标对象的方法，在方法里加上前后环绕，然后执行目标对象的方法，也就是父类方法
### 8. 事务传播
事务传播定义的是：当一个事务方法（调用者）调用另一个事务方法（被调用者）时，事务的行为和边界该如何处理

| 传播类型            | 行为说明                                              | 举例场景                |
| --------------- | ------------------------------------------------- | ------------------- |
| `REQUIRED`（默认）  | 如果当前没有事务，则新建事务；如果已有事务，则加入该事务。                     | 常见默认行为，多个方法共享同一事务   |
| `SUPPORTS`      | 如果当前有事务，则加入事务；如果没有事务，则以非事务方式执行。                   | 可有可无事务环境下执行         |
| `MANDATORY`     | 必须在事务中执行，否则抛异常。                                   | 要求调用方必须开启事务         |
| `REQUIRES_NEW`  | 挂起当前事务，创建一个新事务。                                   | 业务需要独立提交，比如日志表写入    |
| `NOT_SUPPORTED` | 挂起当前事务，以非事务方式执行。                                  | 业务不支持事务，且不想被挂起的事务影响 |
| `NEVER`         | 必须在非事务环境下执行，否则抛异常。                                | 只能无事务调用场景           |
| `NESTED`        | 如果当前有事务，则在嵌套事务内执行，支持回滚到保存点；如果没有事务，则行为同`REQUIRED`。 | 复杂业务中子事务单独回滚        |


## 二. SpringMVC
### 1. 执行流程
#### 视图阶段（JSP）
```txt
请求 -> DispatcherServlet -> HandlerMapping -> HandlerExecutionChain
       -> HandlerAdapter -> Controller -> ModelAndView -> ViewResolver
       -> View -> 渲染 HTML -> 返回给客户端
```
1. 用户发出请求会先到达前端控制器
2. 前端控制器会调用一个或多个处理器映射器
	1. 根据请求路径找到对应的处理器（controller中的某个方法）
	2. 同时处理器映射器会返回处理器执行链HandlerExecutionChain，其包含：handler，所有的拦截器
	3. **随后前端控制器顺序执行一次拦截器，出现false直接拒绝请求**
3. 前端控制器调用处理器适配器
	1. 前端控制器传入HandlerExecutionChain
	2. 调用对应的处理器适配器执行handler
	3. 处理器适配器进行参数解析，调用controller方法，返回ModelAndView给前端控制器，包含视图名称和模型数据
	4. **前端控制器逆序执行一遍拦截器**
4. 视图解析
	1. 前端控制器将ModelAndView传入视图解析器，
	2. 根据视图名称找到对应的jsp文件，返回一个view对象
5. 视图渲染
	1. 前端控制器调用view.render方法
	2. 将模型数据和jsp模板进行合并、渲染（如EL表达式）
	3. 最终生成HTML返回给浏览器

#### 前后端分离阶段
```txt
        浏览器/前端JS
             ↓
      DispatcherServlet
             ↓
     HandlerMapping  — 找到Controller方法
             ↓
     HandlerAdapter   — 调用目标方法
             ↓
     HttpMessageConverter
     （比如返回 JSON）
             ↓
     响应写回给前端
```
前面步骤都一致，在adaptor调用完controller方法之后会进行返回值处理，转换成json，封装进response，通过网络返回给前端
## 三. Springboot
### 1. 自动装配
```java
@Configuration
@EnableAutoConfiguration
@ComponentScan
public @interface SpringBootApplication { }
```
```java
@Target({ElementType.TYPE})  
@Retention(RetentionPolicy.RUNTIME)  
@Documented  
@Inherited  
@AutoConfigurationPackage  
@Import({AutoConfigurationImportSelector.class})  
public @interface EnableAutoConfiguration { }
```
1. 关键注解在于启动注解内的@**EnableAutoConfiguration**，它会触发自动装配流程
2. 它的@**Import({AutoConfigurationImportSelector.class})** 向spring容器中导入一个组件（configuration类）
3. spring通过调用AutoConfigurationImportSelector的selectImports方法，读取META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports自动装配文件
4. 逐个判断这个自动装配类是否满足装配条件:
```java
@AutoConfiguration  //xxxAutoConfiguration自动装配类的特征
@ConditionalOnClass({OllamaApi.class})  
@EnableConfigurationProperties({OllamaConnectionProperties.class}) //导入配置属性类
```
```java
@ConfigurationProperties("spring.ai.ollama.chat") //配置属性类特征，定义配置前缀
```
```java
@ConditionalOnClass：classpath 中有该类才生效
@ConditionalOnMissingBean：如果没有用户定义的 Bean，才注入默认 Bean
@ConditionalOnProperty：配置了某个属性才生效
@ConditionalOnBean：存在某个 Bean 才生效
```
5. 如果某个xxxAutoconfiguration满足所有条件就会将其内部定义的bean注入到ioc容器中
# Mybatis/Mybatis-plus
## 一 . Mybatis
### 1. 执行流程
```txt
     ┌─────────────┐
     │ SpringBoot  │（注入 Mapper、配置）
     └──────┬──────┘
            ↓
     ┌───────────────┐
     │ MapperProxy   │（动态代理 Mapper 接口）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ DefaultSqlSession│（真正执行 SQL 的类）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ Executor（执行器）│
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ StatementHandler │（预编译 SQL）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ ParameterHandler │（设置参数）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ ResultSetHandler │（处理结果）
     └────────────────┘
```
- springboot启动后，mybatis的自动配置类会先读取mybatis.config文件配置，包括Mapper接口和Mapper文件的映射，数据库的连接信息
- Mapper接口在启动时被MapperScannerRegistrar扫描，创建出MapperFactoryBean，并由MapperFactoryBean生成一个代理对象MapperProxy
- 同时所有 Mapper.xml（或注解 SQL）里的 `<select>`、`<insert>`、`<update>`、`<delete>` 标签会被解析成一个个 **MappedStatement** 对象，也就是sql模板
- MapperProxy中会缓存每个Mapper的方法的方法名和参数，调用接口方法实际上会在其内部调用MapperProxy#invoke()方法执行sql：
```java
public class MysqlSessionFactory {  
    @SuppressWarnings("all")  
    public <T> T getMapper(Class<T> mapperClass) {  
        return (T) Proxy.newProxyInstance(this.getClass().getClassLoader(), new Class[]{mapperClass}, new selectInvoker());  
    }  
  
    static class selectInvoker implements InvocationHandler {  
        @Override  
        @SuppressWarnings("all")  
        //在代理方法中，获取到sql标签的sql模板，构建PreparedStatementHandler对象
        //设置参数，执行PreparedStatementHandler
        public Object invoke(Object proxy, Method method, Object[] objects) throws Throwable {  
            if (method.getName().startsWith("select")) {  
                String selectSql = createSelectSql(method, agrgs);  
try (Connection connection = DriverManager.getConnection(JDBCURL, USER, PASSWORD)) {  
    PreparedStatement preparedStatement = connection.prepareStatement(selectSql);  
    for (int i = 0; i < agrgs.length; i++) {  
	    //设置参数
        if(agrgs[i] instanceof Integer){  
            preparedStatement.setInt(i + 1, (Integer) agrgs[i]);  
        }else if(agrgs[i] instanceof String){  
            preparedStatement.setString(i + 1, (String) agrgs[i]);  
        }  
    }  
    //执行sql，获取结果集
    ResultSet resultSet = preparedStatement.executeQuery();  
    if(resultSet.next()){  
	    //处理结果封装
        return pareResult(resultSet,method.getReturnType());  
    }  
} 
            }  
            return null;  
        }  
    }  
}
private Object pareResult(ResultSet resultSet, Class<?> returnType) {
	//根据方法的返回值类型通过反射创建出一个示例，并用ReslutSet进行字段赋值
    Constructor<?> constructor = returnType.getConstructor();  
    Object instance = constructor.newInstance();  
    Field[] declaredFields = returnType.getDeclaredFields();  
    for (Field declaredField : declaredFields) {  
        declaredField.setAccessible(true);  
        declaredField.set(instance, resultSet.getObject(declaredField.getName()));  
    }  
    return instance;  
}
```
- 调用了接口的方法之后，调用的其实是代理对象的代理方法的invoke逻辑
- 根据方法签名找到对应的MappedStatement（xml文件中的sql标签）
- 创建PreparedStatementHandler对象进行预编译sql
- 调用ParameterHandler设置sql参数，将Java对象转换成sql数据
- 执行sql
- 调用ResultSetHandler解析结果集，根据接口方法的返回值类型通过反射创建出一个空示例，并用查询出来的结果进行赋值
## 二. Mybatis-plus
### 1. 执行流程
```java
public interface BaseMapper<T> {
    T selectById(Serializable id);
    int insert(T entity);
    ...
}
```
- 托管了BaseMapper的动态代理，封装了大量的CURD方法
- 项目启动时会将通用CURD方法注入到Mapper的代理对象中
- 自定义 Wrapper 构造器（QueryWrapper、UpdateWrapper）
## 三. 注意点
### 1. sql标签内$、#的区别
在执行mapper接口方法时，最后会创建PreparedStatementHandler对象进行预编译sql，这时如果sql标签内参数的占位符是$，会将方法传入的参数直接拼接进sql语句里不会进行预编译，这种方式会导致sql注入
如果使用的是#，会将原始sql的参数占位符替换成？占位符，然后进行预编译，之后再进行参数设置，相当于使用jdbc底层的prepareStatement方法进行参数传入，可以有效防止sql注入
### 2. 延迟加载
```xml
<resultMap id="userMap" type="User">
    <id property="id" column="id"/>
    <result property="name" column="name"/>
    
    <!-- collection 设置延迟加载,fetchType延迟加载字段，select延迟加载方法，可来自另外的接口 -->
    <collection property="orders"
                ofType="Order"
                select="selectOrdersByUserId"
                column="id"
	            延迟加载字段
                fetchType="lazy"/>
</resultMap>

<select id="selectUserById" resultMap="userMap">
    SELECT * FROM user WHERE id = #{id}
</select>

<select id="selectOrdersByUserId" resultType="Order">
    SELECT * FROM orders WHERE user_id = #{id}
</select>
```
关闭时，会将result里的额外字段一起加载，开启后只有在调用目标结果的get方法时才会调用延迟方法进行查询，然后通过set方法写入
### 3. 一、二级缓存
#### 一级缓存
```java
Sqlsession sqlsession =new Sqlsession();
UserMapper1 u1=sqlsession.getMapper(UserMapper.class);
UserMapper1 u2=sqlsession.getMapper(UserMapper.class);
u1.getbyid(1);
//第二个查询和第一个相同，因为在同一个sqlsession下，是不会重复查询而是从一级缓存里面取
u1.getbyid(1);
```
- 默认开启
- 本质是HashMap
- 作用域是sqlsession，在同一个sqlsession下的缓存数据就是一级缓存，相同的查询语句会优先去一级缓存里面找，当sqlsession进行flush或者close后，里面的缓存就会被清空
- 在分布式情况下，一级缓存就没有什么作用了，别的session已经修改了数据，但是当前session还在使用缓存里的旧数据
#### 二级缓存
- 默认关闭，除了要在配置文件配置外，还要给mapper文件添加 **<cache/>** ，标记此mapper接口开启二级缓存
- 开启后会先查二级再查一级然后数据库
- 作用域是mapper，和session无关，同一个接口的不同对象会在所属的session提交或关闭后将一级缓存数据缓存在二级缓存里，二级缓存的数据必须实现序列化接口
- 可以做到跨session缓存数据，只要是同一个mapper下都会放进同一个二级缓存，但是对于连表查询，连接的表的数据发生修改，主表的mapper缓存无法感知到
- 使用的是**本地map**进行缓存，分布式情况下仍然会出问题
#### 清除
在某一个**作用域**（session作用域或者mapper作用域）的数据发生增删改，之后会将对应作用域的缓存数据清除
# 微服务

**五大组件：注册中心，负载均衡，远程调用，服务熔断，网关**
## 一. 注册中心
### 1. Nacos
##### 服务注册表结构
微服务将自己注册到Nacos后，会将自己的信息保存到注册表中，通过多级的map结构实现
```yaml
┌────────────────────────────────────────────────────────────┐
│                       Nacos 注册表                         │
│      registry: Map<namespaceId, Map<group@@service, Service>> │
└────────────────────────────────────────────────────────────┘
                             │
                             ▼
┌───────────────┐
│ Namespace: public（或自定义） │
└───────────────┘
       │
       ▼
┌────────────────────────────┐
│ Service: DEFAULT_GROUP@@user-service │
└────────────────────────────┘
       │
       ▼
┌────────────────────────────────────────┐
│ ClusterMap:                            │
│   ┌────────────────────────────────┐   │
│   │ Cluster: DEFAULT   可以配置多   │   │
│   │  ├─ metadata: {...}            │   │
│   │  ├─ HealthChecker: {...}       │   │
│   │  └─ instances: List<Instance>  │   │
│   └────────────────────────────────┘   │
└────────────────────────────────────────┘
       │
       ▼
┌─────────────────────────────────────────────────────┐
│ Instance:                                           │
│  ├─ ip: 192.168.1.100                               │
│  ├─ port: 8080                                      │
│  ├─ healthy: true                                   │
│  ├─ ephemeral: true                                 │
│  ├─ metadata: {version=1.0, env=prod}               │
│  └─ weight: 1.0                                     │
└─────────────────────────────────────────────────────┘

```
- namespace：环境隔离（test、pro，dev），包含多个service，不同namespace的服务实例不能互相发现
- service：一个微服务在一个namespace下的抽象表示，service中多个服务实例挂在它的集群Cluster中
- Cluster：每个service默认只有一个，可以手动扩展为多个，每个Cluster承载对应集群的实例
- Instance：服务实例，每个节点（ip+端口）对应一个实例，可以将其分配在同一service下的不同Cluster中
#### 支撑大量注册压力
```txt
[客户端发起注册请求]
           │
           ▼
[服务端接收（如 ServerA）]
  ├─ 解析参数，构建 Instance
  ├─ 本地注册表内存中添加 Instance
  │    └── registry.put(serviceKey, instance)
  └─ 创建一个【同步任务 SyncTask】

           ▼
[将 SyncTask 放入任务阻塞队列中]
           │
           ▼
【线程池（如 DistroTaskEngine）**异步单线程**消费任务】
  ├─ 从任务队列中取出任务
  ├─ 判断任务类型（Distro / Raft）
  |- 更新本地注册表
  └─ 执行集群注册表同步逻辑：
        ├─ 构造同步数据包
        ├─ HTTP/gRPC 推送给其他节点
        └─ 其他节点更新自身内存注册表

           ▼
[同时：将任务放入阻塞队列后主线程立即响应客户端注册成功 ✅]
```
为了应对注册压力，设置nacos集群，某个节点的service实例向某个nacos节点进行注册后，这个nacos节点的注册表不会立即更新，会先将本地的旧的service实例和新注册的实例进行合并，**放入缓存中，之后直接响应客户端**，实际上**放入缓存之后会开启异步任务**，将更新任务放入阻塞队列中，利用**线程池**读取任务，**异步单线程更新**本地和其他nacos节点的注册表
#### 并发读写处理
copyOnwrite
```txt
[客户端注册 / 注销 / 修改实例]
           │
           ▼
[ServiceManager 接口层]
  ├─ 检查是否存在对应 Service / Cluster
  ├─ **使用同步锁保护关键注册流程**
  │     └── synchronized (Service.class) 或 ReentrantLock
  └─ 修改注册表：添加/删除/更新 Instance
           │
           ▼
	    加入阻塞队列中
		   │
           ▼
[任务线程获取一个同步任务，进行单线程异步处理 SyncTask]
           │
           ▼
【阶段1：读取本地注册表】
  └─ 取出当前 Service / Cluster 的 instances 列表（旧视图）

           │
           ▼
【阶段2：复制旧列表 + 合并新数据】
  ├─ 将旧列表 deep copy 一份（为了并发读写隔离）
  ├─ 把新同步来的 instances 与本地进行合并：
  │     ├─ 找出需要删除的（旧有但新数据中不存在）
  │     ├─ 找出需要更新的（IP相同，状态/metadata不同）
  │     └─ 找出需要新增的（新数据中有但本地没有）
  └─ 构造一个“新版本的 instances 列表”

           │
           ▼
【阶段3：将 Cluster 实例列表替换为新列表】
  └─ `cluster.setInstances(newInstanceList);`
           │
           ▼
【此操作为原子性写入，替换掉旧视图】
  → 内存中注册表正式更新
  → 对外暴露读接口时，读到的就是合并之后的数据
```
接取任务后先将本地的、其他nacos节点同步过来的实例信息进行**copy并合**并成一个新的副本，对其中相较于原来减少的进行删除、状态改变的修正状态、不变的保持不变、新增的进行添加。在此期间，**客户端进行读，读到的是旧的注册表**，在完成副本的处理后直接将旧的cluster/service进行替换，注意到**异步任务是单线程处理的**，避免并发执行出现脏数据
此方法在没有加大粒度锁的情况下，解决了读写冲突问题，也没有影响性能
#### nacos实现配置热更新
```txt
+---------------------+
|     Nacos Server    |  ←—— 负责存储和管理配置
+---------+-----------+
          |
    1. 配置变更（新增/修改/删除）
          |
          v
+---------------------+
|  配置发布通知机制   |  ←—— Nacos Server 推送配置变更事件
+---------+-----------+
          |
          v
+---------------------+        +--------------------+
|  配置客户端 Listener | ←—— 监听配置变更事件       |
+---------+-----------+        +--------------------+
          |                              |
    2. 收到变更通知                     3. 执行回调刷新本地配置
          |                              |
          v                              v
+---------------------+
|  应用本地配置刷新   |  ←—— 应用根据新配置动态调整运行行为
+---------------------+
```
- nacos维护了一张订阅者列表
- 当某个配置发生修改，nacos-server触发事件通知机制，**标记**对应配置发生更新
- 客户端以**长轮询**方式持续向 Nacos Server 发送订阅请求，请求中会带上本地已知的配置版本号或内容摘要
- Nacos Server 对比客户端版本，如果配置有变化，马上返回最新配置和变更事件
- 如果配置无变化，则保持连接挂起直到超时，或配置发生变化时立即响应
- 客户端收到配置更新响应后，触发本地的监听器回调
- 回调方法从 Nacos Server 拉取最新配置内容，更新本地缓存
- 应用业务模块通过注入的配置监听接口，动态刷新使用中的配置参数。
- 典型动作包括：刷新内存中的配置对象（将新的配置注入Spring Bean（使用Spring的`@RefreshScope`或手写刷新逻辑））、重新加载服务参数、重建连接池（如果配置改变了数据库或消息中间件连接参数，销毁旧连接，创建新连接）、切换日志级别等。
- 无需重启，应用配置热生效。

#### Nacos和Eureka的区别
##### 实例类型
nacos有临时实例和永久实例，eureka只有临时实例
##### 健康检测
nacos会将临时实例和永久实例注册到两个不同的列表中
临时实例客户端会有一个向nacos发送心跳的任务，nacos判断当前发送心跳的时间戳和上一次发送心跳的时间戳间隔，如果超过了正常实例发送心跳任务规定的时间（正常心跳周期），就会将其标记为不健康实例，此外nacos也有一个定时的轮询任务，遍历临时列表的实例，判断当前时间戳和最近一次发送心跳的时间戳之间的间隔，如果超过了允许发送心跳的最大时间（最大心跳超过时间），就会将其标记为异常，对于异常的临时实例，nacos会直接剔除
对于永久实例，nacos中的一个线程池会轮询永久实例列表并主动发起请求询问实例是否存活，如果在规定时间返回响应说明就是健康的，如果超过了规定时间就会被标记会不健康，如果没有响应会标记为异常，对于异常的永久实例，nacos不会直接剔除

eureka只支持实例的心跳机制
##### 服务拉取
nacos支持定时拉取和订阅推送两种模式
定时拉取是指，客户端定时向服务端发送请求获取最新的服务信息，订阅推送是在服务信息发生变更时nacos会用udp套接字和客户端建立连接，将变更的信息广播给所有订阅的微服务，微服务会将变更的服务信息缓存到本地服务列表，下一次就会优先从缓存读取，缓存没有，再去nacos拉取

eureka只会进行定时拉取
## 二. 负载均衡
在客户端拉取到要调用的服务列表信息后，会使用负载均衡组件选择一个服务调用
注意在版本的spring boot已经弃用了ribbon，建议使用loadbalance
### 1. Ribbon
#### 负载均衡策略
- 简单轮询，对拉取到的服务挨个进行调用
- 按权重选择，响应时间越长的，权重越低
- 随机调用
- 以区域可用的服务器为基础进行选择，使用Zone对服务器进行分区，Zone可以理解为一个机房、一个机架，然后对Zone内多个服务进行轮询调用（默认）
- 忽略短路的服务，选择并发数较低的服务
- 针对一个服务进行重试机制，直到调用成功
- 可用性敏感策略，先过滤非健康的，选择连接数较小的
#### 自定义负载均衡策略
##### Bean配置
```java
@Configuration
public class RibbonClientConfig {

    @Bean
    public IRule ribbonRule() {
        return new CustomWeightRule();  // 自定义策略
    }
}
```
##### 配置文件配置
```yml
my-service: # 你想配置的服务名，必须和 @LoadBalanced 中使用的名称一致
  ribbon:
    NFLoadBalancerRuleClassName: com.example.ribbon.rule.CustomWeightRule
```
### 2. LoadBalancer
#### 自定义负载均衡策略
##### bean配置
```java
public class RandomLoadBalancer implements ReactorServiceInstanceLoadBalancer {

    private final String serviceId;
    private final ServiceInstanceListSupplier supplier;
    private final Random random = new Random();

    public RandomLoadBalancer(ServiceInstanceListSupplier supplier, String serviceId) {
        this.serviceId = serviceId;
        this.supplier = supplier;
    }

    @Override
    public Mono<Response<ServiceInstance>> choose(Request request) {
        return this.supplier.get().map(instances -> {
            if (instances.isEmpty()) return new EmptyResponse();
            int index = random.nextInt(instances.size());
            return new DefaultResponse(instances.get(index));
        });
    }
}
```
```java
@Configuration
public class LoadBalancerConfig {

    @Bean
    public ReactorServiceInstanceLoadBalancer randomLoadBalancer(
            ObjectProvider<ServiceInstanceListSupplier> supplier) {
        // 注意这里的 serviceId 必须与你访问的服务名一致
        return new RandomLoadBalancer(supplier.getIfAvailable(), "my-service");
    }
}
```
##### 配置文件配置
```yaml
spring:
  cloud:
    loadbalancer:
      ribbon:
        enabled: false  # 确保禁用 Ribbon
    loadbalancer:
      retry:
        enabled: true
    loadbalancer:
      hint: # 若使用灰度/标签，可扩展
        my-service: version=beta
```
### 3. 注意点
#### feign调用
feign调用实际上是new出一个客户端向远程服务发起请求，但是new出来的requestTemplate（请求模板）对象是只有参数没有请求上下文的请求头的，所以业务中会出现请求头丢失无法通过远程服务拦截器的情况
```java
@Component  
public class FeignRequestInterceptor implements RequestInterceptor {  
    @Override  
    public void apply(RequestTemplate requestTemplate) {  
  
        // 从当前请求上下文获取请求头  
        ServletRequestAttributes attributes =  
                (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();  
  
        //获取浏览器向服务器发送的请求，并获取请求头信息  
        if (attributes != null) {  
            HttpServletRequest request = attributes.getRequest();  
            requestTemplate.header("Cookie",request.getHeader("Cookie"));  
        }  
  
        //配置seata分布式事务的xid，用于分布式事务的传递，全局事务的分支事务需要xid才能注册到TC  
        String xid = RootContext.getXID();  
        requestTemplate.header(RootContext.KEY_XID, xid);  
    }  

```
在feign的代理对象发送request请求之前会过滤一遍RequestInterceptor的apply方法，所以可以通过实现RequestInterceptor接口的apply方法，从上下文中获取请求头设置进requestTemplate对象中
## 三. 服务降级/熔断
### 1. Hystrix（基于信号量隔离）
#### 服务雪崩
一个服务的异常导致整个服务链路的调用失败
#### 服务降级
服务自我保护或保护下游服务的逻辑，一般用于下游服务响应慢、不可用、错误频发等情况，通过降级策略避免系统调用链路雪崩
**针对的是某个服务的接口**
```java
@FeignClient(
    name = "user-service",              // 服务名
    fallback = UserClientFallback.class // 降级处理类
)
public interface UserClient {

    @GetMapping("/user/info")
    String getUserInfo();
}
```
```java
@Component
public class UserClientFallback implements UserClient {

    @Override
    public String getUserInfo() {
        return "【服务降级】用户服务不可用，稍后重试";
    }
}
```
```yml
feign:
  hystrix:
    enabled: true # 开启 Feign 的 Hystrix 降级支持

hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 3000 # 响应的超时时间
```
#### 熔断
防止某个服务频繁调用失败导致系统调用雪崩
针对的是整个服务
```java
@SpringBootApplication
@EnableFeignClients
@EnableCircuitBreaker // 开启 Hystrix 熔断（Spring Cloud Netflix）
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```
默认关闭需要手动打开，如果检测到10秒内请求失败超过50%，就会触发熔断机制，会立即短路调用，不再执行原调用方法，而是执行降级逻辑，每隔5秒会尝试放行一个请求，如果服务仍然不能响应，则继续熔断，否则关闭熔断，恢复正常请求
### 2. sentinel（默认信号量隔离）
#### 限流算法使用（登录控制台设置）
- 默认限流是滑动窗口，用于简单的接口限流或**秒杀活动**、**抢购接口**
- 排队等待模式是漏桶算法
- 热点参数模式是令牌桶算法，用于系统依赖资源需要预热
### 3. 线程隔离和信号量隔离
#### 线程隔离
A服务要调用B和C服务，当请求到达A后A只负责调用B和C，不会在意他们处理业务的能力，A会为每个要调用的服务给一个线程池，如果其中的大部分线程能返回正常结果，A就继续调用，如果不能就会认为这个服务不健康或者宕机，对这个服务进行熔断降级，不会再调用这个服务，这种模式，压力全在被调用者，ABC之间不在同一个线程
支持异步调用，隔离性更强，但是线程开销大
#### 信号量隔离
A会有一个信号量值，每有一个请求过来，都会占据一个信号量，当服务正确返回一个结果就会释放一个信号量，当信号量使用达到上限，A就会拒绝请求或者让请求进行阻塞等待，这种模式压力就在调用者，因为B和C会根据自己的能力处理业务，并返回结果，只有结果返回A才能释放信号量，且信号量达到上限,A会受到大量的请求压力
不用创建线程池，性能较好，但是隔离性一般
## 四. 服务限流
### 1. nginx漏桶算法限流
桶中存储的是请求，不管请求进入的流量是多少，始终按照一定的速率进行处理，如每秒处理5个，未被处理到的请求会在桶里等待，超过容量的请求会被舍弃或等待，处理速度平滑
```nginx
# nginx.config
http {
    # 1. 定义一个名为 one 的限速区域，这种限流配置必须在总配置文件配置
    limit_req_zone $binary_remote_addr zone=one:10m rate=5r/s;
    # 包含所有子配置
    include /etc/nginx/conf.d/*.conf;
}
```
```nginx
# gulimall.conf
	# 随后便可以在gulimall.conf这种针对于服务的反向代理文件里的server里使用one这个限流配置
	# 以下是使用示例
    server {
        listen 80;
        server_name gulimall.com;

		# 路由匹配
        location /api/ {
            # 2. 应用限速规则
            limit_req zone=one burst=10 nodelay;
            proxy_set_header Host $host;
			# 反向代理的服务器ip
            proxy_pass http://gulimall.com;
        }
    }
```
- binary_remote_addr：基于客户端的IP限流
- Zone定义一个共享存储区存储访问信息
- rate：最大访问速率，每秒只处理5个请求
- burst：桶的大小，超过容量之后，多余的请求会等待或直接拒绝
### 2. 网关令牌桶限流
桶中存储的是令牌，以一定速率生成令牌，请求进入时先申请获取令牌才能被处理，速度较为波动，默认使用redis存储令牌
```pom
<!-- Spring Cloud Gateway -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>

<!-- Redis 支持 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis-reactive</artifactId>
</dependency>
```
```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: user-api
          uri: http://localhost:8081 # 或注册中心的服务名称
          predicates:
            - Path=/api/user/**
          filters:
            - name: RequestRateLimiter
              args:
                key-resolver: '#{@ipKeyResolver}'  # 按请求来源的IP限流（自定义 Bean）
                redis-rate-limiter.replenishRate: 5  # 每秒填充5个令牌
                redis-rate-limiter.burstCapacity: 10 # 桶最大容量10个令牌
```
```java
@Configuration
public class RateLimiterConfig {
    @Bean
    public KeyResolver ipKeyResolver() {
        return exchange -> {
            String ip = exchange.getRequest()
                                 .getHeaders()
                                 .getFirst("X-Forwarded-For");
            if (ip == null) {
                ip = exchange.getRequest().getRemoteAddress().getAddress().getHostAddress();
            }
            return Mono.just(ip);
        };
    }
}
```
### 3. 固定窗口计数器
- 把时间切成固定大小的窗口（例如：1 秒 / 1 分钟）。
- 每个窗口内维护一个计数器，记录请求数。
- 当窗口内的请求数 > 阈值 → **拒绝**。
- 窗口结束时，计数器清零，进入下一个时间窗口。
- 问题是在一个窗口快要结束的时候进入一些请求被放行，在下一个窗口刚开始的时候也进入了一些请求，两个请求进入的时间点虽然在不同的窗口，但两个时间点之间也可以看作是一个窗口，虽然合法但是会造成双倍放行的问题
### 4. 滑动窗口计数器
- 不是简单地“固定时间块”，而是 **将一个大窗口拆成多个小区间**。
- 窗口根据当前请求的时间点移动，范围从当前请求的时间点减去窗口时间跨度得到的时间点的**下一个区间到当前请求所处的区间**
- 这样可以平滑边界，避免突刺。
## 五. 服务安全校验
### 客户端配置
```pom
客户端依赖导入
<!-- Spring Security -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
</dependency>

<!-- Spring Security OAuth2 Client -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-client</artifactId>
</dependency>

<!-- Spring Cloud OpenFeign -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```
```java
//客户端注册
@Configuration
public class AuthorizationServerConfig {

    @Bean
    public RegisteredClientRepository registeredClientRepository() {
        RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString())
            .clientId("product-service")                          // 客户端ID
            .clientSecret("{noop}s3cr3tK3y!")                    // 客户端密钥，{noop}表示不编码
            .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS) // 授权模式
            .scope("read")                                        // 授权范围
            .build();

        // 这里使用内存存储，也可以用数据库存储
        return new InMemoryRegisteredClientRepository(registeredClient);
    }
}
```
```yaml
配置文件配置客户端信息
spring:
  security:
    oauth2:
      client:
        registration:
          product-service:
            client-id: product-service
            client-secret: s3cr3tK3y!
            authorization-grant-type: client_credentials
            scope: read
            provider: auth-server 
        provider:
          auth-server:
            token-uri: http://localhost:9000/oauth2/token


```
```java
//配置OAuth2AccessTokenInterceptor，向请求头中添加token的过滤器
@Configuration
public class FeignOAuth2Config {

	@Bean
    public OAuth2AuthorizedClientManager authorizedClientManager(
            ClientRegistrationRepository registrations,
            OAuth2AuthorizedClientRepository clients) {

        OAuth2AuthorizedClientProvider provider =
                OAuth2AuthorizedClientProviderBuilder.builder()
                        .clientCredentials()
                        .build();

        DefaultOAuth2AuthorizedClientManager manager =
                new DefaultOAuth2AuthorizedClientManager(registrations, clients);

        manager.setAuthorizedClientProvider(provider);

        return manager;
    }
}

    @Bean
    public RequestInterceptor oauth2FeignRequestInterceptor(
            OAuth2AuthorizedClientManager authorizedClientManager) {
        return new OAuth2AccessTokenInterceptor(authorizedClientManager);
    }
}
```
### 认证服务器搭建
```pom
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.security</groupId>
    <artifactId>spring-security-oauth2-authorization-server</artifactId>
    <version>1.1.0</version> <!-- 请确认最新版本 -->
</dependency>

<dependency>
    <groupId>org.springframework.security</groupId>
    <artifactId>spring-security-oauth2-jose</artifactId>
</dependency>
```
```java
//拦截规则
@Configuration
public class ResourceServerSecurityConfig {

    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http
            .authorizeHttpRequests(authorize -> authorize
                .requestMatchers("/public/**").permitAll() // 不拦截
                .anyRequest().authenticated()              // 其他都需要带 token
            )
            .oauth2ResourceServer(oauth2 -> oauth2.jwt()); // 指定用 JWT 方式认证

        return http.build();
    }
}
```
```java
@Configuration
public class AuthorizationServerConfig {

    @Bean
    public RegisteredClientRepository registeredClientRepository() {
        RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString())
                .clientId("product-service")
                .clientSecret("{noop}s3cr3tK3y!")
                .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS)
                .scope("read")
                .tokenSettings(TokenSettings.builder()
                    .accessTokenTimeToLive(Duration.ofHours(1))
                    .build())
                .build();

        return new InMemoryRegisteredClientRepository(registeredClient);
    }

    @Bean
    public SecurityFilterChain authorizationServerSecurityFilterChain(HttpSecurity http) throws Exception {
        OAuth2AuthorizationServerConfiguration.applyDefaultSecurity(http);
        return http.formLogin().and().build();
    }

    // 生成RSA密钥对（用于签发JWT）
    @Bean
    public KeyPair keyPair() {
        try {
            KeyPairGenerator generator = KeyPairGenerator.getInstance("RSA");
            generator.initialize(2048);
            return generator.generateKeyPair();
        } catch (Exception e) {
            throw new IllegalStateException(e);
        }
    }

    // JWT 编码器
	@Bean
	public JWKSource<SecurityContext> jwkSource(KeyPair keyPair) {
	    RSAKey rsaKey = new RSAKey.Builder((RSAPublicKey) keyPair.getPublic())
	            .privateKey(keyPair.getPrivate())
	            .keyID(UUID.randomUUID().toString())
	            .build();
	    JWKSet jwkSet = new JWKSet(rsaKey);
	    return (jwkSelector, securityContext) -> jwkSelector.select(jwkSet);
	}

	@Bean
	public JwtEncoder jwtEncoder(JWKSource<SecurityContext> jwkSource) {
	    return new NimbusJwtEncoder(jwkSource);
	}

    // JWT 解码器（资源服务器用）
    @Bean
    public JwtDecoder jwtDecoder(KeyPair keyPair) {
        return NimbusJwtDecoder.withPublicKey((RSAPublicKey) keyPair.getPublic()).build();
    }

    @Bean
    public ProviderSettings providerSettings() {
        return ProviderSettings.builder()
                .issuer("http://localhost:9000")  // 你的认证服务器地址
                .build();
    }
}
```
```yml
spring:
  security:
    oauth2:
      resourceserver:
        jwt:
          jwk-set-uri: http://localhost:9000/oauth2/jwks
```
## 六. CAP和BASE
### CAP
- 分布式系统节点通过网络进行连接，由于网络问题一定会出现分区问题（P）
- 当分区出现，系统的一致性（C）和可用性（A）就无法同时满足
### BASE
- 基本可用
- 软状态
- 最终一致：各分支事务完成之后进行提交，如果有不一致的情况，再想办法恢复数据，存在中间状态，占用资源少，可用性高
- 强一致：各分支事务完成后先不进行提交，彼此等待执行结果，然后统一进行提交或回滚，不存在中间状态，占用资源多，一致性强，可用性差
## 七. 分布式事务
### 1. seate
#### 组成
```txt
+------------------+            +------------------+            +------------------+
|                  |            |                  |            |                  |
|       TM         |  ——Begin→  |       TC         |  ——Reg→    |       RM         |
| (事务发起者)      |             | (事务协调者)     |             |  (资源操作员)    |
|                  |  ←Result—— |                  |  ←Branch—  |                  |
+------------------+            +------------------+            +------------------+
         |                            ↑      ↑                         ↑
         |                            |      |                         |
         |——commit()/rollback()——→    |      |——→ prepare/commit/rollback()
```

| 组件                               | 所属         | 作用                                                                                                                   |
| -------------------------------- | ---------- | -------------------------------------------------------------------------------------------------------------------- |
| **TM（Transaction Manager）**      | 客户端        | 管理全局事务的生命周期，决定事务总体的开启、提交、回滚                                                                                          |
| **RM（Resource Manager）**         | 客户端        | 管理本地资源（数据库、消息等），向 TC 注册分支事务                                                                                          |
| **TC（Transaction Coordinator）**  | 服务端        | 协调、监控和维护全局事务状态，调度分支提交/回滚                                                                                             |
| **`xid`（Global Transaction ID）** | 由TM生成，TC派发 | 在整个分布式事务中被传播（例如通过 **RPC 请求头、Feign请求头、ThreadLocal、数据源代理**等方式）。所有参与者（RM 资源管理器）汇报分支事务时，都会带上这个 `xid`，这样 TC 就知道他们属于哪个全局事务 |
#### 执行流程
**1. TM 开启全局事务**
- `@GlobalTransactional` 标记的方法执行时，TM 会先向 TC 发送 `Begin` 请求。
- TC 分配一个 **全局事务 XID** 并返回给 TM。
- TM 把这个 XID 绑定到当前线程的上下文（`RootContext.bind(xid)`），保证后续 SQL 操作或 RPC 调用都能取到这个 XID。
**2. XID 的传播**
- 在调用下游服务时（比如 Feign、Dubbo），上游需要把 XID 放到 **请求头**或者 **RPC 元数据**里。
- 下游服务收到请求后，Seata 的拦截器会自动执行 `RootContext.bind(xid)`，让本地 RM 感知到事务上下文。
**3. 分支事务注册**
- 下游服务在执行 SQL 前，RM 会先向 TC 注册 **分支事务**（带上 XID）。
- 注册成功后，RM 才开始真正执行本地 SQL。
- **AT 模式下：**
    - RM 在执行 SQL 前会记录 **前镜像（before image）**。
    - SQL 执行完，再记录 **后镜像（after image）**。
    - 把镜像数据写入 `undo_log` 表，方便未来回滚。
- 如果是 **TCC 模式**，就会执行 `try` 方法来预留资源。

**4. TM 汇报事务状态**
- 当 `@GlobalTransactional` 方法执行完，TM 会根据结果调用：
    - 成功：`TC.commit(XID)`
    - 异常：`TC.rollback(XID)`
 **5. TC 统一调度**
- **全局提交**：TC 通知所有分支事务提交，本地分支释放资源。
- **全局回滚**：
    - TC 通知所有分支事务执行回滚。
    - AT 模式下，RM 会根据 `undo_log` 的前后镜像数据恢复原始状态。
    - TCC 模式下，会调用 `cancel` 方法。
#### 事务级别
##### XA（强一致性）
- RM中执行完业务sql先不进行提交
- 等待各个分支事务完成之后，将执行状态统一报告给TC，TC检查各分支事务的执行状态全部成功通知RM提交事务，如果有失败则通知RM全部回滚
- 因为要两阶段都持有数据库锁，长事务会阻塞严重
##### AT（最终一致）
- 各个RM执行完直接提交
- 会记录执行前后的undo_log数据快照，即SQL语句中相关字段的数据快照，并保存在本地数据库的undo_log表中
- 之后将执行状态报告TC，TC检查执行状态，全部成功则删除RM的undo_log
- 如果有失败，TC通知RM回滚，RM会对比当前数据库和执行后快照的数据是否一致，如果一致说明执行后还没有人改过，就用执行前的数据快照恢复，如果不一致就需要人工修复
- 同时为了防止不同的RM修改同一行或几行的数据造成冲突，RM 执行业务 SQL 前，必须先向 TC 注册分支事务并尝试加锁（排他锁），TC的branch_table.lock_key字段会记录SQL中涉及到的行，如果其他RM执行的SQL涉及到了branch_table.lock_key记录的字段则会自旋循环尝试获取，超过等待事件后会等待的RM直接回滚
##### TCC
需要手动在代码层面实现try、confirm、cancel方法，代码侵入高，耦合度高
1. try：先进行资源的检测和预留，RM向TC报告预留状态
2. Confirm/Cancel：如果全部成功，则真正执行业务并提交，如果有失败则释放锁定的资源
#### 事务表
##### global_table
- 记录全局事务信息：
    - `xid`（全局事务 ID）
    - `status`（事务状态：begin、committing、rollbacking 等）
    - `application_id` / `transaction_service_group`（发起应用信息）
    - `timeout` 等
- **写入时机**：
    - TM 开启全局事务 → 向 TC 申请 xid → **TC 在 `global_table` 插入一条记录**。
- **删除时机**：
    - 全局事务 commit 或 rollback 完成后 → **TC 删除该记录**（可能是立即删，也可能由后台定时清理任务异步清理）
##### branch_table
- 记录分支事务（RM 的资源操作），主要字段：
    - `branch_id`
    - `xid`（所属全局事务）
    - `resource_id`（数据源）
    - `status`
    - `client_id`
    - `lock_key`（资源锁定的行）
- **写入时机**：
    - RM 执行分支事务前 → 向 TC 注册分支 → **TC 在 `branch_table` 插入记录**。
- **删除时机**：
    - 分支事务提交/回滚完成后 → **TC 删除对应记录**。
#### 局限性
- 只适用于关系型数据库，不适用于redis这类非关系型，因为要靠全局和分支事务表来控制回滚和提交
- 跨库事务性能损耗大，适合短事务，不适合大事务 / 长事务。
## 八. 接口幂等性
### 1. 数据库添加唯一索引
### 2. token+redis
```java
String script = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";  
Long execute = redisTemplate.execute(new DefaultRedisScript<>(script, Long.class), Arrays.asList(OrderConstant.ORDER_TOKEN_PREFIX + userInfo.getId()),orderToken);
```
在生成订单页面同时生成一个唯一token保存在redis中，并将这个token连带订单页面信息一同返回给前端，当前端提交订单时会将这个token带上，之后使用lua脚本判断是否存在这个token并删除（保证原子性，防止并发状况导致多次提交），如果成功则执行业务，否则说明已经处理过了直接返回，解决订单防刷和网络波动等问题
### 3. 分布式锁
## 九. xxl-job
### 1. 路由规则
- 轮询
- 故障转移：依次检测心跳，如果心跳正常，则选择当前实例执行
- 分片广播：广播所有实例执行一次任务，按照任务数对实例数取模运算分配任务
### 2. 任务执行失败
- 路由策略选择故障转移，让健康的实例执行任务
- 设置任务重试次数
- 查看日志+邮件通知
### 3. 大数据量任务执行
部署多个实例，路由选择分片广播
# 消息中间件
## 一. RabbitMQ
### 1. 消息不丢失
```txt
  [Producer]
      |
      | 发送消息 (publish)
      v
  +-----------+
  |  Broker   |
  | (RabbitMQ)|
  +-----------+
      |
      |  路由消息
      v
  +-----------+
  | Exchange  |<-- 交换机（Direct/Topic/Fanout/Headers）
  +-----------+
      |
      | 根据绑定规则 (Binding)
      v
  +-----------+
  |   Queue   |<-- 消息队列
  +-----------+
      |
      | 消费消息 (consume)
      v
  [Consumer]
```
投递消息到消费消息过程中都有可能丢失消息
```yaml
rabbitmq:  
  host: 192.168.88.101  
  port: 5672  
  virtual-host: /  
  username: guest  
  password: guest  
  publisher-confirm-type: correlated # 发送者启用confirm模式  
  publisher-returns: true # 启用returnCallback  
  listener:  
    simple:  
      acknowledge-mode: manual # 手动ack  
      auto-startup: true  
      retry:  
        enabled: true # 开启重试机制  
        max-attempts: 3 # 最大重试次数  如果仍然接收不到消息则投递到异常队列
  template:  
    mandatory: true # 强制指定消息发送成功
```
配置发送者confirm消息投递到broker，returnCallback由exchange路由到queue的回调函数
```java
@Configuration  
@Slf4j  
public class PublisherCallback {  
  
    @Autowired  
    private RabbitTemplate rabbitTemplate;  
  
    @PostConstruct
    public void init() {  
        rabbitTemplate.setMandatory(true); // ❗确保 returnCallback 被触发  
  
        //消息投递到Broker的回调函数，confirmCallback  
        //ack表示是否成功，cause包含失败原因  
        rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -> {  
            if (ack) {  
                log.info("消息发送成功,correlationData[{}]", correlationData);  
            } else {  
                log.error("消息发送失败,correlationData[{}],cause[{}]", correlationData, cause);  
            }  
        });  
  
        //消息没有成功由交换机路由到队列的回调函数，returnCallback  
         rabbitTemplate.setReturnsCallback(returnedMessage -> {  
            log.error("消息没有路由到队列,returnedMessage[{}]", returnedMessage);  
        });  
    }  
}
```
消费者手动确认消息是否被消费
```java
//Ack确认消息被消费
channel.basicAck((Long) message.getHeaders().get("amqp_deliveryTag"), false);
//Nack消费失败
channel.basicNack(  
        (Long) message.getHeaders().get("amqp_deliveryTag"),  //消息的唯一标识
        false,  //是否批量拒绝，如果为true，则会一次性拒绝deliveryTag小于等于传入值的消息；如果为false，则只拒绝传入值的消息。
        true/false//是否重新入队
);
```
持久化交换机、队列和消息,消息默认存储在内存中，需要在创建消息的时候将其设置为持久化
```java
@Configuration  
public class MQConfig {  
  
    public Queue orderSeckillOrderQueue() {  
        return new Queue("order.seckill.order.queue", true, false, false);  
    }  
    @Bean  
    public Exchange orderEventExchange() {  
        return new TopicExchange("order-event-exchange", true, false, null);  
    }  
    @Bean  
    public Binding OrderSeckillOrderBinding() {  
        return new Binding("order.seckill.order.queue", Binding.DestinationType.QUEUE, "order-event-exchange", "order.seckill.order", null);  
    }  
}
```
```java
public static Message generateMessage(RabbitTemplate rabbitTemplate, Object messageBody) {  
    MessageProperties messageProperties = new MessageProperties();  
    //设置消息的属性  
    //设置消息的id，此id用于将消息保存到redis中，检查幂等性  
    messageProperties.setMessageId(UUID.randomUUID().toString());  
    //设置消息持久化，保证rabbitmq重启后消息不丢失  
    messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT);  
    return rabbitTemplate.getMessageConverter().toMessage(messageBody, messageProperties);  
}
```
### 2. 消息重复消费
发送消息时，为每条消息设置唯一的id，并存储在redis中，消费者校验id是否存在，如果存在则已经消费，否则没有消费或其他监听者消费失败
### 3. 延迟队列
ttl+死信交换机，把消息投递给交换机，由这个交换机根据路由键把消息路由给死信队列，但是这个死信队列没有监听者消费，超时之后会将消息投递给死信交换机，由死信交换机根据死信路由键把消息路由给另一个和死信交换机绑定的队列
```java
@Bean  
public Queue orderDelayQueue() {  
    Map<String, Object> arguments = new HashMap<>();  
    arguments.put("x-dead-letter-exchange", "order-event-exchange");//死信交换机  
    arguments.put("x-dead-letter-routing-key", "order.release.order");//死信路由键，注意它的意思是死信交给死信交换机前死信的路由键就会变成这个，它必须是和死信交换机绑定的队列的路由键一样  
    arguments.put("x-message-ttl", 1800000);//消息存活时间，单位毫秒，这里是30分钟  
    return new Queue("order.delay.queue", true, false, false, arguments);  
}
@Bean  
public Queue orderReleaseOrderQueue() {  
    return new Queue("order.release.order.queue", true, false, false);  
}
@Bean  
public Binding OrderCreateOrderBinding() {  
    return new Binding("order.delay.queue", Binding.DestinationType.QUEUE, "order-event-exchange", "order.create.order", null);  
}
@Bean  
public Binding OrderReleaseOrderBinding() {  
    return new Binding("order.release.order.queue", Binding.DestinationType.QUEUE, "order-event-exchange", "order.release.order", null);  
}
```
### 4. 消息堆积
- 增加更多消费者去消费
- 在消费者内部开启线程池加快处理速度
- 增加队列容积，采用惰性队列（消息存储在磁盘中）
### 5. 高可用
#### 普通集群
```txt
  ┌────────┐      ┌────────┐      ┌────────┐
  │ Node A │<---->│ Node B │<---->│ Node C │
  └────────┘      └────────┘      └────────┘
```
每个节点共享交换机信息和部分队列信息，队列绑定在哪个节点数据就存储在哪个节点，其他节点只有这个队列的引用信息，当客户端访问的节点没有对应队列的数据时，队列所在节点会把数据发给当前节点返回给客户端
#### 镜像集群
```txt
          (同步复制机制)
        ┌─────────────────────┐
        │                     │
  ┌────────┐   ┌────────┐   ┌────────┐
  │ Node A │<->│ Node B │<->│ Node C │
  └────────┘   └────────┘   └────────┘
      ▲             ▲             ▲
      │             │             │
     主队列       镜像副本     镜像副本
    （Master）   （Slave）     （Slave）
```
队列数据自动同步到其他镜像节点，当主节点宕机副本自动成为新的master，高可用，但同步数据开销大，性能下降
#### 仲裁模式
```txt
    (使用 Raft 协议强一致复制)
        ┌────────┐
        │Client  │
        └───┬────┘
            │
        ┌───▼────┐
        │ Leader │  ←  写操作、投票主节点
        └───┬────┘
     ┌──────┴──────┐
     ▼             ▼
┌────────┐     ┌────────┐
│Follower│     │Follower│
└────────┘     └────────┘
```
主从同步采用raft协议、强一致，使用简单

| 模式          | 数据副本 | 容灾能力 | 性能  | 官方推荐 | 备注            |
| ----------- | ---- | ---- | --- | ---- | ------------- |
| 普通集群        | 无    | 差    | 高   | ❌    | 队列挂在哪个节点算谁的   |
| 镜像队列集群      | 手动配置 | 高    | 中-低 | ⚠️弃用 | 同步成本高、复杂      |
| Quorum 队列集群 | 自动控制 | 高    | 中   | ✅推荐  | Raft强一致，适合新项目 |
## 二. kafka
### 1. 集群关系
```txt
+------------------------- Kafka 集群 -------------------------+
|                                                               |
|   +------------+      +------------+      +------------+      |
|   |  Broker 1  |      |  Broker 2  | ...  |  Broker N  |      |
|   +-----+------+      +-----+------+      +-----+------+      |
|         |                   |                   |             |
|         |                   |                   |             |
|         +-------------------+-------------------+             |
|                  每个 Broker 管理多个分区（Partition）         |
|                                                               |
|                 Topic A (多分区)                              |
|                 +-------------------------------+             |
|                 | Partition 0  (Leader @ Broker1)|             |
|                 | Partition 1  (Leader @ Broker3)|             |
|                 | Partition 2  (Leader @ Broker2)|             |
|                 +-------------------------------+             |
|                                                               |
|                 Topic B (多分区)                              |
|                 +-------------------------------+             |
|                 | Partition 0  (Leader @ Broker2)|             |
|                 | Partition 1  (Leader @ Broker1)|             |
|                 +-------------------------------+             |
|                                                               |
+---------------------------------------------------------------+
```
- **Broker**
    - Kafka 集群中的服务器节点。
    - 每个 Broker 负责管理它所拥有的 Partition 的数据和请求。
    - Broker 之间协作，形成分布式存储和处理能力。
- **Topic**
    - Kafka 消息的逻辑分类，并不是真正的物理结构。
    - 一个 Topic 可以有多个 Partition，Partition 数量在 Topic 创建时定义。
    - 生产者发送的消息属于某个 Topic，消费者订阅某个 Topic。
- **Partition（分区）**
    - Topic 的物理拆分单元，每个Partition存储不同的消息，但都属于同一topic。
    - 每个 Partition 是一个有序的消息队列。
    - 每个Partition有多个副本，每个副本存储在不同的broker上
    - Partition 的副本有且只有一个 **Leader**副本，负责处理所有读写请求。
    - 其他 Broker 上的副本叫 **Follower**，用于备份和容错。
    - Partition 是 Kafka 实现高吞吐和扩展性的关键。
### 2. 生产者发送消息
```txt
[调用线程（用户线程）]
    |
    | 1. 生产者 API 发送消息（send()）
    |    → 消息封装成 ProducerRecord
    v
[RecordAccumulator 缓存区]
    |
    | 2. 写入对应 Topic-Partition 的缓冲区（内存队列）
    |    → 对消息做批量处理（Batch）
    v
[Sender 线程]
    |
    | 3. 定时(默认0ms)或达到阈值(16k)时，Sender 从 RecordAccumulator 拉取批次数据
    |    → 批量打包成请求（ProduceRequest）
    |    → 选择 Partition Leader 对应的 Broker 节点
    v
[网络请求]
    |
    | 4. 发送 ProduceRequest 到 Broker Partition Leader
    |    → 等待 Broker 响应（ACK）
    v
[Broker Partition Leader]
    |
    | 5. 写入磁盘，进行副本同步（如果启用副本）
    |    → 返回写入确认（三个等级：0，不需要回应、1，leader收到后就可以回应、-1，leader和     |        follower都收到后才回应）
    v
[网络响应]
    |
    | 6. Sender 接收到 ACK
    |    → 更新发送状态，唤醒等待的调用线程
    v
[调用线程]
    |
    | 7. send() 返回 Future，成功/失败通知
```
#### 分区策略
- 如果send方法指定了分区就向这个分区发送
- 如果没有指定分区，但是指定了key，按照key的hash值对分区数取模
- 如果都没指定，采用粘性分区器，随机选择一个分区发送，直到这个分区的batch满了或者linger时间到了，再重新随机选择一个分区
### 3. 生产者提高吞吐量

- 每个批次batch满了之后sender线程才会把消息发送到broker
- 等待linger时间之后才发生消息
- 这两种方式，消息从生成者发送到broker都有延迟不能实时发送，但是提高了资源的吞吐，避免io资源的浪费
- 除此之外还可以提高缓冲区大小、将消息压缩发送
- 以上都可以在构建kafka客户端的时候指定
### 4. 数据可靠
- broker应答ack策略分三种
- 0，不进行ack，sender线程持续发送，如果leader宕机，新的leader还未选出，但仍然数据在发送，就会丢失大量数据
- 1，leader接收到消息就ack，如果leader进行ack之后，数据还未同步完成，leader节点宕机，会丢失数据
- -1，leader和所有follower都收到消息再ack，如果有一个follower宕机迟迟无法和leader同步，不能及时ack，会降低可用性
- 对于-1这种策略，如果有一个follower宕机迟迟无法和leader同步，则会被退出存活副本集合队列，这个follower的响应时间阈值可以通过参数设置
- 相同<PID, Partition, `SeqNumber` >主键的消息多次提交时，broker只会持久化一次,PID对于每次kafka重启都会重新分配一个，Partition是分区号，SeqNumber是序列号，单调递增，保证单分区但会话内消息不重复
- 生产者事务：会通过生成全局唯一的 `transactional.id` 与集群的事务协调器建立事务上下文。事务协调器将事务状态（而不是消息本身）持久化到内部主题 `__transaction_state`。当生产者提交事务时，协调器会向所有涉及的分区写入 Commit Marker；如果事务中止，则写入 Abort Marker。消费者在 `read_committed` 模式下会过滤掉未提交事务的消息，从而实现逻辑上的“回滚”
### 5. 数据乱序
- broker会缓存生产者最近发生的5条数据，如果发送过来的消息的序列号是严格递增的则写入磁盘，如果不是就将其放入缓存区，直到等到正确序列号的数据发送过来，再将缓存区内的消息根据序列号进行排序
### 6. 集群选主策略
| 类型                | 作用                                                                   |
| ----------------- | -------------------------------------------------------------------- |
| **Controller 选举** | 在所有 Broker 中选出一个 Controller 节点，负责集群管理（包括分区 Leader 的选举、Topic 元数据管理等）。 |
| **分区 Leader 选举**  | 对于某个 Topic 的每个分区，在它的副本中选出一个 Leader 来负责处理该分区的读写请求。                    |
1. 所有 Kafka Broker 启动时，会尝试成为 Controller（即集群管理节点）。
2. 通过 Raft 协议（基于 term + quorum 机制）在候选者中选出一个 Leader Controller。
3. 当某个 Controller 挂掉时，其他 Broker 会感知到（Raft 心跳超时），触发重新选举。
4. 新的 Controller 上任后，会从元数据日志中恢复集群状态，并通知其他 Broker。
5. 集群中只有一个leadercontroller，但是它不一定是所有分区的leader副本
6. Controller 通过心跳检测到 Broker1 不可用。
7. Controller 查该分区的 ISR（In-Sync Replica，同步副本列表）。
8. 以ISR中存活的broker为前提，从 AR（所有副本的统称） 中按顺序选出一个新的 Leader（比如 Broker2）。
9. 更新元数据并广播给集群中所有 Broker。
10. Producer/Consumer 会根据新的 Leader 元数据重新连接到 Broker2。
### 7. 故障恢复
LED：每个副本最后一个offset+1，每个副本独自拥有一个
HW：分区内所有副本中最小的LED
- 当某个follower副本宕机之后，会先将其从isr队列中剔除，并记录当时的HW
- 当它恢复之后，会把当时保存的HW的位置往后的数据删除，之后和leader同步数据，直到自己的LED的位置到达当前HW的位置
- 当leader副本宕机之后，会通过controller节点选举出新的leader，之后其余的follower会将超过新的leader的LED位置的数据全部删除
### 8. 文件存储
- 每个分区对应一个log文件，这个文件存储的就是生产者发送的数据，生产者发送的数据**会追加写入log文件末尾**，在磁盘上是顺序存储，读写效率更快
- 为防止log文件过大，kafka采取分片加索引的机制
- 将每个分区的log文件拆分成多个segment，每个segment包括.index索引文件、.log数据文件、.timeindex时间戳文件（数据保存的时间，时间一到将数据删除），这些文件由所属的segment的第一条的数据的offset命名，每个segment文件夹以topic+分区编号命名
- 每个segment文件的大小1G
- index文件存储稀疏索引，每向.log文件存储4kb数据，会向.index文件写入一条索引
- 当要寻找某个offset的数据时，会先定位到具体的segment的.index文件，由于每4kb存储一条索引，所以index文件里的索引数据之间是一个范围，当找到具体的范围之后，再根据范围到log数据文件中寻找
### 9. 文件清除
#### delete策略
根据segment文件夹中的timeindex文件的时间限制，以该segment中最大的时间戳作为该文件的时间戳，以一定的频率检查时间戳，如果时间到了，就会将整个segment的数据删除
#### 压缩策略
将.log数据文件中相同key中最新的数据进行保留，其余删除
### 10. 高效读写
- log数据文件的数据是顺序写入到末尾，在磁盘上是顺序存储的，顺序读写的效率比随机的更快
- 读数据采用稀疏索引，可以快速定位到数据
- kafka依赖操作系统底层的页缓存机制，当应用层有写操作时，会将数据直接写入页缓存，之后由操作系统异步刷盘，当需要读数据时，先从页缓存里面找，页缓存里面没有去磁盘里面找，找到之后直接通过网卡发送给消费者，不经过用户空间
### 11. 消费方式
- 消费者采用**主动拉取**的方式消费消息
- **消费者组内每个消费者负责消费不同分区的数据**，防止重复消费
- 每个消费者的offset由消费者提交到系统的主题进行保存
- 消费者组之间不受影响
- 消费者组初始化时，会用这个组的groupId的hashCode对分区数取模，在那个分区上，就由这个分区的broker的coordinator管理这个消费者组，这个组的消费者的offset也由这个coordinator通过__consumer_offsets 系统主题进行存储，consumer_offsets里面以key和value的形式存储，key是groupId+topic+分区号，value是当前的offset
- 之后这个组的消费者向这个coordinator发送加入组的请求，coordinator会从中选出一个leader，由这个leader指定消费计划发送给coordinator，coordinator把计划下发给各个消费者
- 每个消费者都会和coordinator保持心跳（5s周期），一旦超时（45s），该消费者就会被移出，并触发再平衡，如果消费者处理的时间过长（5mine）也会被移出，并触发再平衡
### 12. 消费流程
- 消费者创建客户端
- Fetcher 线程会向分配给自己的分区所在的 Broker Leader 发送 **Fetch 请求**。
- Broker 返回一个批次（Batch）的消息，批次的大小受单次拉取的最大最小字节数和最大消息条数决定
- 消息先进入 **本地缓冲队列（`ConsumerRecords`）**。
- 主线程从缓冲队列里取消息，进行反序列化和拦截器后交给应用逻辑处理
- 拉取到数据并返回后，定时提交最新 Offset 到 Broker 的 **__consumer_offsets** 主题，这个提交是自动的，时间可以配置，由于记录的offset和实际消费到的offset有差异，可能会导致消费者宕机重启后，重新开始消费的offset已经消费过了，出现重复消费
- 也可以手动提交，分为同步提交，和异步提交。同步提交会阻塞线程直到提交成功，成功之后才会继续消费，如果失败会进行重试，异步提交不会阻塞，但是失败后不会重试
### 13. 消费者组分组分区策略
| 策略                     | 分配逻辑                   | 示例（Topic T1 5个分区，消费者 C1、C2）                                      | 均衡性      | 稳定性 | 适用场景               |
| ---------------------- | ---------------------- | ---------------------------------------------------------------- | -------- | --- | ------------------ |
| **Range**              | 按 Topic 顺序分区编号连续分配给消费者 | C1 → P0, P1, P2C2 → P3, P4                                       | 中等（可能不均） | 低   | 单 Topic，要求分区顺序消费   |
| **RoundRobin**         | 所有分区放一起，轮流分配           | C1 → P0, P2, P4C2 → P1, P3                                       | 高        | 低   | 多 Topic，多分区均衡消费    |
| **Sticky**             | 尽量保持原分配不变，最小化改动后均衡分配   | 原分配：C1→P0, P1, C2→P2, P3, P4加 C3 后 → C1→P0, C2→P2, P3, C3→P1, P4 | 高        | 高   | 减少 rebalance 影响的业务 |
| **Cooperative Sticky** | 渐进式迁移分区，逐步完成 Rebalance | 类似 Sticky，但一次只迁移部分分区，其他保留                                        | 高        | 最高  | 对延迟/可用性敏感的生产环境     |
### 14. 消费者事务
- 对于自动提交offset的方式，由于记录的offset（以一定时间周期提交）和实际消费到的offset有差异，可能会导致消费者宕机重启后，重新开始消费的offset已经消费过了，出现重复消费
- 对于手动提交的方式，如果在业务处理完成之前提交，业务逻辑出现异常或者消费者宕机，重新消费的位置无法从失败的offset开始，导致漏消费
### 15. 消费者提高吞吐量
- 提高topic的分区数和消费者的数量
- 提高每批次拉取数据的大小参数


# 基础
## 一. 常见集合
### 1. 数组
#### 为什么索引下标从0开始
通过索引访问元素实际上是通过 **数组首地址+索引 * 数组数据类型长度** 得到的，如果下标从1开始，索引要额外进行减1运算，增加了cpu的运算
#### 插入/修改/删除
都是O( n )复杂度
### 2. ArrayList
#### 成员属性、构造函数、add方法
```java
//默认的初始化容量
private static final int DEFAULT_CAPACITY = 10;  

//两个容量是0的缓冲区，用来区分有参和无参创建出的list集合，在首次扩容时会有区别
private static final Object[] EMPTY_ELEMENTDATA = {}; 

private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};  

//短暂性存储数据的数组，在扩容时是直接进行数组拷贝+替换，地址会改变
transient Object[] elementData;

//元素个数并非容量
private int size;

//有参构造器，创建一个指定容量的list，如果参数是0，直接将EMPTY_ELEMENTDATA成员变量
//赋给elementData
public ArrayList(int initialCapacity) {  
    if (initialCapacity > 0) {  
        this.elementData = new Object[initialCapacity];  
    } else if (initialCapacity == 0) {  
        this.elementData = EMPTY_ELEMENTDATA;  
    } else {  
        throw new IllegalArgumentException("Illegal Capacity: "+  
                                           initialCapacity);  
    }  
}  

//无参构造，直接将DEFAULTCAPACITY_EMPTY_ELEMENTDATA赋给elementData
public ArrayList() {  
    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;  
}  

//接收collection参数，将其直接赋给elementData，或将其元素拷贝+替换给elementData
public ArrayList(Collection<? extends E> c) {  
    Object[] a = c.toArray();  
    if ((size = a.length) != 0) {  
        if (c.getClass() == ArrayList.class) {  
            elementData = a;  
        } else {  
            elementData = Arrays.copyOf(a, size, Object[].class);  
        }  
    } else {  
        // 如果参数长度为0，则为 EMPTY_ELEMENTDATA
        elementData = EMPTY_ELEMENTDATA;  
    }  
}
```

| 字段名                                 | 含义             | 用途                                                                 |
| ----------------------------------- | -------------- | ------------------------------------------------------------------ |
| `EMPTY_ELEMENTDATA`                 | 真正的空数组         | 通过 `new ArrayList(0)` 创建时用它，表示**容量就是 0**                           |
| `DEFAULTCAPACITY_EMPTY_ELEMENTDATA` | 空数组，占位用，懒初始化时用 | 通过 `new ArrayList()` 创建时用它，表示**初始容量为默认值（10），但尚未分配** ，在首次添加元素之后分配空间 |

```java
public boolean add(E e) {  
    modCount++;  
    add(e, elementData, size);  
    return true;  
}
private void add(E e, Object[] elementData, int s) {  
    if (s == elementData.length)  
        elementData = grow();  
    elementData[s] = e;  
    size = s + 1;  
}
private Object[] grow() {  
    return grow(size + 1);  
}
private Object[] grow(int minCapacity) {  
    int oldCapacity = elementData.length;  
    if (oldCapacity > 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {  
        int newCapacity = ArraysSupport.newLength(oldCapacity,  
                minCapacity - oldCapacity, /* minimum growth */  
                oldCapacity >> 1           /* preferred growth */);  
                //拷贝并替换
        return elementData = Arrays.copyOf(elementData, newCapacity);  
    } else {  
    //如果是`DEFAULTCAPACITY_EMPTY_ELEMENTDATA`且首次添加，则直接扩容到10
        return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)];  
    }  
}
```
当所需最小容量超过当前容量时，触发扩容，比较 **当前容量 * 1.5和所需最小容量，取较大值** 成为新elementData的长度，且将原来的元素copy成新的数组并替换原来的
但是通过 **new ArrayList()** 创建的list **初始默认容量是10**，但实际上还没有真正分配空间，实际大小是0，在首次添加元素时，会利用 **DEFAULTCAPACITY_EMPTY_ELEMENTDATA** 判断是否是由无参构造创建的，如果是则直接扩容到默认的初始大小10
#### list和数组转换
通常使用Arrays.asList( T... a )方法将数组转成list
```java
public static <T> List<T> asList(T... a) {  
    return new ArrayList<>(a);  
}

private static class ArrayList<E> extends AbstractList<E>  
    implements RandomAccess, java.io.Serializable{
	private final E[] a;
	ArrayList(E[] array) {  
	    a = Objects.requireNonNull(array);  
	}
}
```
注意这个返回的ArrayList是Arrays内部的一个静态类，通过它的构造方法，判断传入的数组是否为空，如果不为空就直接赋给了内部的成员变量，也就是实际存储数据的变量，数组和成员变量指向同一个地址，所以当数组内容发生改变，转成的list也是会变化的

使用toArray((T[] a)方法将list转成数组
```java
public <T> T[] toArray(T[] a) {  
    int size = size();  
    if (a.length < size)  
	    //拷贝this.a
        return Arrays.copyOf(this.a, size,  
                             (Class<? extends T[]>) a.getClass());  
    System.arraycopy(this.a, 0, a, 0, size);  
    if (a.length > size)  
        a[size] = null;  
    return a;  
}
```
把list内的a，也就是实际存储数据的数组，copy元素进传入的数组参数中（浅拷贝），然后将copy完成的参数数组返回，两者没有指向同一个地址，所以list变化影响不到数组
#### ArrayList和LinkedList区别
##### 底层结构
ArrayList底层是Object[ ]数组，LinkedList底层是双向链表
##### 效率
- ArrayList支持索引查询，LinkedList不支持
- 查询未知元素两者都需要遍历，O(n)
- ArrayList尾部插入和删除是O(1)，其他位置需要遍历是O(n)
- LinkedList头尾插入和删除是是O(1)，其他位置需要遍历是O(n)
##### 空间
ArrayList使用数组，空间连续，占用内存小，LinkedList使用链表，节点还包含双向指针，占用内容大
##### 线程安全
都不是线程安全的
可以只在方法内创建并使用list
```java
List<Integer> list = Collections.synchronizedList(thereIsNoParametricStructure);
public static <T> List<T> synchronizedList(List<T> list) {  
    return (list instanceof RandomAccess ?  
            new SynchronizedRandomAccessList<>(list) :  
            new SynchronizedList<>(list));  
}

static class SynchronizedList<E>  
    extends SynchronizedCollection<E>  
    implements List<E> {  
    
    @SuppressWarnings("serial") // Conditionally serializable  
    final List<E> list;  
  
    SynchronizedList(List<E> list) {  
        super(list);  
        //直接赋
        this.list = list;  
    }
}
```
可以使用Collections.synchronizedList方法使其线程安全，本质上是给原集合加上了sync锁，封装成了SynchronizedList集合返回，其内部的list变量和传入方法的原list指向同一个地址
### 3. HashMap
#### 实现原理
- 使用数组+链表或红黑树的结构（hash表），数组的元素是链表或红黑树
- 之所以使用红黑树不用AVL树，是因为后者严格平衡，维护成本高
- 存储时，根据key计算它的hash值得到数组下标，如果出现hash值相同的情况，key相同则覆盖原来的值，key不同则放入链表或红黑树中
- 查找时，计算hash值得到下标，在根据key到链表或红黑树中判断key是否一致，查找对应的值
- jdk8之前只有数组+链表，之后才是数组+链表或红黑树
##### 链表和红黑树转换
- 当数组长度大于等于64，某个元素的链表长度大于等于8，则会将该元素的链表转换为红黑树
- 当树节点小于等于6时，会退化成链表，之所以不是8，是要有一个缓冲，防止链表和红黑树之间反复横跳
#### put方法
##### 执行流程
```txt
Start
 |
 |---> 1. key == null ?
 |         |
 |         |-- Yes --> 插入或替换 table[0]（链表/树结构）
 |         |
 |         |-- No --> 计算 key 的 hash 值（hash(key)）
 |
 |---> 2. 计算索引位置 index = (n - 1) & hash
 |
 |---> 3. table[index] 是否为 null？
 |         |
 |         |-- Yes --> 创建新节点，直接插入
 |         |
 |         |-- No --> 冲突处理：
 |                |
 |                |-- 节点 key 相同（equals 判断）？
 |                |       |
 |                |       |-- Yes --> 替换旧值
 |                |       |
 |                |       |-- No --> 遍历链表/树
 |                |                 |
 |                |                 |-- 查到重复 key？替换旧值
 |                |                 |-- 否，尾部插入新节点
 |                |
 |                |-- 如果链表长度 ≥ TREEIFY_THRESHOLD（默认 8）
 |                        |
 |                        |-- 是 --> 转换为红黑树
 |
 |---> 4. size++
 |
 |---> 5. 判断 size > threshold？
 |         |
 |         |-- 是 --> resize() 扩容
 |
End
```
##### 成员变量和构造函数
```java
//默认的初始容量
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
//最大容量
static final int MAXIMUM_CAPACITY = 1 << 30;
//默认负载因子
static final float DEFAULT_LOAD_FACTOR = 0.75f;
//链表转换成红黑树的长度临界值
static final int TREEIFY_THRESHOLD = 8;
//红黑树退化成链表的临界值
static final int UNTREEIFY_THRESHOLD = 6;
//触发链表转换成红黑树的数组长度最小要求
static final int MIN_TREEIFY_CAPACITY = 64;
//存储k，v的数组，哈希表
transient Node<K,V>[] table;
//存储元素的多少
transient int size;
//触发扩容的阈值，当前最大容量*负载因子
int threshold;
```
- 之所以临界值和默认负载因子要设置成这样是因为出于经验考虑和泊松分布统计而来
- 当负载因子为0.75时空间浪费不严重，且哈希冲突次数较少
- 如果因子较小则会频繁扩容空间浪费严重，较大则哈希冲突次数变多
- 链表长度大于8时查找性能就会从O(1)下降到O(n)，转换成红黑树查找效率能得到提升
- 如果转换临界值小于8则过早转换浪费大量空间（红黑树耗费空间），大于8则查找效率低下
```java
//无参构造，设置负载因子为默认的，注意这种情况下扩容阈值还没有设置为0
public HashMap() {  
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted  
}
public HashMap(int initialCapacity) {  
	//传入指定容量和默认负载因子
    this(initialCapacity, DEFAULT_LOAD_FACTOR);  
}
//有参构造
public HashMap(int initialCapacity, float loadFactor) {  
    if (initialCapacity < 0)  
        throw new IllegalArgumentException("Illegal initial capacity: " +  
                                           initialCapacity);
	 //指定容量大于最大容量，取最大容量
    if (initialCapacity > MAXIMUM_CAPACITY)  
        initialCapacity = MAXIMUM_CAPACITY;  
    if (loadFactor <= 0 || Float.isNaN(loadFactor))  
        throw new IllegalArgumentException("Illegal load factor: " +  
                                           loadFactor);  
    this.loadFactor = loadFactor; 
    //提前计算出初始化容量大小，只不过赋值给了阈值变量，由此看出有参构造初始化时，扩容阈值就不会是0，和无参构造区分开了，而其真正的阈值会在第一次put是才真正计算
    this.threshold = tableSizeFor(initialCapacity);  
}
//由于hashmap要求容量只能是2的幂次，所以会将真实容量设置为大于等于有参构造传入参数的最小2的幂次
static final int tableSizeFor(int cap) {  
    int n = -1 >>> Integer.numberOfLeadingZeros(cap - 1);  
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;  
}
```
##### put方法
```java
public V put(K key, V value) {  
    return putVal(hash(key), key, value, false, true);  
}
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,  
               boolean evict) {  
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    //先判断table是否为空或者长度为0，如果是就要初始化容量  
    if ((tab = table) == null || (n = tab.length) == 0)  
        n = (tab = resize()).length;
    //判断key要插入的位置是否为空，为空直接插入  
    if ((p = tab[i = (n - 1) & hash]) == null)  
        tab[i] = newNode(hash, key, value, null);  
    else {  
        Node<K,V> e; K k;  
        //查找桶中第一个元素，是否key相同，相同则进行覆盖
        if (p.hash == hash &&  
            ((k = p.key) == key || (key != null && key.equals(k))))  
            e = p;  
        else if (p instanceof TreeNode)  
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);  
        else {  
	        //不相同则进入链表进行遍历
            for (int binCount = 0; ; ++binCount) {  
	            //如果找到末尾仍然没有匹配的则插入到尾部
	            //如果链表长度大于8则转换成红黑树
                if ((e = p.next) == null) {  
                    p.next = newNode(hash, key, value, null);  
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  
                        treeifyBin(tab, hash);  
                    break;  
                }  
                //找到匹配节点直接退出
                if (e.hash == hash &&  
                    ((k = e.key) == key || (key != null && key.equals(k))))  
                    break;  
                p = e;  
            }  
        }  
        //如果找到的节点为空，更新节点
        if (e != null) { // existing mapping for key  
            V oldValue = e.value;  
            if (!onlyIfAbsent || oldValue == null)  
                e.value = value;  
            afterNodeAccess(e);  
            return oldValue;  
        }  
    }  
    //增加修改次数
    ++modCount;  
    //判断元素个数是否超过阈值，超过则进行扩容，如果是新增才会触发++，覆盖旧的不会
    if (++size > threshold)  
        resize();  
    afterNodeInsertion(evict);  
    return null;  
}
```
#### 扩容
```java
final Node<K,V>[] resize() {  
	//引用table
    Node<K,V>[] oldTab = table; 
    //如果为空容量为0，否则为哈希表的长度 
    int oldCap = (oldTab == null) ? 0 : oldTab.length;  
    //记录当前扩容阈值
    int oldThr = threshold;  
    //定义新的容量和扩容阈值
    int newCap, newThr = 0;  
    //如果当前容量大于0
    if (oldCap > 0) {  
		//容量已经达到最大容量，设置扩容阈值，返回当前哈希表，表示不再扩容
        if (oldCap >= MAXIMUM_CAPACITY) {  
            threshold = Integer.MAX_VALUE;  
            return oldTab;  
        }  
        //没有到最大容量，则将容量翻倍，同时扩容阈值也因此翻倍
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&  
                 oldCap >= DEFAULT_INITIAL_CAPACITY)  
            newThr = oldThr << 1; // double threshold  
    }  
    //如果当前容量为0，且扩容阈值大于0（哈希表没有初始化），将容量设置为当前扩容阈值
    //注意，此种情况只有使用的是有参构造才会出现，传了初始容量，在构造方法里提前计算了初始化容量赋给了阈值变量
    else if (oldThr > 0) // initial capacity was placed in threshold  
        newCap = oldThr;  
    else {               // zero initial threshold signifies using defaults  
	    //如果容量和阈值都为0，则使用默认容量16和阈值
	    //此种情况使用的是无参构造才会出现，因为无参构造没有传初始容量，则阈值计算出来才是0
        newCap = DEFAULT_INITIAL_CAPACITY;  
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);  
    }  
    //计算扩容阈值
    if (newThr == 0) {  
        float ft = (float)newCap * loadFactor;  
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?  
                  (int)ft : Integer.MAX_VALUE);  
    }  
    //更新阈值
    threshold = newThr;  
    @SuppressWarnings({"rawtypes","unchecked"}) 
    //创建新的哈希表，长度为扩容之后的长度 
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];  
    //直接替换掉旧的哈希表
    table = newTab;  
    //把旧的哈希表的数据拷贝过去
    if (oldTab != null) {  
        for (int j = 0; j < oldCap; ++j) {  
            Node<K,V> e;  
            if ((e = oldTab[j]) != null) {  
                oldTab[j] = null;  
                if (e.next == null)  
                    newTab[e.hash & (newCap - 1)] = e;  
                else if (e instanceof TreeNode)  
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);  
                else { // preserve order  
                    Node<K,V> loHead = null, loTail = null;  
                    Node<K,V> hiHead = null, hiTail = null;  
                    Node<K,V> next;  
                    do {  
                        next = e.next;  
                        if ((e.hash & oldCap) == 0) {  
                            if (loTail == null)  
                                loHead = e;  
                            else  
                                loTail.next = e;  
                            loTail = e;  
                        }  
                        else {  
                            if (hiTail == null)  
                                hiHead = e;  
                            else  
                                hiTail.next = e;  
                            hiTail = e;  
                        }  
                    } while ((e = next) != null);  
                    if (loTail != null) {  
                        loTail.next = null;  
                        newTab[j] = loHead;  
                    }  
                    if (hiTail != null) {  
                        hiTail.next = null;  
                        newTab[j + oldCap] = hiHead;  
                    }  
                }  
            }  
        }  
    }  
    return newTab;  
}
```
#### 寻址方式
```java
static final int hash(Object key) {  
    int h;  
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);  
}
```
先通过hashCode方法得到哈希值，然后将其向右位移16位的值和自己做异或运算进行二次哈希，之所以要进行二次哈希是为了让哈希值更均匀
```java
newTab[e.hash & (newCap - 1)]

(e.hash & oldCap) == 0
 ```
根据哈希值计算索引时是用哈希值对数组长度取模，但是cup的取余运算会有多步操作，如果数组长度是2的幂次可以将其等价为**hash&(长度-1)**，只需要一次运算，增加了性能
而且在扩容时需要重新计算哈希值对应的索引，如果数组长度是2的幂次，可以直接通过**hash&oldCap**的运算快速判断元素是否要留在原来的位置还是新的位置（当前位置+旧的数组长度）
#### 1.7HashMap多线程死循环
1.7的hashmap进行数据迁移使用头插法将链表元素移动，相当于迁移之后链表发生颠倒，在多线程情况下，线程二完成了迁移链表颠倒，线程一对链表头部的引用仍然是没有颠倒之前的，如之前是
A->B，线程二之后成了B->A，线程一对链表头部的引用仍然是A而不是B，next是B，B的next又是A，造成循环A->B->A
## 二. 常见类
### 1. Integer
#### 自动装箱
```java
//java代码
Integer a=123;
//编译后的字节码文件
Integer a=Integer.valueOf(123);
```
int类型的值能自动被封装成Integer对象，是因为在编译后的class文件调用了valueOf方法
```java
Integer a=123;  
Integer b=123;  
int c=a+b;
//编译之后
int c=a.intValue()+b.intValue();
```
包括两个对象相加能得出int类型的值，是在编译之后调用了intValue进行了拆箱
#### 缓存机制
```java
//常量，自动装箱的int原值
private final int value;
//得到Integer对象
public static Integer valueOf(int i) {  
	//判断是否是缓存池中范围的数字，如果是则直接从缓存池中取出
	//不是则用构造函数new一个
    if (i >= IntegerCache.low && i <= IntegerCache.high)  
        return IntegerCache.cache[i + (-IntegerCache.low)];  
    return new Integer(i);  
}

//静态内部类，所有Integer对象共享，缓存池对
private static class IntegerCache {  
	//规定的缓存池的下限
    static final int low = -128;  
    //缓存池上限
    static final int high;  
    //真实缓存
    static final Integer[] cache;
    //归档缓存  
    static Integer[] archivedCache;  
	//初始化静态代码块
    static {  
        //初始化
        int h = 127;  
        //从JVM参数中读取配置设置high，没有不抛异常
        String integerCacheHighPropValue =  
            VM.getSavedProperty("java.lang.Integer.IntegerCache.high");  
        if (integerCacheHighPropValue != null) {  
            try {  
                h = Math.max(parseInt(integerCacheHighPropValue), 127);  
                // Maximum array size is Integer.MAX_VALUE  
                h = Math.min(h, Integer.MAX_VALUE - (-low) -1);  
            } catch( NumberFormatException nfe) {  
                // If the property cannot be parsed into an int, ignore it.  
            }  
        }  
        high = h;  
        //CDS（Class Data Sharing） 是 JVM 为了加快类加载速度和节省内存的一种共享机制
        //如果启用了 CDS（一般在模块化 JVM 中开启），JVM 会将常见类（如 Integer、String）预缓存到归档文件中，下次启动可复用这些缓存，不必重新初始化
		//从归档文件中恢复 IntegerCache 的缓存。如果归档中存在有效的缓存数据，它会加载这些数据并初始化 IntegerCache.archivedCach
        CDS.initializeFromArchive(IntegerCache.class);
        //当前缓存的大小
        int size = (high - low) + 1;  

		//如果没有缓存数据，或者新的上下限超过了原来的缓存数据，则进行更新
        if (archivedCache == null || size > archivedCache.length) {  
            Integer[] c = new Integer[size];  
            int j = low;  
            for(int i = 0; i < c.length; i++) {  
                c[i] = new Integer(j++);  
            }  
            //重复new一个数组，范围从是新的上下限，然后设置值，把原来的归档缓存替换
            archivedCache = c;  
        }  
        //设置新的真实缓存
        cache = archivedCache;  
        assert IntegerCache.high >= 127;  
    }  
  
    private IntegerCache() {}  
}
```
由此可见可以通过`-XX:AutoBoxCacheMax=<size>` JVM参数设置上限大小
### 2. String
#### 字符串常量池
```java
String a = "hello";
String b = "hello";
System.out.println(a == b); // true
```
- **字符串字面量（双引号）** 会自动放入JVM的方法区的常量池
- 如果池中已有该字符串，JVM 不会重新创建，而是复用地址
- **但是注意**如果不是字面量字符串而是new出来的，会放进堆中，不管有没有相同字符串**值**的对象
```java
String s1 = "abc";
String s2 = new String("abc");
System.out.println(s1 == s2); // false ❗
```
#### String 是不可变的
```java
//内部存储字符串的数组，因为字符串本身就是一个字符数组，Java9之后改成了byte数组
//final修饰，引用地址不可变
@Stable  
private final byte[] value;
```
- 安全（多线程下不需要加锁）
- String本身这个类就是final修饰的，且存储字符串的value数组也是final修饰不可变，有参构造也是将传入参数进行了拷贝而不是直接引用
- 可缓存（做 hash 缓存）
- 可被作为 Map 的 key
- 注意对String对象或者String字面量进行操作，改变的只是当前这个引用变量的地址，指向操作后的新的对象，原本的字符串和对象并没有改变，操作后形成的新字符串或对象会放进方法区的常量池里或堆里
- 所以如果对String对象加了final关键字，由于final修饰的变量不能修改引用地址，对原字符串对象进行操作返回的是一个新的地址引用，也就是地址改变，这和final冲突所以不会成功，所以final修饰的String对象是线程安全的
```java
String a = "hello";
//因为不知道a这个变量到底是常量池的地址引用。还是堆的地址引用，则一律将新的结果放入堆中，b是堆中string对象的地址引用，实际上是编译器优化的结果
String b = a + "world";
//但是"helloworld"是常量池中的，两个虽然值一样，但是地址不一样所以是false
System.out.println(b == "helloworld"); // false ❌
```
#### 拼接优化
```java
String a = "hello" + "world"; // 编译期常量优化，形成一个整的字符串
String b = "hello";
String c = b + "world";       // 运行期拼接
```
对于两个字面量字符串拼接，编译后会被优化成一个整串，放进常量池中（如果没有）
对于对象+常量或对象+对象的拼接，编译后优化成`new StringBuilder().append(b).append("world").toString()` 使用api进行拼接形成新的String对象，放入堆中（不管有没有）
#### intern() 方法
```java
String a = new String("abc");
String b = a.intern();
String c = "abc";
System.out.println(b == c); // true ✅
```
把字符串放进常量池（如果还没放的话），返回**池中的引用**
### 3. 迭代器
把“遍历”这个行为从集合的内部数据结构中解耦出来，调用者不需要知道集合是数组、链表还是树，都能用统一的方式遍历
#### Iterator
迭代遍历的实现依赖于Iterator接口
##### 单向迭代器
```java
public interface Iterator<E> {
    boolean hasNext();   // 是否还有元素
    E next();            // 返回下一个元素
    default void remove() { 
        throw new UnsupportedOperationException("remove"); 
    }
}
```
##### 双向迭代器
```java
public interface ListIterator<E> extends Iterator<E> {
    boolean hasPrevious(); // 是否有前一个
    E previous();           // 返回前一个
    int nextIndex();        // 下一个元素的索引
    int previousIndex();    // 上一个元素的索引
    void set(E e);          // 修改当前元素
    void add(E e);          // 添加新元素
}
```
#### ArrayList的迭代器
```java
private class Itr implements Iterator<E> {
    int cursor;       // 下一个要返回的元素索引
    int lastRet = -1; // 上一个返回的元素索引
    int expectedModCount = modCount; // 期望的修改次数，用来检测并发修改

    public boolean hasNext() {
        return cursor != size;
    }

    public E next() {
        checkForComodification(); // 检查并发修改
        //返回当前元素的同时指针向后移动
        int i = cursor;
        cursor = i + 1;
        lastRet = i;
        return elementData[i];
    }

    public void remove() {
        checkForComodification();
        //删除last指针的元素
        ArrayList.this.remove(lastRet);
        //所有元素会往前移动，所以cursor指针要回到原来的位置，即last指针的位置
        cursor = lastRet;
        //删除当前元素之后last置为-1，所以在使用迭代器的remove之前必须调用next方法，不然使用的last指针是-1，会抛异常！！！！
        lastRet = -1;
        expectedModCount = modCount; // 更新期望值
    }

    final void checkForComodification() {
        if (modCount != expectedModCount)
            throw new ConcurrentModificationException();
    }
}
```
- 它在内部采用了Fail-Fast 机制
- 如果在迭代过程中，集合结构发生了非迭代器自身的修改（比如直接 `list.remove()` 而不是用 `iterator.remove()`），`modCount` 会变，但 `expectedModCount` 不会变，就会抛 **ConcurrentModificationException**
```java
for (String s : list) {
    if ("B".equals(s)) {
        list.remove(s); // ❌ 直接修改集合
    }
}

//现实代码
for (E e : collection) { ... }
// 编译后其实是：
for (Iterator<E> it = collection.iterator(); it.hasNext(); ) {
    E e = it.next();
    ...
}
```
所以对于这种删除是错的，因为增强for循环本质在编译之后还是使用迭代器进行遍历，在迭代器中直接使用源集合删除当前元素，会导致迭代器内部的修改次数对不上，在校验的时候会抛异常
### 4. final关键字
- **final 变量的特殊语义**：
    1. 对 `final` 字段的写操作在对象构造完成之前，禁止和构造器之外的操作发生重排序；
    2. 对 `final` 字段的读操作时，JMM 保证能看到构造器中正确初始化的值，而不是默认值；
    3. 这使得 `final` 字段在多线程下的可见性比普通字段更强。
- **和 static 的区别**：
    - `static` 是类级别的存储位置（类加载时分配），所有实例共享。
    - `final` 是语义修饰符，保证不可变性（对象构造完成后值不会再变）。
    - `static final` 且是编译期常量时，会直接内联进字节码（相当于宏展开）。

# JUC
## 一. 基础
### 1. 进程和线程
#### 进程
**一个程序运行的实例**，将程序的指令和数据加载到内存中，一个进程可以包含多个线程
#### 线程
线程来执行指令，同一进程下的线程共享资源，分别执行任务
#### 上下文切换
当cup在执行A线程任务时切换到B线程会保存A线程运行时的程序和临时数据，并加载B线程的程序和数据
### 2. 并行和并发
#### 并发
同一时间应对多件事情的能力，多个线程轮流使用一个或多个cup的能力
#### 并行
- 同一时间同时处理多件事情的能力，多个线程同时使用cup的能力
- 需要注意的是，对于cpu来说同一时间只能处理一个线程的指令，应对多个线程还是一个一个去执行，所以如果cpu是单核的，即使看起来在执行并行操作，但是实际上花费的时间比串行执行更慢，因为会有上下文的切换耗费性能
### 3. 创建线程的方式
#### 实现Runable
```java
public class MyRunable implements Runnable {  
    @Override  
    public void run() {  
        System.out.println("Runnable is running");  
    }  
  
    public static void main(String[] args) {  
        MyRunable runnable = new MyRunable();  
        //本质上是Runable任务交给线程去执行  
        Thread thread = new Thread(runnable);  
        thread.start();  
	        //注意：如果在同一个线程对象上调用start()方法多次，会抛出IllegalThreadStateException异常，因为这个线程对象的生命周期已经结束
        thread.start();  
    }  
}
```
实现Runable接口实现run方法，交给一个线程对象去执行这个任务
#### 继承Thread，修改run方法逻辑
```java
public class MyThread extends Thread {  
    @Override  
    public void run() {
	    //super.run(); 执行初始的run逻辑也就是执行runable任务  
        System.out.println("Thread is running");  
    }  
    public MyThread(Runnable task){  
        super(task);  
    }  
    public MyThread() {  
        super();  
    }  
  
    public static void main(String[] args) {  
        MyThread thread = new MyThread();  
        //注意到两次执行任务，一次是重写的run方法，一次是通过构造函数传入的Runnable任务  
        //但是结果都是"Thread is running"，因为run方法被重写了  
        thread.start();  
        new MyThread(new MyRunable()).start();  
    }  
}
```
继承Thread重写run方法，然后就可以启动这个线程对象执行run方法内容，可以注意到两次的执行结果一致，都是重写的run方法，没有执行传入的Runable接口的实现的run方法，因为Tread原本的start的逻辑就是申请内存开辟一条线程，然后在run方法内执行一个runable任务，通过继承它重写run方法把原本的run逻辑覆盖了，逻辑就成了直接执行重写方法内的内容，所以Runable的run没有执行
**注意**
**可以在重写的run方法里加上==super.run()==，这样就能执行子类和父类的两种run方法逻辑了**
#### 实现Callable接口
```java
public class MyCallable implements Callable<String> {  
    @Override  
    public String call() throws Exception {  
        return "Callable is running";  
    }  
  
    public static void main(String[] args) throws ExecutionException, InterruptedException {  
        MyCallable callable = new MyCallable();  
        //创建一个单线程执行器  
        ExecutorService executorService = Executors.newSingleThreadExecutor();  
        //提交Callable任务到执行器，并获取Future对象  
        Future<String> future = executorService.submit(callable);  
        //获取Callable任务的执行结果  
        System.out.println(future.get());  
        //执行器执行完毕后需要关闭  
        executorService.shutdown();  
    }  
}
```
Callable也是一个线程可执行的任务，但是需要创建线程池处理器去处理，**可以得到任务返回的结果**
#### 多线程执行器
```java
public class MyExecutor implements Runnable{  
    @Override  
    public void run() {  
        System.out.println("Executor is running");  
    }  
  
    public static void main(String[] args) {  
        //创建一个固定大小的线程池执行器  
        ExecutorService executorService = Executors.newFixedThreadPool(3);  
        for (int i = 0; i < 10; i++) {  
            //提交任务到执行器  
            executorService.submit(new MyExecutor());  
        }  
        executorService.shutdown();  
    }  
}
```
创建一个固定大小的线程池处理器，执行任务，注意到**线程池处理器可以执行Runable和Callable两种任务**
#### 注意
Runbale抛出的异常只能在内部处理，不允许继续向上抛，但是Callable可以
**Thread的start方法是开启一个线程，在线程里执行run方法，直接运行它的run方法不会开启线程，就只是一个普通方法**
### 4. 线程状态
```txt
+---------+          start()         +-------------+
|  NEW    | -----------------------> |  RUNNABLE   |
+---------+                          +-------------+
                                         |
                                         |  CPU调度
                                         v
                                     +-------------+
                                     |   RUNNING   | (其实Java里没有单独RUNNING状态，
                                     +-------------+  在RUNNABLE里包含"正在运行"和"可运行")

                                         |
               +-------------------------+-------------------------+
               |                         |                         |
      synchronized锁没拿到         Object.wait()              Thread.sleep()/join()/parkNanos()
               |                         |                         |
               v                         v                         v
         +-------------+          +-------------+          +----------------+
         |   BLOCKED   |          |   WAITING   |          | TIMED_WAITING  |
         +-------------+          +-------------+          +----------------+
               |                         |                         |
               |锁可用                   | notify()/notifyAll()    | 时间到 / notify()
               +------------+------------+-------------+-----------+
                            |                          |
                            v                          v
                       +-------------+            +-------------+
                       |  RUNNABLE   | <----------+  RUNNABLE   |
                       +-------------+            +-------------+


     线程执行结束
          |
          v
     +-------------+
     | TERMINATED  |
     +-------------+
```
#### NEW
新建状态，新创建出来的线程对象，尚未调用start方法启动
#### RUNNABLE
可运行状态，线程已经准备就绪正在抢夺cup的执行权，抢到了就能执行代码，没有抢到可能进入其他状态
#### RUNNING
正在运行中
#### BLOCKED
阻塞状态，等待获得锁，之后重新进入RUNNABLE状态
#### WAITING
等待状态，被唤醒之后进入进入RUNNABLE状态
#### TIMED_WAITING
计时等待，计时完成进入RUNNABLE状态
#### TERMINATED
执行完成，死亡状态
### 5. 线程顺序执行
```java
public class test1 {  
    public static void main(String[] args) {  
        Thread t1 = new Thread(() -> System.out.println("Thread 1 is running"));  
        Thread t2 = new Thread(() -> {  
            try {  
                t1.join();  
            } catch (InterruptedException e) {  
            }  
            System.out.println("Thread 2 is running after Thread 1");  
        });  
        Thread t3 = new Thread(() -> {  
            try {  
                t2.join(1000);  
            } catch (InterruptedException e) {  
            }  
            System.out.println("Thread 3 is running after Thread 2");  
        });  
        t1.start();  
        t2.start();  
        t3.start();  
    }  
}
```
可以在线程任务中使用**其他线程对象的join()方法**，使当前线程处于阻塞状态，保证当前线程会在其他线程执行之后才执行，如果调用有参数的join方法，可以限制等待线程完成的时间，指定时间结束后无论这个线程任务有没有结束，当前线程会继续向下执行
```java
thread.setPriority(2);
```
除此之外还可以使用设置线程优先级，但是这只是标记作用，在cpu繁忙时，任务调度器会忽略优先级设置
#### join原理
```java
public final synchronized void join(long millis) throws InterruptedException {
    long base = System.currentTimeMillis();
    long now = 0;

    if (millis < 0) {
        throw new IllegalArgumentException("timeout value is negative");
    }

    if (millis == 0) {
        // 没有超时时间，等目标线程结束
        while (isAlive()) {//循环判断，防止伪唤醒
            wait(0);  // 等待被唤醒
        }
    } else {
        // 带超时的 join
        while (isAlive()) {
            long delay = millis - now;
            if (delay <= 0) break;
            wait(delay);  // 等待一段时间
            now = System.currentTimeMillis() - base;
        }
    }
}
```
- 本质上是主线程拿到t1对象的锁，然后wait主动释放，开始等待
- isAlive()用于判断目标线程，也就是调用了join方法的线程对象有没有执行完
	- 如果没有就wait等待
		- 不带超时的join就是无限等
		- 带了的就在指定时间内等待
	- 执行完了，JVM 会在 `Thread` 内部调用 `notifyAll()`，唤醒主线程，主线程重新拿到锁继续进行后面的代码
### 6. wait和sleep

| 特性    | `wait()`                            | `sleep()`                  |
| ----- | ----------------------------------- | -------------------------- |
| 所属类   | `Object` 类的方法                       | `Thread` 类的静态方法            |
| 使用前提  | 线程必须持有该对象的锁（即在 `synchronized` 代码块内） | 无需任何同步前提                   |
| 是否释放锁 | ✅ 会释放当前对象的**监视器锁（monitor）**         | ❌ 不会释放锁                    |
| 唤醒方式  | `notify()` / `notifyAll()` 或超时      | 自动在指定时间后唤醒                 |
| 常用场景  | 多线程协调（如生产者/消费者）                     | 简单的延迟，如定时器、轮询、节流等          |
| 抛出异常  | 抛出 `InterruptedException`           | 也抛出 `InterruptedException` |
wait方法必须搭配synchronized代码块使用，调用wait方法之后会释放锁，让其他线程去使用，
sleep调用不会释放锁就只是让线程睡觉
`notify()` / `notifyAll()`方法实际上是通知所有正在wait、阻塞在这个锁对象的线程可以抢占锁了，但是其他线程开始抢占的**前提是通知的线程之后进行了wait或执行完了synchronized内的内容，锁才会释放**
### 7. 停止一个正在运行的线程
```java
public class stopThread {  
    public static void main(String[] args) throws InterruptedException {  
        //中断阻塞的线程  
        Thread thread = new Thread(() -> {  
            try {  
                Thread.sleep(10000);  //阻塞
            } catch (InterruptedException e) {  
                System.out.println("线程被中断了");  
                throw new RuntimeException(e);  
            }  
        });  
        thread.start();  
        Thread.sleep(1000);  
        thread.interrupt();//直接中断正在阻塞的线程，同时会抛出异常  
  
        //打断正常的线程，实际上是改变线程的中断状态，来退出线程的代码  
        Thread thread1 = new Thread(() -> {  
            while (true) {  
                boolean interrupted = Thread.currentThread().isInterrupted();  
                if (interrupted) {  
                    System.out.println("状态被中断了");  
                    break;  
                }  
            }  
        });  
        thread1.start();  
        Thread.sleep(1000);  
        thread1.interrupt();  
    }  
}
```
除此之外线程对象的`stop()`方法也能强制杀死一个线程，通过这种方式终止的线程无法释放持有的资源，比如无法释放锁导致死锁问题，所以在1.2版本之后被废弃
#### 两阶段终止模式
在t1线程里优雅地终止t2线程，给t2一个处理后事的机会
```java
Thread t1 = new Thread(() -> {  
    while (true){  
        Thread thread = Thread.currentThread();  
        if(thread.isInterrupted()){  
            System.out.println("处理后事");  
            break;  
        }  
        try {  
            Thread.sleep(1000);  
        } catch (InterruptedException e) {  
            thread.interrupt();  
        }  
    }  
},"t1");
```
- 如果在sleep的时候打断，会捕获到异常然后重新执行打断方法，将其打断状态置为true（因为在阻塞状态被打断，会将打断状态重新置为false），在下一轮循环时进入if处理后事
- 如果在sleep之前或结束之后进行打断，打断标记正常变为true，进入if处理后事
### 8. 守护线程
```java
t1.setDaemon(true);
```
- 在没有使用setDaemon方法时创建的线程是非守护线程，这种线程组哎主线程执行完后仍然会继续执行
- 将线程对象设置成守护线程后，如果主线程结束，守护线程也会被强制结束
- 垃圾回收线程就是一个守护线程

### 9. park&unpark
```java
Thread t1 = new Thread(() -> {  
    System.out.println("1");  
    LockSupport.park();  
}, "t1");  
t1.start();  
LockSupport.unpark(t1);
```
- `park`方法会暂停当前线程
- `unpark`方法会唤醒指定的线程
- 每个线程关联一个park对象，其中包括_counter，_cond，_mutex
- 在调用park时，会判断counter是否为1
	- 如果不为1，则会正常暂停
	- 如果为1，会将counter置为0，然后线程继续运行，不会暂停
- 调用unpark会把指定线程对象的counter置为1

## 二. 线程安全
### 0. 线程安全问题
- 源于线程间的上下文切换，发生指令交错
- 线程在操作共享资源时，会先将其读出来，进行操作，然后写回
- 如果在写回之前发生了上下文切换，其他线程读取的数据仍然是此线程操作前的数据，且其他线程将操作后的数据成功写回
- 上下文切换回来后，此线程会将没有写入的数据进行写入，导致数据不一致
### 1. synchronized
- `synchronized` 的实现依赖 JVM 中的**对象头（Mark Word）和Monitor（监视器锁）**
- Mark Word 不是完全固定的，JVM 会根据位数和压缩配置调整布局
#### Mark Word
| 位数（64-bit JVM） | 内容说明                     |
| -------------- | ------------------------ |
| 25 bits        | 对象哈希码（hashcode）          |
| 4 bits         | GC 分代年龄                  |
| 1 bit          | 是否是偏向锁标志                 |
| 2 bits         | 锁标志位（轻量锁、偏向锁、重量锁、无锁）     |
| 32/64 bits     | 指向 Monitor 的指针或线程ID（锁竞争） |

|状态|Mark Word 内容|
|---|---|
|无锁|对象Hashcode、GC分代年龄等|
|偏向锁|ThreadID + Epoch时间戳 + 偏向锁标志|
|轻量锁|指向线程栈中 Lock Record 的指针（即 Mark Word 被线程占用）|
|重量锁|指向 Monitor 对象的指针|
|GC标记|专门给 GC 暂用，表示对象是否可回收等信息|
#### 四种锁的状态
| 锁状态 | 线程安全 | 性能  | 特点           |
| --- | ---- | --- | ------------ |
| 无锁  | 否    | 高   | 普通对象         |
| 偏向锁 | 是    | 高   | 适用于线程不竞争     |
| 轻量锁 | 是    | 中   | 适用于线程间存在少量竞争 |
| 重量锁 | 是    | 低   | 多线程竞争激烈      |
jvm的锁只会升级而不会降级，为防止频繁切换锁带来性能开销
##### 偏向锁
- 在jdk1.6之后引入，默认在对象创建的时候就是偏向锁，后三位值101
- 调用对象的hashCode方法后，会将哈希码填充到对象头中，占用了写线程Id的地方，相当于禁用了偏向锁
- 首次加锁时线程会将自己的Thread Id写入对象的对象头中
- 之后如果没有其他线程使用这个锁，这个锁就偏向这个线程，即当加锁的线程再次申请加锁时会直接成功省去了检查和加锁（CAS）的时间
- 当另一个线程尝试获取锁时，偏向锁撤销，将对象变成轻量锁状态后三位000，这个过程需要全局停顿，在释放锁之后变成正常状态后三位001
	- 如果偏向锁撤销超过20次，会进行重偏向，偏向到另一个线程，后三位101
	- 如果超过40，jvm会认为这个类不应该偏向，会将这个类的所有对象包括新建的对象都变成不可偏向，对象头后三位是001
##### 轻量锁
```txt
Lock Record
+--------------------------+
| Displaced Mark Word      | ← 保存对象头原始信息
| （重入时是 null）        |
+--------------------------+
| Object Reference         |
| 被加锁的对象引用          |
+--------------------------+

```
- 用于线程之间交替进行并无真正冲突情况发生
- 线程进入 synchronized：
    - 在自己的栈帧里创建一个 Lock Record。
    - 保存对象头原始 Mark Word 到 Lock Record。
- CAS 尝试：
    - 把对象头的 Mark Word 改为指向 Lock Record 的指针。
    - 如果成功 → 获得锁。
    - 如果失败 → 自旋一定次数，如果仍失败 → 锁升级为重量级锁，进入Monitor的竞争队列中。
- 重入：
    - 新建 Lock Record，但不再 CAS。
    - Displaced Mark Word 置 null。
- 解锁：
    - 如果 Lock Record 的 Displaced Mark Word 是 null → 表示只是重入释放，直接弹栈即可。
    - 否则恢复对象头为原始 Mark Word
##### 重量锁
- 多线程竞争时升级为重量锁
- 线程处于阻塞状态，会消耗大量资源
#### Montior
**实现了重量锁**
```c
ObjectMonitor {
    Object* object;       // 指向被锁定的对象
    Thread* owner;        // 拥有者线程
    int     recursions;   // 重入次数
    List    EntryList;    // 竞争队列（阻塞线程）
    List    WaitSet;      // 等待队列（wait线程）
}
```
- Mark Word主要存储的是一个指向Montior的指针
- 当前线程尝试 CAS 设置 `ObjectMonitor` 的 `_owner` 字段为自己
- 成功，进入临界区
- 失败进入竞争队列，操作系统会将这个线程挂起
- 有锁的线程执行完同步代码块，调用 `monitorexit`
- 之后JVM 会清空 `_owner`，并唤醒 EntryList 里的一个或多个等待线程
- 被唤醒的线程再次尝试 CAS 抢锁
- 注意代码块执行完JVM唤醒的是竞争队列里的线程，等待队列的线程调用了wait方法，需要使用notifyall唤醒
##### 重入锁
Montior记录了当前持有锁的线程和重入次数，如果持有的线程再次申请获得锁，会增加重入次数
### 2. JMM内存结构
- 每个线程有自己的工作空间，在自己的工作空间的变量是没有线程安全问题的
- 空间中还会有引用主内存变量的副本
- 当一个线程对主内存的共享变量修改之后会将数据同步到主内存，之后由主内存把数据同步到其他引用了这个共享变量的线程
- 但是这个同步并不是立刻的，且JIT编译器会对部分使用了共享变量的代码做优化，将共享变量的初始值缓存到线程的工作内存中，线程读取的就是工作内存的旧值

### 3. volatile
#### 线程可见性
```java
public class test {  
    static volatile Integer i = 0;  
//    static Integer i = 0;  
  
    public static void main(String[] args) {  
        new Thread(() -> {  
            try {  
                Thread.sleep(100);  
                i = 1;  
            } catch (InterruptedException e) {  
                throw new RuntimeException(e);  
            }  
        }, "t1").start();  
  
        new Thread(() -> {  
            try {  
                Thread.sleep(500);  
                System.out.println("i = " + i); //打印语句也可以实现可见性
            } catch (InterruptedException e) {  
                throw new RuntimeException(e);  
            }  
        }, "t2").start();  
  
        new Thread(() -> {  
            int j = 0;
            //变量的修改对于其他线程是可见，否则就是从自己线程的工作内存中读取
            while (i != 1) {  //对于共享变量的判断可以会被JIT直接优化成true或false
                j++;  
            }  
        }, "t3").start();  
    }  
  
}
```
- 被volatile修饰的变量会要求使用这个共享变量的线程在读取时必须从主内存中读取，写时强制刷新到主内存
- synchronized也可以实现可见性，进入代码块时会从主内存刷新共享变量到线程工作内存，退出时会把本地修改刷新到主内存，但是相较于volatile更重量级
- 除了以上两者方式可以实现可见性，System.out.println方法也可以做到，因为其本质调用了`synchronized(this)`刷新了主内存的共享变量
#### 禁止指令重排序
- cpu对于一条指令的执行分为：取指令、指令译码、执行指令、访问内存、数据写回，每个阶段用到不同的组件处理
- 为将执行效率提高，cpu会将多个指令并行执行，让多个指令的不同阶段在同一时刻使用不同组件运行
- 同样的java程序的指令可能会被cpu或JIT编译器进行指令重排序，导致在多线程情况下读写操作的原始顺序发生可见性和有序性问题
- 使用volatile修饰的变量会在读写时加入不同的屏障，对于写操作，保证之前的写不会被重排序到之后，且会将屏障之前的写的结果刷新到主内存中，对于读操作，保证之后的读写不会被重排序到前面，阻止其他读写操作越过屏障
#### DCL问题
```java
class Singleton {
    private static Singleton instance;//没有使用volatile

    public static Singleton getInstance() {
        if (instance == null) {
            synchronized(Singleton.class) {
                if (instance == null) {
                    instance = new Singleton(); //  这里可能被重排序
                }
            }
        }
        return instance;
    }
}
```
- 创建一个对象的时候，会先开辟内存，将对象的信息写入，然后再将这个对象的地址引用返回
- 但是在多线程状况下，写入信息和返回地址这两个指令可能会重排，导致后续线程发现对象并不为空，直接拿来用，但实际上对象信息还没有写入内存，相当于使用的是一个半成品对象
- 加上volatile之后保证这两个指令不会重排序

### 4. CAS
- 全称是compare and swap先比较再交换，采用的是**乐观锁的思想**，在无锁状态下保证线程操作的原子性，体现在原子类里，CAS底层是cpu级别的原子操作
- 当一个线程修改了自己的共享变量副本之后，先会将**修改前的数据和主内存的共享变量比较**，如果一样则把修改后的数据进行同步，如果不一样则进行自旋，即**重新拉取主存里的共享变量然后重新操作修改之后重新比较**这个过程
- 效率比加锁要高是因为线程并没有阻塞或挂起，**没有发生上下文切换**，如果线程数没有超过cpu核数，线程就一直在运行中
#### 乐观锁
认为其他线程一般不会修改，所以不加锁，在提交的时候再验证数据有没有被其他线程修改过
#### 悲观锁
始终认为其他线程会来修改变量，所以每次操作之前先加锁，确保当前线程独占资源，其他线程等待或阻塞，直到锁释放

### 5. AQS（实现了Lock类）
全称是 `AbstractQueuedSynchronizer`，是 JDK 提供的一个**用于构建锁和同步器的框架**，它通过一个**FIFO 的等待队列（CLH 队列变种）+ 一个原子状态字段 state** 来实现线程的阻塞与唤醒
#### 成员变量和方法
```java
//AbstractQueuedSynchronizer的内部类，每一个没有抢到锁的线程都会封装成一个node节点
abstract static class Node {
	//前驱节点
    volatile Node prev;
    //后继节点       
    volatile Node next;      
    //正在等待的节点
    Thread waiter; 
    //节点的状态字段，如不再等待（节点会被跳过）、后继节点需要被唤醒、节点正在队列中、共享模式中传播唤醒
    volatile int status;
}
```
```java
//FIFO等待队列，队头节点
private transient volatile Node head;  

//队尾节点
private transient volatile Node tail;  

//状态字段，在不同的子类有不同的含义
private volatile int state;  

//读写state字段的原子操作方法
protected final int getState() {  
    return state;  
}  
  
protected final void setState(int newState) {  
    state = newState;  
}  
//CAS原子修改  
protected final boolean compareAndSetState(int expect, int update) {  
    return U.compareAndSetInt(this, STATE, expect, update);  
}
```
- state字段对于不同的子类有不同的含义
	- 对于 `ReentrantLock`：state 表示加锁的次数（重入次数）
		- 0，锁是空闲的
		- 1，锁被一个线程占用
		- >1，重入次数，一个线程多次获得锁
	- 对于 `Semaphore`：state 表示当前可用的许可证数量
	- 对于`CountDownLatch`是计数器
	- 对于`ReentrantReadWriteLock`高 16 位读锁计数 + 低 16 位写锁计数
- 当一个线程获取资源失败后，会被构造成一个node节点插入FIFO双向等待队列的尾部
- 当前持有锁的线程释放锁之后会唤醒head（哨兵，本身并不是线程）的下一个节点，让它去CAS获取资源，成功获取资源后，这个线程成为新的head
- 对于ReentrantLock（CIL队列加AQS）有两种锁，非公平锁（默认），即队列中的线程和队列外的线程能一起抢占资源，公平锁，只有队列中的线程能抢占锁
```txt
尝试获取锁
  ↓失败
构造Node并入队
  ↓
设置前驱状态为 SIGNAL
  ↓
挂起当前线程（LockSupport.park）
  ↓
被唤醒后重新尝试获取锁

```
#### 两种锁模式及对应的抽象方法
##### 独占模式
```java
protected boolean tryAcquire(int arg) // 独占式获取资源
protected boolean tryRelease(int arg) // 独占式释放资源
```
由一个线程占有锁，其他线程等待或阻塞
##### 共享模式
```java
protected int tryAcquireShared(int arg) // 共享式获取资源
protected boolean tryReleaseShared(int arg) // 共享式释放资源
```
多个线程共享资源
### 6. synchronized和Lock的区别
| 对比维度          | `synchronized`                  | `Lock`（如 `ReentrantLock`）                      |
| ------------- | ------------------------------- | ---------------------------------------------- |
| **基本用途**      | 内置关键字，用于加锁同步代码块或方法              | 显式锁，通过调用 `lock()` 和 `unlock()` 控制              |
| **使用方式**      | 隐式获取与释放锁（JVM 自动管理）              | 需显式获取与释放，代码更灵活但也需更小心                           |
| **类别**        | 悲观锁                             | 悲观锁                                            |
| **可重入性**      | 支持，可重入（同一线程可以多次进入）              | 支持，可重入（`ReentrantLock` 就是可重入锁）                 |
| **可中断性**      | 不支持中断等待锁的线程                     | 支持中断等待（`lockInterruptibly()`）                  |
| **是否公平锁**     | 不支持公平性选择（默认非公平）                 | 可选择公平或非公平（构造函数中指定）                             |
| **是否可定时**     | 不支持超时等待锁                        | 支持超时等待（`tryLock(long timeout)`）                |
| **读写锁支持**     | 不支持读写分离                         | 支持（通过 `ReentrantReadWriteLock`）                |
| **条件变量支持**    | 不支持                             | 支持多个 `Condition` 对象用于线程间通信（比 `wait/notify` 灵活） |
| **性能表现（轻载）**  | 由于是 JVM 内置锁，在低竞争下性能优秀           | 略逊色于 synchronized，需额外维护状态                      |
| **性能表现（高竞争）** | JVM 优化有限（但从 JDK1.6 开始引入偏向锁、轻量锁） | 使用 AQS 高性能队列支持，在高并发场景下表现更佳                     |
| **内存开销**      | 无需显式对象开销，语法级别支持                 | 需要维护锁对象和内部状态，开销略高                              |
| **适用场景**      | 简单同步场景，代码简洁                     | 对并发行为控制要求更高的场景（中断、公平、定时等）                      |
##### lock可打断
```java
public static void main(String[] args) throws InterruptedException {  
    ReentrantLock lock = new ReentrantLock();  
    Thread t1 = new Thread(() -> {  
            try {  
                lock.lockInterruptibly();  
            } catch (InterruptedException e) {  
                System.out.println("等待获取锁的过程中被中断了");  
                throw new RuntimeException(e);  
            }  
            try{  
                System.out.println("获取锁成功，开始执行任务");  
            }finally {  
                lock.unlock();  
            }  
    }, "t1");  
    lock.lock();  
    t1.start();  
    Thread.sleep(1000);  
    t1.interrupt();//直接打断线程  
}
```
`lock.lockInterruptibly()`会阻塞等待获取锁，但是可以被线程的中断而打断

##### lock超时等待
```java
public static void main(String[] args) throws InterruptedException {  
    ReentrantLock lock = new ReentrantLock();  
    Thread t1 = new Thread(() -> {  
        try {  
	        //lock.tryLock()无参方法，只尝试获取一次锁，不会阻塞等待，不会重复尝试
            if (!lock.tryLock(2, TimeUnit.SECONDS)) {// 尝试获取锁，最多等待2秒  
                System.out.println("尝试获取锁失败");  
                return;  
            }  
        } catch (InterruptedException e) {  
            throw new RuntimeException(e);  
        }  
        try {  
            System.out.println("线程1获取锁成功");  
        } finally {  
            lock.unlock();  
            System.out.println("线程1释放锁");  
        }  
    }, "线程1");  
    lock.lock();  
    t1.start();  
    Thread.sleep(3000);//超出等待时间  
}
```
`lock.tryLock()`只尝试获取一次锁，不会阻塞等待
`lock.tryLock(2, TimeUnit.SECONDS)`在指定时间内获取锁，超时之后不会再次尝试获取，不会阻塞

##### lock条件变量
```java
public static void main(String[] args) throws InterruptedException {  
    ReentrantLock lock = new ReentrantLock();  
    Condition c1 = lock.newCondition();  
    Condition c2 = lock.newCondition();  
    Thread t1 = new Thread(() -> {  
        lock.lock();  
        System.out.println("t1获得锁");  
        try {  
            c1.await();//相当于是synchronized的wait方法会释放锁  
            System.out.println("t1被唤醒");  
            lock.unlock();  
        } catch (InterruptedException e) {  
            throw new RuntimeException(e);  
        }  
    });  
    Thread t2 = new Thread(() -> {  
        lock.lock();  
        System.out.println("t2获得锁");  
        try {  
            c2.await();//相当于是synchronized的wait方法会释放锁  
            System.out.println("t2被唤醒");  
            lock.unlock();  
        } catch (InterruptedException e) {  
            throw new RuntimeException(e);  
        }  
    });  
    Thread t3 = new Thread(() -> {  
        lock.lock();  
        c1.signal();  
        c2.signal();  
        lock.unlock();//释放锁  
    });  
    t1.start();  
    t2.start();  
    TimeUnit.SECONDS.sleep(1000); // 确保t1和t2已经开始并等待  
    t3.start();  
}
```
#### lock的读写锁
```java
ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
Lock readLock = lock.readLock();
Lock writeLock = lock.writeLock();

// 获取读锁，可以多个线程拥有
readLock.lock();
readLock.unlock();
readLock.lock();
readLock.unlock();

// 获取写锁，只能一个线程拥有
writeLock.lock();
writeLock.unlock();
```
当线程占有写锁时其他线程不能占有写锁或读锁，占有读锁时其他线程可以共享读锁
### 7. 死锁
当多个线程持有、抢夺多个锁时有可能抢夺的锁是别的线程正在持有的，造成死锁
```cmd
jps
jstack -l[线程号]
```
在jvm终端运行命令查看线程占有锁的情况
或者使用jdk/bin的jconosl程序查看或visualVM
### 8. lambda表达式的线程安全
- lambda表达式在使用外部变量时，只允许使用effectively final变量，也就是要保证在lambda引用之后变量没有发生改变或变量直接就是不可改变的
- lambda 更像是直接在当前作用域里“内联”，匿名类则是“新建了一个作用域”
- 在引用外部变量时，实际上是编译器将外部变量拷贝一份形成副本进行使用，而**不是直接引用**其本身
- 为什么这么做
	- 防止线程安全问题
	- 防止歧义
```java
int cnt=0;
Runnable r=()->{
	cnt++;
}
//如果多个线程执行这个Runnable，会出现线程安全
```
```java
int cnt=0;
Runnable r=()->{
	print(cnt);
}
cnt=2;
r.run();//产生歧义：如果允许这样做，打印的是0还是2？
```
### 9. Unsafe
#### 获取
```java
try {  
    // 通过反射获取 Unsafe 实例  
    Field unsafeField = Unsafe.class.getDeclaredField("theUnsafe");  
    unsafeField.setAccessible(true);  
    Unsafe unsafe = (Unsafe) unsafeField.get(null);  
} catch (Exception e) {  
    e.printStackTrace();  
}
```
只能通过反射获取，它的`Unsafe.getUnsafe`方法只能由类加载器调用，防止应用程序直接使用 Unsafe 类进行底层操作，造成安全问题
#### 实现CAS
```java
//获取偏移量  
long offset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value"));
//cas
unsafe.compareAndSwapInt(i,0,1);  
unsafe.compareAndSwapLong(i,0,1);  
unsafe.compareAndSwapObject(i,0,1);
```
需要传入要cas的属性所属的对象、属性的偏移量、旧的属性值，新的属性值
### 10. 保护性暂停模式
构造一个中间桥梁实现两个线程间的通信
```java
public static void main(String[] args) throws NoSuchMethodException, InterruptedException {  
    GuardeObject guardeObject = new GuardeObject();  
    new Thread(()->{  
        Object response = guardeObject.get();  
        System.out.println(response);  
    }).start();  
    new Thread(()->{  
        try {  
            Thread.sleep(1000);  
        } catch (InterruptedException e) {  
            throw new RuntimeException(e);  
        }  
        guardeObject.commit("哈哈哈");  
    }).start();  
}  
static class GuardeObject{  
    private Object response;  
  
    public Object get(){  
        synchronized (this){  
            while (response==null){  //防止伪唤醒
                try {  
                    this.wait();  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
            }  
            return response;  
        }  
    }  
  
    public void commit(Object response){  
        synchronized (this){  
            this.response=response;  
            this.notifyAll();  //唤醒
        }  
    }  
}
```

## 三. 线程池
### 1. 线程池的执行原理
#### 核心参数
```java
public ThreadPoolExecutor(int corePoolSize,  
                          int maximumPoolSize,  
                          long keepAliveTime,  
                          TimeUnit unit,  
                          BlockingQueue<Runnable> workQueue,  
                          RejectedExecutionHandler handler)
```
```java
executor.allowCoreThreadTimeOut(true);//允许销毁核心线程
```
- corePoolSize：核心线程数，不会被销毁，除非调用allowCoreThreadTimeOut方法
- maximumPoolSize：最大线程数，即核心线程数+救急线程数
- keepAliveTime：当没有任务处理时，救急线程的最大存活时间
- unit：存活时间单位
- BlockingQueue：当**没有空闲的核心线程**时，新来的任务会被放入这个阻塞队列，当阻塞队列满时，如果当前线程数没有超过最大线程数，会创建救急线程来处理
- RejectedExecutionHandler：当阻塞队列已满且当前线程数到达最大线程数，会根据拒绝策略处理新来的任务
- 线程池的五种状态
	- running，创建出来就是running，可以接收和处理任务
	- shutdown，不能接收但是能处理队列中的任务
	- stop，什么都干不了
	- tidying，所有任务执行完，可用线程数为0，之后会调用terminated方法让线程池进入终止状态
	- terminated，线程池真正终止
#### execute逻辑
```java
//高3位存线程池的五种状态，低29位存线程数量
private final AtomicInteger ctl;
public void execute(Runnable command) {  
	//检查任务是否为空
    if (command == null) {  
        throw new NullPointerException();  
    } else {  
        int c = this.ctl.get();  
        //如果当前线程数小于核心线程数，则则创建一个核心线程去直接执行
        if (workerCountOf(c) < this.corePoolSize) {  
	        //如果创建新的核心线程成功
            if (this.addWorker(command, true)) {  
                return;  
            }  
  
            c = this.ctl.get();  
        }  
		//如果线程池还在运行且将任务放进任务队列成功
        if (isRunning(c) && this.workQueue.offer(command)) {  
            int recheck = this.ctl.get();  
            //再次检查线程池状态，如果线程池不再运行，则将任务拒绝
            if (!isRunning(recheck) && this.remove(command)) {  
                this.reject(command);  
                //如果线程池正在运行，但是可用的线程没有了，则创建一个空的worker确保任务被拿走
            } else if (workerCountOf(recheck) == 0) {  
                this.addWorker((Runnable)null, false);  
            }  
            //如果线程池正在运行且当前线程数已经达到了最大核心线程数且任务队列放不下
            //则创建救急线程去执行
        } else if (!this.addWorker(command, false)) {  
            this.reject(command);  
        }  
  
    }  
}
```
1. 先判断传入的任务是否为空，为空则抛异常
2. 如果当前线程数小于核心线程数，则创建一个核心线程去执行
3. 如果当前线程数已经大于等于核心线程数，则检查线程池状态并往队列中添加任务
	1. 如果添加成功，说明现在队列没有满，则队列中的任务由当前已经有了的线程去处理，但是添加成功后会再次检查线程池状态，如果状态异常就要移除任务
	2. 如果添加失败则队列已满，尝试创建一个救急线程去执行
		1. 如果创建失败，说明当前的线程数已经达到最大线程数，并且因为此时队列已满，则会根据拒绝策略拒绝任务
总结，优先创建核心线程去执行，核心线程满了，放到队列中，队列满了，创建救急线程执行，救急也满了则拒绝任务，之所以在处理任务时**优先创建核心线程**去处理任务，而不是等队列满了再创建核心线程就像救急线程那样，是因为在线程池设计中，核心线程不会被销毁，它要一直保持运行处理任务，作为长期劳动力要优先创建，其次早将核心线程创建出来有利于应对任务激增的情况，可以直接使用之前已经创建好的核心线程去处理，不用因为要创建线程而浪费时间，同时多个线程共同处理队列任务也能提高消费效率，不至于任务被拒绝
#### tomcat的execute
tomcat的线程池继承了ThreadPoolExecutor，它的execute方法先去调用父类的execute，如果父类方法抛出拒绝异常，则自己的方法会catch住，然后往自己的TaskQueue阻塞队列里，等一段时间再放一次，如果还是失败才会真正抛异常

### 2. Executors创建线程池方式
```java
//指定核心线程数，没有救急线程，阻塞队列容量无限
public static ExecutorService newFixedThreadPool(int nThreads) {  
    return new ThreadPoolExecutor(nThreads, nThreads,  
                                  0L, TimeUnit.MILLISECONDS,  
                                  new LinkedBlockingQueue<Runnable>());  
}
//单例线程池，只有一个核心线程处理任务，队列无界
public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {  
    return new AutoShutdownDelegatedExecutorService  
        (new ThreadPoolExecutor(1, 1,  
                                0L, TimeUnit.MILLISECONDS,  
                                new LinkedBlockingQueue<Runnable>(),  
                                threadFactory));  
}
//缓存线程池，全部由救急线程处理任务
public static ExecutorService newCachedThreadPool() {  
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,  
                                  60L, TimeUnit.SECONDS,  
                                  new SynchronousQueue<Runnable>());  
}
//定时处理线程池
public ScheduledThreadPoolExecutor(int corePoolSize) {  
    super(corePoolSize, Integer.MAX_VALUE,  
          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,  
          new DelayedWorkQueue());  
}
```
所以不推荐使用Executors创建线程池，容易出现创建过多线程或存储过多任务的情况，导致OOM

### 3. 阻塞队列
| 特性              | `LinkedBlockingQueue`                      | `ArrayBlockingQueue`                |
| --------------- | ------------------------------------------ | ----------------------------------- |
| **底层结构**        | 链表（链式节点）                                   | 数组（循环数组）                            |
| **是否有界**        | 默认无界（可设容量）                                 | 必须设定容量（有界）                          |
| **吞吐量**         | 通常较高，适合高并发                                 | 略低，但性能更稳定                           |
| **锁实现**         | **两把锁**，更高并发效率，put时锁住链表尾节点，take时锁住头结点，互不影响 | **一把锁**（put 和 take 互斥）较简单但冲突多，并发效率低 |
| **内存占用**        | 动态增长链表节点，内存占用较高                            | 固定数组大小，内存使用稳定                       |
| **构造时是否必须指定容量** | 否（默认 `Integer.MAX_VALUE`）                  | 是（必须指定）                             |
| **典型使用场景**      | `ExecutorService` 的默认队列                    | 对资源敏感、实时性要求高的系统                     |
| **阻塞行为**        | put 满时阻塞，take 空时阻塞                         | 相同行为                                |
| **并发性能**        | 更优（读写锁分离）                                  | 中等偏上                                |
| **适合场景**        | 任务量不确定、大量生产消费、流式处理                         | 任务量稳定、内存受限的高性能任务队列                  |
SynchronousQueue不存储任务，每个插入操作必须等待一个移出操作完成
DelayedWorkQueue，可以指定任务执行的开始时间
#### 阻塞队列的基本使用
```java
public class test1 {  
    //线程池异步任务执行器  
    private static final ExecutorService executors = Executors.newSingleThreadExecutor();  
    //阻塞队列  
    private static final BlockingQueue<Coffee> blockingQueue = new ArrayBlockingQueue<>(1024 * 1024);  
  
    //静态代码块，在类加载时就进行异步任务  
    static {  
        //只需提交一个异步任务进去就行  
        executors.submit(new myRunnable());  
    }  
  
    public static class myRunnable implements Runnable {  
  
        //异步任务内部死循环从阻塞队列中取出coffee对象进行执行  
        @Override  
        public void run() {  
            while (true) {  
                try {  
                    Coffee take = blockingQueue.take();  
                    System.out.println(take.name());  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
            }  
        }  
    }  
}
```

### 4. 确定核心线程数
- 对于IO型任务，如文件读写，db读写，线程数是2n+1，n是cup的核数
- 对于CUP密集型任务，如代码计算，Bitmaap转换等，是n+1
### 5. 使用场景
```java
public static void main(String[] args) throws InterruptedException {  
    CountDownLatch countDownLatch = new CountDownLatch(3);  
    ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) Executors.newFixedThreadPool(3);  
    threadPoolExecutor.execute(new Runnable() {  
        @Override  
        public void run() {  
            System.out.println("哈哈");  
            countDownLatch.countDown();  
        }  
    });  
    threadPoolExecutor.execute(new Runnable() {  
        @Override  
        public void run() {  
            System.out.println("哈哈");  
            countDownLatch.countDown();  
        }  
    });  
    countDownLatch.await();  
}
```
- 利用CountDownLatch等待所有线程任务完成
- 构造函数指定了信号量，每有一个线程调用了countDown方法就相当于减少了一个信号量
- await方法类似于sleep方法，当信号量减少到0则线程被唤醒
- 底层使用CAS来减少信号量
- 例如可以利用线程池把数据库数据迁移到es的过程，划分成多个线程任务，每个任务迁移一页数据，将任务交给线程池去执行，利用 await方法判断是否执行完成
```java
public static void main(String[] args) throws InterruptedException {  
    ExecutorService executorService = Executors.newFixedThreadPool(3);  
    try {  
        CompletableFuture<String> stringCompletableFuture = new CompletableFuture<String>().completeAsync(() -> "l",executorService);  
        System.out.println(stringCompletableFuture.get());  
    } catch (Exception e) {  
        throw new RuntimeException(e);  
    }  
}
```
可以使用异步任务加线程池进行数据整合
### 6. ThreadLocal
- 实现线程对象隔离，让每个现线程使用各自的资源，避免发生线程安全
- 每个线程对象内部有一个ThreadLocalMap类型的成员变量，是真正存储数据的地方
- 当调用set方法时，就是以当前的ThreadLocal为键将值存入进去的
- get方法就是以当前TreadLocal作为键找出对应的值
- remove方法会删除以当前ThreadLocal为键的所有值
```java
static class ThreadLocalMap {  
  static class Entry extends WeakReference<ThreadLocal<?>> {   
        Object value;  
        Entry(ThreadLocal<?> k, Object v) { 
	        //引用变成弱引用 
            super(k);  
            value = v;  
        }  
    }
}
```
由于ThreadLocalMap实际是以内部的Entry存储数据的，而它继承了`WeakReference<ThreadLocal<?>>`弱引用接口，导致ThreadLocal是弱引用，而val是强引用，导致ThreadLocal在GC之后key失效，但是val却仍然存在，长时间后就会在Map里累积大量无用数据导致OOM
## 四. 类

### 1. LongAdder原子累加器
它将线程的累加值维护到了一个分段计数数组中，相较于Atomic的单点更新：每个线程都cas+自旋的方式来说，冲突更少，性能更高
#### 成员变量
```java
//分段计数数组，每个 Cell 里面就是一个 long 值，表示某一部分线程的计数结果，在多线程竞争的时候才会使用，而且是懒惰创建，需要时才创建
transient volatile Cell[] cells;  
//低并发时使用
transient volatile long base;
//自旋锁标识，在cells数组创建和扩容的时候使用
transient volatile int cellsBusy;
```
#### cell累加单元类
```java
@Contended
static final class Cell{
	final boolean cas(long cmp, long val) {  
	    return VALUE.weakCompareAndSetRelease(this, cmp, val);  
	}
}
```
- 为提高读取数据的速度，会将内存的数据加载进缓存中的缓存行进行读取
- 同一份缓存数据会在cpu的不同核心的缓存中存储
- 当其中一个核心的**缓存行的某个数据**发生修改，**其他核心对应的整个缓存行都会失效**
- 那么两个不同的cell对象可能在同一个缓存行里，当一个线程对一个cell对象进行了修改，所有的核心的这个缓存行的数据都会失效，其他线程操作的另一个cell对象由于在同一个缓存行里，另一个cell对象也会失效，增加耗时
- `Contended`注解能够使不同的cell对象处在不同的缓存行中，防止一个线程的cell的修改导致其他线程的cell失效，防止缓存行的伪缓存问题
#### 具体实现
```java
//累加方法
public void increment() {  
    this.add(1L);  
}

public void add(long x) {  
    Striped64.Cell[] cs;  
    long b;  
    //如果cell数组不为空，说明已经有了竞争，或者cell数组为空但cas给base累加失败了，也说明发生竞争，那么就要给当前线程的cell对象进行累加
    if ((cs = this.cells) != null || !this.casBase(b = this.base, b + x)) {  
	    //获取线程哈希值
        int index = getProbe();  
        boolean uncontended = true;  
        long v;  
        int m;  
        Striped64.Cell c;  
        //如果cell数组本身就为空，或者cell数组不为空对应线程的cell为空，或者线程对应的cell进行累加时失败，进入longAccumulate
        if (cs == null || (m = cs.length - 1) < 0 || (c = cs[index & m]) == null || !(uncontended = c.cas(v = c.value, v + x))) {  
            this.longAccumulate(x, (LongBinaryOperator)null, uncontended, index);  
        }  
    }  
  
}
```
```java
final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended, int index) {  
    while(true) {  
        Cell[] cs;  
        int n;  
        long v;  
        //如果cell数组不为空
        if ((cs = this.cells) != null && (n = cs.length) > 0) {  
            Cell c;  
            //但是线程对应的cell对象为空，那就要给线程创建cell对象
            if ((c = cs[n - 1 & index]) == null) {  
	            //如果当前没有人加锁
                if (this.cellsBusy == 0) {  
                    Cell r = new Cell(x);
                    //如果cas修改cellsBusy成功，相当于加锁成功
                    if (this.cellsBusy == 0 && this.casCellsBusy()) {  
                        try {  
                            Cell[] rs;  
                            int m;  
                            int j;  
                            //再判断一次有没有cell数组、对应的cell
                            if ((rs = this.cells) == null || (m = rs.length) <= 0 || rs[j = m - 1 & index] != null) {  
	                            //如果已经有别的线程先创建出了对应的cell，那么对于自己的累加操作就要进入下一轮循环进行
                                continue;  
                            }  
							//赋值
                            rs[j] = r;  
                            break;  
                        } finally {  
	                        //释放锁，由于没有加锁成功的线程不会进入到这里，所以不需要cas解锁
                            this.cellsBusy = 0;  
                        }  
                    }  
                }  
  
                collide = false;  
            } else {  
	            //如果线程的cell对象不为空则进行cas自加，成功则退出
                if (c.cas(v = c.value, fn == null ? v + x : fn.applyAsLong(v, x))) {  
                    break;  
                }  
            }  
  
            index = advanceProbe(index);  
            //如果当前没有加锁，且cell数组不存在且没有被修改过（==判断地址是否改变），且加锁成功
        } else if (this.cellsBusy == 0 && this.cells == cs && this.casCellsBusy()) {  
            try {  
	            //再次判断有没有创建cell数组
                if (this.cells == cs) {  
	                //创建一个cell数组，并把自己对应的cell对象赋值，然后修改LongAdder的原本的cell数组
                    Cell[] rs = new Cell[2];  
                    rs[index & 1] = new Cell(x);  
                    this.cells = rs;  
                    break;  
                }  
            } finally {  
	            //解锁
                this.cellsBusy = 0;  
            }  
            //加锁失败，在base上累加，失败则下一轮尝试
        } else if (this.casBase(v = this.base, fn == null ? v + x : fn.applyAsLong(v, x))) {  
            break;  
        }  
    }  
  
}
```
- 如果cell数组为空，或者不为空但是自己线程对应的cell没有，或者有cell对象但是cas累加失败，进入重新累加，或者先创建出cell数组和自己的cell对象
- 判断cell数组是否为空
	- 不为空
		- 判断是否自己线程的cell为空
			- 为空，则cas加锁尝试新建，加锁失败进入下一轮循环重试，如果成功再次判断有没有自己的cell对象
				- 没有则新建
				- 有说明有线程捷足先登，别的线程已经通过新建的方式实现了它自己的累加，对于自己的累加则进入下一轮循环重试
			- 自己的cell不为空，则cas尝试累加，失败则进入下一轮循环
- 如果当前cell数组为空，且cas加锁成功
	- 再次判断一下cas有没有别的线程捷足先登创建出来
		- 没有，则自己创建数组和自己的cell
		- 有了，则进入下一轮循环，看是新建自己的cell对象还是在基础上累加
- 如果cell数组为空，自己还没有加锁成功，则进入下一轮循环重试，看怎么回事

### 2. ReentrantLock
#### 成员变量及内部类
```java
//主要实现了锁功能的内部类对象
private final Sync sync;  
//默认是非公平
public ReentrantLock() {  
    this.sync = new NonfairSync();  
}  
//有参构造
public ReentrantLock(boolean fair) {  
    this.sync = (Sync)(fair ? new FairSync() : new NonfairSync());  
}
```
```java
//继承了AQS
abstract static class Sync extends AbstractQueuedSynchronizer
//非公平锁，不用排队
static final class NonfairSync extends Sync
//公平锁，严格排队
static final class FairSync extends Sync
```
#### NonfairSync
```java
//ReentrantLock#lock
public void lock() {  
    this.sync.lock();  
}
//Sync#lock
final void lock() {
	//初始尝试获取（在锁空闲状态下的尝试）
    if (!this.initialTryLock()) {  
	    //失败之后，再试一次
        this.acquire(1);  
    }  
}
//初始尝试获取
final boolean initialTryLock() {  
	//当前线程
    Thread current = Thread.currentThread();  
    //cas成功
    if (this.compareAndSetState(0, 1)) {  
	    //标记当前占有锁的线程
        this.setExclusiveOwnerThread(current);  
        return true;  
        //如果cas失败，但是当前持有锁的线程就是自己，则重入
    } else if (this.getExclusiveOwnerThread() == current) {  
        int c = this.getState() + 1;  
        if (c < 0) {  
            throw new Error("Maximum lock count exceeded");  
        } else {  
            this.setState(c);  
            return true;  
        }  
    } else {  
        return false;  
    }  
}
//再次尝试获取
public final void acquire(int arg) {  
	//再次尝试获取
    if (!this.tryAcquire(arg)) { 
	    //还是失败，循环等待获取锁，代码太长放在后面了
        this.acquire((Node)null, arg, false, false, false, 0L);  
    }  
  
}
```
```java
//NonfairSync#tryAcquire，第二次尝试获取
protected final boolean tryAcquire(int acquires) {  
	//如果当前重入次数为0（即是否有线程持有锁），且CAS替换state成功则获取锁
    if (this.getState() == 0 && this.compareAndSetState(0, acquires)) {  
        this.setExclusiveOwnerThread(Thread.currentThread());  
        return true;  
    } else {  
        return false;  
    }  
}
```
#### FairSync
```java
//初次尝试获取
final boolean initialTryLock() {  
    Thread current = Thread.currentThread();  
    int c = this.getState();  
    if (c == 0) {  
	    //自己前面还有没有别的线程要获取（先来先获取），且cas成功
        if (!this.hasQueuedThreads() && this.compareAndSetState(0, 1)) {  
            this.setExclusiveOwnerThread(current);  
            return true;  
        }  
        //重入
    } else if (this.getExclusiveOwnerThread() == current) {  
        ++c;  
        if (c < 0) {  
            throw new Error("Maximum lock count exceeded");  
        }  
  
        this.setState(c);  
        return true;  
    }  
  
    return false;  
}
//第二次尝试获取
protected final boolean tryAcquire(int acquires) {  
	//判断重入次数、队列中是否由比自己更靠前的线程（先来的先获取锁），然后判断CAS是否成功
    if (this.getState() == 0 && !this.hasQueuedPredecessors() && this.compareAndSetState(0, acquires)) {  
	    //设置当前持有锁的线程
        this.setExclusiveOwnerThread(Thread.currentThread());  
        return true;  
    } else {  
        return false;  
    }  
}
```

#### 循环获取
```java
final int acquire(Node node, int arg, boolean shared, boolean interruptible, boolean timed, long time) {  
    Thread current = Thread.currentThread();  
    byte spins = 0;  
    byte postSpins = 0;  
    boolean interrupted = false;  
    boolean first = false;  
    Node pred = null;  
  
    label139:  
    do {  
        while(true) {  
            while(true) {  
                while(true) {  
                    while(true) {  
                        while(true) {  
                            while(!first) {  
	                            //拿到前置节点
                                Node var10000 = node == null ? null : ((Node)node).prev;  
                                pred = var10000;
                                //前置节点为空，或者前置节点就是对头，退出  
                                if (var10000 == null || (first = this.head == pred)) {  
                                    break;  
                                }  
                                //如果前直节点取消了，status<0，要把它取消掉
                                if (pred.status < 0) {  
								    this.cleanQueue();  
								}
                            }  
							//前置为空或者前置为头，自己可以拿锁
                            if (first || pred == null) {  
                                boolean acquired;  
                                if (acquired) {  
                                    if (first) {  
	                                    //自己变成头
                                        ((Node)node).prev = null;  
                                        this.head = (Node)node;  
                                        pred.next = null;  
                                        ((Node)node).waiter = null;  
                                        if (shared) {  
	                                        //唤醒需要唤醒的后继节点
                                            signalNextIfShared((Node)node);  
                                        }  
										//如果被打断了，再调用一次，让打断状态变为true
                                        if (interrupted) {  
                                            current.interrupt();  
                                        }  
                                    }  
  
                                    return 1;  
                                }  
                            }  
  
                            Node t;  
                            //获取失败或首次进入队列，则进入队尾，调用park等待，并把前置节点的status置  为-1，表示有责任唤醒它这个后继节点
                            if ((t = this.tail) != null) {  
                                
                            } else if (this.tryInitializeHead() == null) {  
                                return this.acquireOnOOME(shared, arg);  
                            }  
                        }  
                    }  
                }  
            }  
        }  
        //循环前提是，当前线程没有被打断
    } while(!(interrupted |= Thread.interrupted()) || !interruptible);
	//线程被打断，线程取消获取锁，从队列中移除  
    return this.cancelAcquire((Node)node, interrupted, interruptible);  
}
```
需要注意的是，在前两次尝试获取锁失败之后，进入循环等待获取时才会将线程放入队列中
#### unlock
```java
public void unlock() {  
    this.sync.release(1);  
}
public final boolean release(int arg) { 
	//尝试释放锁（完全释放-没有锁重入了）
    if (this.tryRelease(arg)) {
	    //释放后唤醒后继节点  
        signalNext(this.head);  
        return true;  
    } else {  
        return false;  
    }  
}
protected final boolean tryRelease(int releases) {  
	//如果当前持有锁的线程不是自己则抛异常
    if (!this.isHeldExclusively()) {  
        throw new IllegalMonitorStateException();  
    } else {  
	    //计算释放锁后的state的值
        int nextc = this.getState() - releases;  
        //判断锁是否完全释放，例如锁重入的情况
        boolean free = exclusiveCount(nextc) == 0;  
        if (free) {  
	        //如果锁完全释放，则将锁的占有者释放
            this.setExclusiveOwnerThread((Thread)null);  
        }  
	   //设置新的state值
        this.setState(nextc);  
        return free;  
    }  
}
```
#### 打断
- 默认是不可打断（`lock`方法），只要线程还在队列中就不会被外界执行打断方法而被中断，只有被移除队列后才会被中断
- 如果是可打断模式（`lockInterruptibly`方法），则在外界执行打断方法后，会抛出异常并中断，还有`tryLock(long time, TimeUnit unit)`方法，在超过获取时间后就会被中断

#### ReentrantLock的条件变量
```java
public Condition newCondition() {  
    return this.sync.newCondition();  
}
final AbstractQueuedSynchronizer.ConditionObject newCondition() {  
    return new AbstractQueuedSynchronizer.ConditionObject(this);  
}
```
##### Condition的成员变量
```java
//头尾节点
private transient ConditionNode firstWaiter;  
private transient ConditionNode lastWaiter;
```
维护了一个等待链表
##### await
```java
public final void await() throws InterruptedException {  
    if (Thread.interrupted()) {  
        throw new InterruptedException();  
    } else {  
	    //创建一个链表节点
        ConditionNode node = this.newConditionNode();  
        if (node != null) {  
	        //获取这个node关联的线程，将这个node放入等待队列，然后完全释放占用的ReentranLock的锁（可能有重入）并唤醒后继节点
            int savedState = this.enableWait(node);  
            LockSupport.setCurrentBlocker(this);  
            boolean interrupted = false;  
            boolean cancelled = false;  
            boolean rejected = false;  
			//判断当前是否被sginal转移到AQS队列中即被unpark唤醒，是则退出循环
            while(!this.canReacquire(node)) {  
	            //如果等待被中断直接退出
                if (interrupted |= Thread.interrupted()) {  
                    if (cancelled = (node.getAndUnsetStatus(2) & 2) != 0) {  
                        break;  
                    }  
                } else if ((node.status & 2) != 0) {  
		                //LockSupport.park();阻塞住
						ForkJoinPool.managedBlock(node);  
                }  
            }  
  
            //清理节点状态  
            node.clearStatus();  
            //尝试循环获取锁，拿到锁之后才能退出await
            AbstractQueuedSynchronizer.this.acquire(node, savedState, false, false, false, 0L);  
            //处理中断
            if (interrupted) {  
                if (cancelled) {  
                    this.unlinkCancelledWaiters(node);  
                    throw new InterruptedException();  
                }  
  
                Thread.currentThread().interrupt();  
            }  
  
        }  
    }  
}
```
##### signal
```java
public final void signal() {  
    ConditionNode first = this.firstWaiter;  
    //如果调用signal的不是持有锁的线程就抛出异常
    if (!AbstractQueuedSynchronizer.this.isHeldExclusively()) {  
        throw new IllegalMonitorStateException();  
    } else {  
        if (first != null) {  
	        //把等待的线程添加进AQS队列中并调用unpark唤醒线程
            this.doSignal(first, false);  
        }  
  
    }  
}
```

### 3. ReentrantReadWriteLock
- 有了读锁不可以获取写锁，有了写锁可以获取读锁
- 读锁可以有多个且可以多个线程持有且可以重入，写锁只能由一个线程持有也可以重入
- `state`高 16 位读锁计数 + 低 16 位写锁计数
- 共用同一个阻塞队列
- 当在没有写锁情况下，读锁数量上限达到65535，只有当这65535个读锁全部释放才能唤醒后继节点，有写锁情况下，写锁完全释放就可以唤醒后继节点
```java
ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
public ReentrantReadWriteLock(boolean fair) {  
	//默认非公平
    this.sync = (Sync)(fair ? new FairSync() : new NonfairSync());  
    this.readerLock = new ReadLock(this);  
    this.writerLock = new WriteLock(this);  
}
public WriteLock writeLock() {  
    return this.writerLock;  
}  
public ReadLock readLock() {  
    return this.readerLock;  
}

abstract static class Sync extends AbstractQueuedSynchronizer{
	//ThreadLocal<HoldCounter>的子类，每个线程都有一个HoldCounter计数器，来记录这个线程的读锁重入次数
	private transient ThreadLocalHoldCounter readHolds = new ThreadLocalHoldCounter();  
	//缓存最近一次成功获取读锁的线程的HoldCounter，不用频繁去ThreadLocal里查
	private transient HoldCounter cachedHoldCounter;  
	//第一个获取读锁的线程，一般情况下只有一个线程频繁获取读锁，所有直接记录，不用在readHolds里查
	private transient Thread firstReader;
	//专门用一个int存第一个获取读锁的线程的读锁重入次数  
	private transient int firstReaderHoldCount;
}
```
需要注意的是ReentrantReadWriteLock内部的Sync，有以上特殊的成员变量

#### ReadLock
##### 构造方法
```java
//拿到ReentrantReadWriteLock的同步模式
protected ReadLock(ReentrantReadWriteLock lock) {  
    this.sync = lock.sync;  
}
```
##### lock
```java
public void lock() {  
	//使用ReentrantReadWriteLock同步模式获取共享锁（获取一个）
    this.sync.acquireShared(1);  
}
public final void acquireShared(int arg) {  
	//尝试获取共享锁
    if (this.tryAcquireShared(arg) < 0) {  
	    //失败则循环等待获取
        this.acquire((Node)null, arg, true, false, false, 0L);  
    }  
  
}
protected final int tryAcquireShared(int unused) {  
    Thread current = Thread.currentThread();  
    int c = this.getState();  
    //如果独占线程的数量不为0，即现在有写锁存在，且写锁当前的持有者不是自己
    //由于写锁存在不能获取读锁，且自己没有写锁不能拿到读锁，则获取读锁失败
    if (exclusiveCount(c) != 0 && this.getExclusiveOwnerThread() != current) {  
        return -1;  
    } else {  
	    //当前读锁数量
        int r = sharedCount(c);  
        //判断当前是否允许线程插队拿读锁（公平/非公平模式），且读锁数量没有超过上限，且cas成功
        if (!this.readerShouldBlock() && r < 65535 && this.compareAndSetState(c, c + 65536)) {  
            if (r == 0) {  
	            //如果当前数量为0，说明当前线程为首个读者，并单独用一个int值计数
                this.firstReader = current;  
                this.firstReaderHoldCount = 1;  
            } else if (this.firstReader == current) {  
	            //如果当前数量不为0，但是首个读者，直接++
                ++this.firstReaderHoldCount;  
            } else {  
	            //拿到最近一次获取读锁的线程的计数器
                HoldCounter rh = this.cachedHoldCounter;  
                //比较是不是当前线程的计数器或者新来的
                if (rh != null && rh.tid == LockSupport.getThreadId(current)) {  
                    if (rh.count == 0) {  
	                    //count为0，说明是最新来的线程，创建一个计数器，并放入readHolds
                        this.readHolds.set(rh);  
                    }  
                } else {  
	                //如果不是当前线程的计数器则找到对应的计数器
                    this.cachedHoldCounter = rh = (HoldCounter)this.readHolds.get();  
                }  
				//计数器++
                ++rh.count;  
            }  
  
            return 1;  
        } else {  
	        //否则，写锁持有者拿到读锁
            return this.fullTryAcquireShared(current);  
        }  
    }  
}

final int fullTryAcquireShared(Thread current) {  
    HoldCounter rh = null;  
    int c;  
    do {  
        c = this.getState();  
        if (exclusiveCount(c) != 0) {  
	        //写锁持有者不是自己，获取失败
            if (this.getExclusiveOwnerThread() != current) {  
                return -1;  
            }  
            //如果持有者是自己，但自己不是首个读者
        } else if (this.readerShouldBlock() && this.firstReader != current) {  
	        //判断最近一次的计数器是不是当前线程的
            if (rh == null) {  
                rh = this.cachedHoldCounter;  
                //从来没有线程拿读锁或者计数器不是自己的
                if (rh == null || rh.tid != LockSupport.getThreadId(current)) {
	                //拿到自己的  
                    rh = (HoldCounter)this.readHolds.get();  
                    //自己的读锁已经释放完，则移除
                    if (rh.count == 0) {  
                        this.readHolds.remove();  
                    }  
                }  
            }  
			  
            if (rh.count == 0) {  
                return -1;  
            }  
        }  
		//达到最大读锁数量，拿不了了
        if (sharedCount(c) == 65535) {  
            throw new Error("Maximum lock count exceeded");  
        }  
        //cas没成功（写锁数量不变，读锁数量加1），循环
    } while(!this.compareAndSetState(c, c + 65536));  
    //剩下的逻辑就和tryAcquireShared一样了
    if (sharedCount(c) == 0) {  
        this.firstReader = current;  
        this.firstReaderHoldCount = 1;  
    } else if (this.firstReader == current) {  
        ++this.firstReaderHoldCount;  
    } else {  
        if (rh == null) {  
            rh = this.cachedHoldCounter;  
        }  
  
        if (rh != null && rh.tid == LockSupport.getThreadId(current)) {  
            if (rh.count == 0) {  
                this.readHolds.set(rh);  
            }  
        } else {  
            rh = (HoldCounter)this.readHolds.get();  
        }  
  
        ++rh.count;  
        this.cachedHoldCounter = rh;  
    }  
  
    return 1;  
}
```
##### unlock
```java
public void unlock() {  
    this.sync.releaseShared(1);  
}
public final boolean releaseShared(int arg) {  
	//完全释放所有的读写锁
    if (this.tryReleaseShared(arg)) {
	    //唤醒后继节点  
        signalNext(this.head);  
        return true;  
    } else {  
        return false;  
    }  
}
protected final boolean tryReleaseShared(int unused) { 
	//当前释放读锁的线程
    Thread current = Thread.currentThread();  
    int nextc;  
    //判断是否为首个读者，并判断其计数器会不会减为零，为零就把首个读者置为空
    if (this.firstReader == current) {  
        if (this.firstReaderHoldCount == 1) {  
            this.firstReader = null;  
        } else {  
            --this.firstReaderHoldCount;  
        }  
    } else {  
	    //依旧判断当前线程的计数器和缓存计数器
        HoldCounter rh = this.cachedHoldCounter;  
        if (rh == null || rh.tid != LockSupport.getThreadId(current)) {  
            rh = (HoldCounter)this.readHolds.get();  
        }  
  
        nextc = rh.count;  
        if (nextc <= 1) {  
            this.readHolds.remove();  
            if (nextc <= 0) {  
                throw unmatchedUnlockException();  
            }  
        }  
		//计数器--
        --rh.count;  
    }  
  
    int c;  
    do {  
        c = this.getState();  
        nextc = c - 65536;  
        //cas设置新的state，读锁数量减1，写锁数量不变
    } while(!this.compareAndSetState(c, nextc));  
	//当前的所有读写锁都释放
    return nextc == 0;  
}
```

#### WriteLock
##### lock
```java
public void lock() {  
    this.sync.acquire(1);  
}
//尝试获取
public final void acquire(int arg) {  
    if (!this.tryAcquire(arg)) {  
	    //失败后循环重试
        this.acquire((Node)null, arg, false, false, false, 0L);  
    }  
}
protected final boolean tryAcquire(int acquires) {  
    Thread current = Thread.currentThread();  
    int c = this.getState();  
    //当前写锁数量
    int w = exclusiveCount(c);  
    if (c != 0) {  
	    //如果已经有了写锁而且是自己，锁重入
        if (w != 0 && current == this.getExclusiveOwnerThread()) {  
	        //超出数量，抛异常
            if (w + exclusiveCount(acquires) > 65535) {  
                throw new Error("Maximum lock count exceeded");  
            } else {  
	            //否则重入，重新设置state
                this.setState(c + acquires);  
                return true;  
            }  
        } else {  
	        //如果写锁持有者不是自己，获取失败
            return false;  
        }  
	    //如果现在没有写锁，判断是否允许插队，进行cas
    } else if (!this.writerShouldBlock() && this.compareAndSetState(c, c + acquires)) {  
	    //成功则设置独占线程持有者是自己
        this.setExclusiveOwnerThread(current);  
        return true;  
    } else {  
        return false;  
    }  
}
```
##### unlock
```java
public void unlock() {  
    this.sync.release(1);  
}
public final boolean release(int arg) {  
    if (this.tryRelease(arg)) {  
	    //唤醒后继节点
        signalNext(this.head);  
        return true;  
    } else {  
        return false;  
    }  
}
protected final boolean tryRelease(int releases) {  
	//如果解锁的线程不是写锁持有者，抛出异常
    if (!this.isHeldExclusively()) {  
        throw new IllegalMonitorStateException();  
    } else {  
	    //计算释放写锁后的state值
        int nextc = this.getState() - releases;  
        boolean free = exclusiveCount(nextc) == 0;
        //如果写锁数量为0，则写锁完全释放，独占线程置为null
        if (free) {  
            this.setExclusiveOwnerThread((Thread)null);  
        }  
		//设置新的值
        this.setState(nextc);  
        //如果写锁完全释放，其他线程就可以加读锁或者抢写锁，可以唤醒后继节点
        return free;  
    }  
}
```

### 4. CountDownLatch
- 内部的Sync依旧继承了AQS
- countDown方法就是将state的值减一
- await方法就是循环等待（park）获取锁，也就是当state为0的时候获取到锁，进行唤醒

### 5. 原子类

#### AtomicInteger、AtomicLong
基本的数据类型的原子类
```java
AtomicInteger i=new AtomicInteger(1);  
int i1 = i.get();  
i.compareAndSet(i1,i1*10);  //CAS比较并修改
int andGet = i.updateAndGet(value -> value * 100);//自定义修改，本质上是一个while循环：获取值，比较并修改
i.incrementAndGet();//自加后获取
```

#### AtomicReference
针对于复杂数据类型的原子类
```java
AtomicReference<userService> atomicReference=new AtomicReference<>();
atomicReference.get();//获取引用的对象
```

#### AtomicStampedReference
同样用于复杂数据类型，但是带有版本号，在CAS时需要传入版本号，防止在校验时其他线程进行了修改，最后修改回原来数值，但是当前线程没有感知到
```java
AtomicStampedReference<userService> atomicStampedReference=new AtomicStampedReference<>(new userService(),0);  //设置初始版本号为0
userService reference = atomicStampedReference.getReference();  
//获取版本号
int stamp = atomicStampedReference.getStamp();  
//修改后版本号+1
atomicStampedReference.compareAndSet(reference,new userService(),stamp,stamp+1);
```

#### AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray
用于数组的原子类
```java
AtomicIntegerArray atomicIntegerArray=new AtomicIntegerArray(10);  
AtomicLongArray atomicLongArray=new AtomicLongArray(10);  //普通的数组
AtomicReferenceArray<userService> atomicReferenceArray=new AtomicReferenceArray<>(10);//复杂类型数组
userService userService = atomicReferenceArray.get(0);  //获取元素和CAS时不仅要提供原来的值，还要有值所在的索引，以便比较
atomicReferenceArray.compareAndSet(0,userService,new userService());
```

#### AtomicReferenceFieldUpdater
用于类对象的字段的原子类
```java
//需要提供类的class对象，以便利用其访问到常量池中的字段信息，还有字段的类型，字段名
AtomicReferenceFieldUpdater<userService, String> updater = AtomicReferenceFieldUpdater.newUpdater(userService.class, String.class, "name");  
userService userService = new userService();  
updater.compareAndSet(userService, "1", "2");
```

### 6. ConcurrentHashMap
在jdk1.7之前是数组加链表的结构，在之后是和HashhMap一样的结构
#### 1.7ConcurrentHashMap
```txt
ConcurrentHashMap
      |
      v
+----------------------------+
|        Segment[]          |   （默认长度 16）
+----------------------------+
     |       |       |
     v       v       v
  Segment  Segment  Segment  ...
     |
     v
+------------------------+
|      HashEntry[]      |     （每个 Segment 内部一个桶数组）
+------------------------+
     |      |      |
     v      v      v
  Entry   Entry   Entry   ...
    ↓
  Entry
    ↓
  Entry
（链表结构）
```
- Segment数组不像1.8版本的，它是在调用构造方法的时候就创建好了
- 插入或扩容使用的**只有ReentrantLock**
- 在插入的时候会先用key的哈希码的高四位，和内部的mark变量（第四位的掩码）做&运算找到对应Segment元素的哈希表，然后才去找哈希表找对应的桶
- Segment的每个元素是一个`HashEntry[]`数组真正存储数据
- 它的每个元素存储桶，Segment数组无法扩容，但是`HashEntry[]`是可以扩容的
- 插入数据或扩容时直接锁住的是一个Segment元素也就是一整个`HashEntry[]`数组，性能低下
##### 死链
```txt
//原来的桶
OldTable[i] -> A -> B -> null
//t1把头结点A插入，此时旧桶的头结点成了B
NewTable[j] -> A -> null
//t2此时过来迁移，但是旧桶的头节点已经变成了B
NewTable[j] -> B -> A -> null
//t2再次准备迁移的时候，因为它认为旧桶里的B是头结点，所以要把它的next节点头插进新的桶，让B成为next的next，但是B的next是A，但是A已经在新桶中了，会导致A成为头结点之后，它的next又指回了B
NewTable[j] -> A -> B -> A -> ...
```
1. **扩容逻辑**
    - 扩容时，线程会把旧桶中的链表搬到新桶。
    - 使用 **头插法**：遍历旧链表，从头到尾，把节点依次插到新桶的链表头。
2. **并发场景**
    - 假设旧表某个桶链表有两个节点：A → B。
    - 线程 T1、T2 同时扩容迁移：
        - T1 先处理 A，插入新桶，链表变成 A。
        - T2 先处理 B，插入新桶，链表变成 B。
        - 然后 T1 处理 B，把 B 插到新桶的头，形成 B → A。
        - 再 T2 处理 A，把 A 插到新桶的头，形成 A → B → A ……
    这样，就出现了一个 **环形链表**。
3. **后果**
    - 任何线程再去查找或遍历这个桶时，就会在环里无限循环，CPU 飙高，程序卡死。
#### 1.8ConcurrentHashMap
```txt
ConcurrentHashMap
┌────────────────────────────────────────────────────────────────────────────┐
│                                   table                                    │
│                      (Node<K,V>[]，长度为2的幂次)                           │
├────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┤
│ Node0  │ Node1  │ Node2  │ Node3  │ Node4  │ Node5  │ Node6  │ Node7  │ ...
│  ↓         ↓        ↓        ↓        ↓        ↓        ↓        ↓
│ 链表/树  链表/空  空      链表     树      空      链表     空
│         ↑       ↑                ↑      ↑              ↑
│       (CAS+锁机制，节点扩容/插入时互不阻塞，分段控制)        ...
└────────────────────────────────────────────────────────────────────────────┘
```
```java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;      // key的哈希值
    final K key;
    volatile V val;      // volatile保证可见性
    volatile Node<K,V> next; // 链表结构 or 红黑树 TreeNode
}
```
内部节点的结构和HashMap的node不同，val和next指针是volatile修饰的线程可见
- 插入或扩容过程通过 **CAS + synchronized（锁分段）** 保证线程安全和性能
- 在插入或修改的时候先用CAS进行操作，例如在插入时，如果桶为空，则CAS直接成功
- 如果CAS失败，则把桶的链表的头结点或红黑树的根节点用synchronized锁住再操作
- **在扩容时必定会使用synchronized**，因为会使用**多线程来进行数据迁移**，每个线程分配一段**桶区间**，一个线程在处理区间的时候会用synchronized锁住当前遍历到的桶节点，保证一个桶只能由一个线程来操作
	- 在数据迁移过程在如果一个桶的数据已经迁移完成，则会将这个桶替换成ForwardingNode，它并不存储数据，只是标记这个桶已经完成迁移，其他线程迁移遇到这个ForwardingNode就会直接跳过，或者当其他线程读取这个桶的数据时就知道要去新表里面查
- 在**链表转换成红黑树**的时候也会有**synchronized**锁住桶的头结点
- 不允许k，v存储null，但是hashMap可以
##### get
```java
public V get(Object key) {  
	//拿到key的正数哈希码，对于负数的哈希码有别的作用
    int h = spread(key.hashCode());  
    Node[] tab;  
    Node e;  
    int n;  
    //如果哈希表不为空，就进入查，否则直接返回null
    if ((tab = this.table) != null && (n = tab.length) > 0 && (e = tabAt(tab, n - 1 & h)) != null) {  
        int eh;  
        Object ek;  
        //桶的头结点
        //如果哈希码本身就是正数，说明桶里的是一个链表
        if ((eh = e.hash) == h) {  
	        //头结点就是
            if ((ek = e.key) == key || ek != null && key.equals(ek)) {  
                return e.val;  
            }  
        } else if (eh < 0) {  
            Node p;  
            //哈希码本身是负数，去新的表里找或者找树节点
            return (p = e.find(h, key)) != null ? p.val : null;  
        }  
		//正常遍历链表
        while((e = e.next) != null) {  
            if (e.hash == h && ((ek = e.key) == key || ek != null && key.equals(ek))) {  
                return e.val;  
            }  
        }  
    }  
  
    return null;  
}
```
##### put
```java
final V putVal(K key, V value, boolean onlyIfAbsent) {  
    if (key != null && value != null) {  
        int hash = spread(key.hashCode());  
        int binCount = 0;  
        Node<K, V>[] tab = this.table;  
  
        while(true) {  
            int n;  
            //哈希表还没有初始化，进行初始化
            while(tab == null || (n = tab.length) == 0) {  
                tab = this.initTable();  
            }  
  
            Node f;  
            int i;  
            //如果找到的桶式空的，cas插入就够了，不用加锁，节省资源
            if ((f = tabAt(tab, i = n - 1 & hash)) == null) {  
                if (casTabAt(tab, i, (Node)null, new Node(hash, key, value))) {  
                    break;  
                }  
            } else {  
                int fh;  
                //正在扩容
                if ((fh = f.hash) == -1) {  
	                //该线程帮忙去扩容，扩容结束后进入下一轮循环再插入
                    tab = this.helpTransfer(tab, f);  
                } else {  
                    Object fk;  
                    Object fv;  
                    if (onlyIfAbsent && fh == hash && ((fk = f.key) == key || fk != null && key.equals(fk)) && (fv = f.val) != null) {  
                        return fv;  
                    }  
  
                    V oldVal = null;  
                    //锁住桶的头结点
                    synchronized(f) {  
	                    //再次判断头结点有没有被移动
                        if (tabAt(tab, i) == f) {  
	                        //哈希码小于0，桶里是树
                            if (fh < 0) {  
	                            //把节点转换成树节点存入
                                if (f instanceof TreeBin) {  
                                    binCount = 2;  
                                    TreeNode p;  
                                    if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) {  
                                        oldVal = p.val;  
	                                    //替换
                                        if (!onlyIfAbsent) {  
                                            p.val = value;  
                                        }  
                                    }  
                                } 
                            } else {  
	                            //往链表里存
                                label124: {  
                                    binCount = 1;  
  
                                    Node e;  
                                    Object ek;  
                                    for(e = f; e.hash != hash || (ek = e.key) != key && (ek == null || !key.equals(ek)); ++binCount) {  
                                        Node<K, V> pred = e;  
                                        //没找到，尾部添加一个
                                        if ((e = e.next) == null) {  
                                            pred.next = new Node(hash, key, value);  
                                            break label124;  
                                        }  
                                    }  
  
                                    oldVal = e.val;  
                                    //替换
                                    if (!onlyIfAbsent) {  
                                        e.val = value;  
                                    }  
                                }  
                            }  
                        }  
                    }  
				   //binCount表示链表长度
                    if (binCount != 0) {  
                        if (binCount >= 8) {  
	                        //链表变成红黑树
                            this.treeifyBin(tab, i);  
                        }  
  
                        if (oldVal != null) {  
                            return oldVal;  
                        }  
                        break;  
                    }  
                }  
            }  
        }  
		//增加元素个数，和LongAdder累加器的原理一致，如果某这个线程的cell的大小超过了sizeCtl就会触发扩容
        this.addCount(1L, binCount);  
        return null;  
    } else {  
        throw new NullPointerException();  
    }  
}
```
##### 初始化
```java
private final Node<K, V>[] initTable() {  
    Node[] tab;  
    while((tab = this.table) == null || tab.length == 0) {  
        int sc;  
        //sizeCtl>0表示下一次触发扩容的阈值大小，=0表示还没有初始化，<0表示正在初始化当中
        //如果正在初始化就等别的线程初始化完成
        if ((sc = this.sizeCtl) < 0) {  
            Thread.yield();  //让出cpu使用权
            //否则自己cas成功后，自己来初始化
        } else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) {  
            try {  
                if ((tab = this.table) == null || tab.length == 0) {  
                    int n = sc > 0 ? sc : 16;  
                    Node<K, V>[] nt = new Node[n];  
                    tab = nt;  
                    this.table = nt;  
                    sc = n - (n >>> 2);  
                }  
                break;  
            } finally {  
                this.sizeCtl = sc;  
            }  
        }  
    }  
  
    return tab;  
}
```
##### 扩容
```java
//帮忙扩容
final Node<K, V>[] helpTransfer(Node<K, V>[] tab, Node<K, V> f) {  
    Node[] nextTab;  
	//如果当前桶是一个标记过的需要迁移的桶就去迁移
    if (tab != null && f instanceof ForwardingNode && (nextTab = ((ForwardingNode)f).nextTable) != null) {  
	    //生成一个基于表长度的扩容戳，拼接在sizeCtl的高 16 位，用来标识正在进行扩容的表
        int rs = resizeStamp(tab.length) << 16;  
  
        int sc;  
        //若当前表不是新表，则扩容未完成且仍然处于扩容状态
        while(nextTab == this.nextTable && this.table == tab && (sc = this.sizeCtl) < 0 && sc != rs + '\uffff' && sc != rs + 1 && this.transferIndex > 0) {  
	        //把sizeCtl的低 16 位（扩容线程数）加 1
            if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1)) {  
	            //开始迁移
                this.transfer(tab, nextTab);  
                break;  
            }  
        }  
		//返回新表
        return nextTab;  
    } else {  
        return this.table;  
    }  
}
```
##### 迁移
```java
private final void transfer(Node<K, V>[] tab, Node<K, V>[] nextTab){
	int stride;
	//计算迁移步长，即每个线程需要迁移的桶个数，最小16个
	if ((stride = NCPU > 1 ? (n >>> 3) / NCPU : n) < 16) {
	    stride = 16;
	}
	//如果新的表还没有创建，就创建一个
	if (nextTab == null) {
	    Node<K, V>[] nt = new Node[n << 1]; //容量扩大一倍
	    nextTab = nt;
	    this.nextTable = nextTab;
	    this.transferIndex = n; //迁移起始位置
	}
	//在旧表桶搬迁完毕后，把该桶设置为ForwardingNode，别的线程查询数据的时候就知道要去新表里查
	ForwardingNode<K, V> fwd = new ForwardingNode(nextTab);
	//开始迁移桶
	while(true) {
    ...
	    if ((f = tabAt(tab, i)) == null) {
	        // 桶为空 -> 直接放 ForwardingNode 占位
	        advance = casTabAt(tab, i, null, fwd);
	    } else if (f.hash == -1) {
	        // 已经是 ForwardingNode -> 跳过
	        advance = true;
	    } else {
		    //锁住桶的头结点
	        synchronized(f) {
	            if (tabAt(tab, i) == f) {
	                if (fh >= 0) {
	                    // 普通链表拆分迁移
	                } else if (f instanceof TreeBin) {
	                    // 红黑树拆分迁移
	                } else if (f instanceof ReservationNode) {
	                    throw new IllegalStateException("Recursive update");
	                }
	            }
	        }
	    }
	    //通过transferIndex分配任务区间，每次线程拿一段 [nextBound, sc) 的桶负责迁移
	    if ((sc = this.transferIndex) <= 0) {
		    i = -1;
		    advance = false;
		} else {
		    int nextBound;
		    if (U.compareAndSetInt(this, TRANSFERINDEX,
		                           sc, nextBound = sc > stride ? sc - stride : 0)) {
		        bound = nextBound;
		        i = sc - 1;
		        advance = false;
		    }
		}

	}
	//最后重新计算扩容阈值
	if (finishing) {
	    this.nextTable = null;
	    this.table = nextTab; //新表生效
	    this.sizeCtl = (n << 1) - (n >>> 1); //新阈值 = 0.75 * 新容量
	    return;
	}


}
```

|操作|CAS|synchronized|
|---|---|---|
|get()|❌|❌|
|put() 空桶插入|✅ 尝试CAS|❌|
|put() 非空桶插入|❌|✅ 锁住桶头节点|
|put() 更新已有key|❌|✅ 遍历需要锁，赋值本身无需锁|
|扩容 resize|❌|✅ 分段锁+迁移节点|
|链表转红黑树|❌|✅|
### 7. LinkedBlockingQueue
线程安全的
#### 成员变量即构造方法
```java
//用于消费的锁
private final ReentrantLock takeLock;
//用于put的锁
private final ReentrantLock putLock;
//队列不为空的条件变量，在消费时，阻塞住消费线程，被唤醒说明队列不为空了，可以消费了
private final Condition notEmpty;
//没有满的条件变量，在插入时阻塞住插入线程，被唤醒说明队列不是满状态了，可以插入了
private final Condition notFull;
//队列头，不存元素，是一个标识位
transient Node<E> head; 
//最后一个元素
transient Node<E> last;
//默认队列大小无界
public LinkedBlockingDeque() {  
    this(Integer.MAX_VALUE);  
}  
  
public LinkedBlockingQueue(int capacity) {  
    this.count = new AtomicInteger();  
    this.takeLock = new ReentrantLock();  
    this.notEmpty = this.takeLock.newCondition();  
    this.putLock = new ReentrantLock();  
    this.notFull = this.putLock.newCondition();  
    if (capacity <= 0) {  
        throw new IllegalArgumentException();  
    } else {  
        this.capacity = capacity;  
        this.last = this.head = new Node((Object)null);  
    }  
}
```
#### put
```java
public void put(E e) throws InterruptedException {  
    if (e == null) {  
        throw new NullPointerException();  
    } else {  
        Node<E> node = new Node(e);  
        //获取put锁
        ReentrantLock putLock = this.putLock;  
        AtomicInteger count = this.count;  
        putLock.lockInterruptibly();  
  
        int c;  
        try {  
	        //如果队列满了则等待
            while(count.get() == this.capacity) {  
                this.notFull.await();  
            }  
		    //尾插同时唤醒使用了notEmpty条件变量的消费线程
            this.enqueue(node);  
            c = count.getAndIncrement();  
            if (c + 1 < this.capacity) {  
	            //插入完成后，如果没有达到上限，则唤醒其他要插入的线程
                this.notFull.signal();  
            }  
        } finally {  
            putLock.unlock();  
        }  
  
        if (c == 0) {  
	        //先获取消费锁，然后唤醒消费线程
            this.signalNotEmpty();  
        }  
  
    }  
}
```
#### take
```java
//从头部拿
public E take() throws InterruptedException {  
    AtomicInteger count = this.count;  
    //消费者锁
    ReentrantLock takeLock = this.takeLock;  
    //可打断式抢锁
    takeLock.lockInterruptibly();  
  
    Object x;  
    int c;  
    try {  
	    //没有消息则等待
        while(count.get() == 0) {  
            this.notEmpty.await();  
        }  
	    //取出第一个
        x = this.dequeue();  
        c = count.getAndDecrement();  
        if (c > 1) {  
            this.notEmpty.signal();  
        }  
    } finally {  
        takeLock.unlock();  
    }  
  
    if (c == this.capacity) {  
	    //先获取put锁，然后唤醒要put的线程
        this.signalNotFull();  
    }  
  
    return x;  
}
```
- 需要注意：获取第一个元素时，会将head移动至真正存储元素的第一个node也就是head的next
- 并将哨兵的next指向自己，方便GC回收
- 之后将head的item元素取出并返回并将head这个node的item置为null，让其成为新的哨兵

# JVM
## 一. 组成
```txt
┌──────────────────────────────────── JVM ─────────────────────────────────────┐
│                                                                              │
│  ┌────────────── Method Area ───────────────┐     ┌────── Native Method ─────┐│
│  │   类信息（类名、父类名、方法、字段等） │     │   本地方法接口（JNI） ││
│  │   常量池（运行时常量池）               │     │   调用C/C++方法支持    ││
│  │   静态变量、类加载信息等               │     └──────────────────────┘│
│  └─────────────────────────────────────────┘                                │
│                                                                              │
│  ┌────────────── Heap ───────────────┐                                       │
│  │   所有对象实例和数组分配在堆中    │                                       │
│  │   包括：                          │                                       │
│  │   ┌────────── Young Generation ┐ │                                       │
│  │   │ Eden、Survivor From/To区   │ │                                       │
│  │   └────────────────────────────┘ │                                       │
│  │   ┌────────── Old Generation ───┐ │                                       │
│  │   │  长期存活的对象              │ │                                       │
│  │   └─────────────────────────────┘ │                                       │
│  └───────────────────────────────────┘                                       │
│                                                                              │
│  ┌──────────── JVM Stack ─────────────┐                                      │
│  │ 每个线程一个栈，每个方法调用对应  │                                      │
│  │ 一个栈帧（Stack Frame）            │                                      │
│  │ 包含：局部变量表、操作数栈、      │                                      │
│  │ 方法返回地址、异常处理信息等      │                                      │
│  └────────────────────────────────────┘                                      │
│                                                                              │
│  ┌──────────── Program Counter ─────────────┐                                │
│  │ 每个线程一个PC寄存器                  │                                │
│  │ 指向当前线程所执行方法字节码的地址    │                                │
│  └────────────────────────────────────────┘                                │
│                                                                              │
│  ┌────────────── Stack Native (C Stack) ──────────────┐                      │
│  │ 用于支持native方法执行（如JNI调用）               │                      │
│  └────────────────────────────────────────────────────┘                      │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘

```
### 1. 程序计数器
每个线程一个私有的pc寄存器，内部保存字节码的行号，用于记录即将要执行的下一条字节码指令的地址
### 2. 堆
线程共享的区域，保存所有的对象实例和数组，包括伊甸园区，两个幸存者区，一个老年带
在jdk1.7之前Method Area（永久带，包括类信息，常量信息，静态变量）存储在堆中，1.8之后才移至元空间
### 3. 虚拟机栈
	每个线程运行时所需要的内存，就是jvm栈
- 每个线程在启动时，jvm会为它分配一个JVM栈，栈由一组栈帧组成
```txt
┌───────────────────────────────┐
│    局部变量表 (Local Variables)│
│  - 方法参数                    │
│  - 方法内部定义的变量           │
├───────────────────────────────┤
│    操作数栈 (Operand Stack)    │
│  - 用于临时保存计算过程中的中间值 │
│  - 执行指令如 iadd、imul 等     │
├───────────────────────────────┤
│    动态链接 (Dynamic Linking)  │
│  - 指向运行时常量池中当前方法信息 │
│  - 比如方法引用、字段引用等      │
├───────────────────────────────┤
│    方法返回地址 (Return Address)│
│  - 调用者方法的字节码执行位置    │
└───────────────────────────────┘
```
- 每次调用方法时，都会创建一个新的栈帧压栈
- 在一个栈帧执行完成后弹栈，内存释放
- 局部变量表：存放方法参数和方法内局部变量，引用类型对象也会以地址形式存储在这里
- 操作数栈：保存计算过程中的中间值和操作指令
- 动态链接：每个方法在编译时引用的是**常量池中的符号引用，运行时解析成实际地址**，这个信息被存储在动态链接中
- 方法返回地址：当前方法返回后，**继续执行调用者方法的下一条字节码指令的地址**
- 由此可见每调用一次方法都会创建一个栈帧，所以方法内的局部变量如果没有逃离作用范围就是线程安全的，否则就是不安全的
- 栈帧过多、过大都会导致jvm栈内存溢出
### 4. 方法区
- 各个线程共享的内存区域
- 存储类信息、运行时常量池
- 虚拟机开启时创建，关闭时释放
- 如果方法区的内存无法满足分配请求，如类的加载信息放不下了，就会抛出Metaspace内存溢出
- **常量池**可以看作`.class`文件中的一张表，虚拟机指令根据这张表找到要执行的类名，方法名，字面量等，**这些只是描述信息（名字而已）**，**相当于只是一段类路径/方法路径的字符串，不是其本身**
- **运行时常量池**是当类被加载的时，**常量池的信息就会放入运行时常量池，并把符号引用解析为真实地址**，这个解析过程就是**类装载**的过程，由类加载器 → Class 对象 → 方法区，完成解析，得到真实地址
### 5. 直接内存
是 JVM 外的一块内存区域，**不属于堆、也不属于方法区**，是通过 Java 代码（通常是 `ByteBuffer.allocateDirect`）直接向操作系统申请的内存空间
普通的IO操作，需要先将数据批次读到系统内存，再由系统内存写入java堆的缓冲区，java代码无法直接操作系统内存
而直接内存是java代码申请的、可以直接操作的内存，更省时间
## 二. 类加载器
### 1. 概念
**类加载器** 是 JVM 中用来 **将 `.class` 文件读取进内存，并转换为 Class 对象** 的组件，以便jvm能够识别运行
### 2. 双亲委派机制
| 类加载器名       | JVM名称/实现类                       | 加载内容                           |
| ----------- | ------------------------------- | ------------------------------ |
| **引导类加载器**  | `BootstrapClassLoader`（C/C++实现） | 核心类库：`rt.jar`, `java.lang.*` 等 |
| **扩展类加载器**  | `ExtClassLoader`                | JDK 扩展目录下的类（如 `jre/lib/ext/`）  |
| **应用类加载器**  | `AppClassLoader`                | CLASSPATH 下的类（你写的类）            |
| **自定义类加载器** | 继承 `ClassLoader` 写的             | 动态加载类，热部署，解耦（常见于框架、插件）         |
双亲委派机制就是当一个加载器尝试加载一个类的时候，不会自己去加载，而是委派自己的父加载器去加载，如果父加载器也有自己的父加载器就继续向上委托，如果父加载器没有加载该类时，子加载器才会自己去加载
#### 作用
- 防止核心代码被用户代码替换，例如用户自定义的一个叫String的类会被jdk自带的覆盖
- 避免重复加载，如果父加载器已经加载过，就不会重复加载
- springboot、tomcat或插件会人为打破机制，优先自定义加载器加载，不成功再让父加载器加载
### 3. 类装载执行流程
```txt
加载（Load） → 验证（Verify） → 准备（Prepare） → 解析（Resolve） → 初始化（Initialize） → 使用（Use） → 卸载（Unload）
```
#### 加载
java类在编译之后生成.class文件，加载阶段就是将文件从文件系统中去读取成二进制的字节流，并构建成jvm能操作的Class对象
- 通过类的全限定名，找到二进制数据流
- 解析数据流，在**方法区中存储类的结构信息**，在堆**中开辟空间存储这个类的Class对象**，对象的内部结构中持有对方法区（元空间）中类结构信息的**直接引用（指针）**，形成映射关系，作为方法区这个类的各种数据、方法的**访问入口**
- 之后要创建这个类的对象，就能通过这个Class对象去方法区中获得类的构造函数、方法、字段等信息来创建对象，创建出来的对象的对象头**包含它所属的类的Class对象的引用**，从而形成链条，jvm就是通过这个引用来支持对象的反射、方法查找、字段访问等操作
#### 验证
- 文件格式验证
- 元数据验证
- 字节码验证
- 符号引用验证，Class文件**在其常量池通过字符串（符号引用）** 记录自己将要用到的其他类或者方法，检查它们是否存在
#### 准备
为类变量分配内存并设置初始值
```java
static int a=10;  //实际上在这个阶段的默认值是0
static final int b=10;  //直接赋值，下面一样
static final String c= "hello";  
static final Object d= new Object();
```
- static直接修饰的变量，在准备阶段设置默认值，比如int类型就是0，要给a赋值10要在初始化阶段才会执行
- static修饰的final变量，会在这个阶段直接赋值，因为是常量，值已经确定
- static修饰的final引用变量，在这个阶段也会完成赋值
#### 解析
将符号引用转化为真实地址
#### 初始化
优先初始化父类的静态代码块（也就是执行静态代码块）和静态变量，然后是子类的静态代码块和静态变量
当用**子类访问父类的静态变量时，就只会初始化父类**
## 三. 垃圾回收
### 1. 对象什么时候可以被回收
当堆中的对象没有任何的引用指向它时，就可能被定为垃圾被回收
如果堆中的对象身上只有弱引用，在GC的时候也会被回收
如果身上有强引用，就不会被回收
如果没有强引用有软引用，在GC过程中如果内存不足会被回收
#### 引用计数法
每当对象被引用一次，计数器就会加1，如果计数器为0，就会把对象标记为垃圾
#### 可达性分析法（默认）
JVM 通过从一组被称为 **GC Roots** 的对象开始向下搜索，只要某个对象**能从 GC Roots 直接或间接访问到**，就被认为是“可达的（live）”，否则就是垃圾，等待回收
GC Root 是 JVM 认为“永远活着”的对象起点

| GC Root 类型                  | 说明                                                      |
| --------------------------- | ------------------------------------------------------- |
| ✅ **虚拟机栈（栈帧中的局部变量表）中的引用对象** | 方法正在执行的所有局部变量、参数（包括基本类型的包装对象、引用对象）                      |
| ✅ **方法区中类静态属性引用的对象**        | 如 `static Object obj = new Object()`，只要类还被加载，这个静态引用就是活的 |
| ✅ **方法区中常量引用的对象**           | 如 `final static String s = "abc"`；"abc" 可能会被常量池引用       |
| ✅ **本地方法栈中 JNI 引用的对象**      | native 方法中使用的对象，不受 JVM 自动管理，因此视为根                       |
| ✅ **正在运行的线程对象本身**           | 活跃线程对象、线程上下文类加载器等                                       |
| ✅ **Class 对象本身**            | 每个类对应一个 `java.lang.Class` 对象，存在堆中，被类加载器引用，活着            |
| ✅ **被同步锁（monitor）持有的对象**    | 如果对象作为锁 monitor，也会被视为根，避免在同步中被回收                        |
### 2. 四种引用
#### 引用
每当new出一个对象，就会在堆内存中开辟一段空间用来存储这个对象，返回一个引用值交给变量，相当于是指针但不是裸指针，变量只是对堆中对象的引用或者“指向”

#### 四种引用

| 引用类型    | 是否参与 GC 判断     | 被 GC 回收时机            | 典型用途                                 | 是否影响 GC Root 可达性分析 |
| ------- | -------------- | -------------------- | ------------------------------------ | ------------------ |
| **强引用** | ✅ 是            | 只有没有强引用时才会回收         | 普通对象引用，如 `Object obj = new Object()` | ✅ 是                |
| **弱引用** | ✅ 是            | 只要发生 GC 就会被回收        | ThreadLocal 的 key、元数据缓存              | ✅ 是                |
| **软引用** | ✅ 是            | 内存不足时回收（GC 前判断内存压力）  | 缓存（如图片缓存）                            | ✅ 是                |
| **虚引用** | ❌ 否（无法通过它获取对象） | 被 GC 后会收到通知，但本身不阻止回收 | 管理直接内存（配合 `ReferenceQueue`）          | ❌ 否（不能影响可达性）       |
### 3. 回收垃圾算法
#### 标记清除算法
- 先进行可达性分析，标记出要回收的对象然后将标记的对象进行回收
- 标记和清除速度比较快
- 碎片化严重，内存不连续，没有办法存储较大的数组
#### 标记整理算法
和标记清除算法基本一样，但是在清除之后把存活的对象进行了移动整理，让空间变得连贯
由于花费实时间移动对象，所以效率有一定影响
老年代使用
#### 复制算法
将内存分成两块大小相同的区域，将标记的存活的对象**复制**到一个区域，将另一个区域全部清除，复制的过程就完成了空间的整理
### 4. GC过程的分代回收
- 新建对象都会先分配到伊甸园区，伊甸园内存不足时，触发GC，标记**伊甸园和幸存者from**内存活的对象，用复制算法把存活的对象复制到幸存者to中，之后伊甸园和from内存全部释放
- 之后如果伊甸园区又满了，就会标记**伊甸园和to**的活对象，然后采用复制算法把对象复制到from中，依次类推，如果from和to中的对象经历了n次（默认15次，jvm参数可以改）这样的回收之后就会迁移到老年代中
- 如果新生代GC完仍然放不下就会GC老年代，尝试放进老年代，如果老年代也放不进去，就进行堆整体的GC，如果整体GC完还是放不进去就OOM了
- young GC：发生在新生代，会暂停所有线程进行GC，暂停时间短
- Mixed GC：发生在新生代和部分老年代
- Full GC：发生在新生代和全部老年代，暂停时间长
### 5. 垃圾回收器
- 串行垃圾收集器：Serial GC、Serial Old GC
- 并行垃圾收集器：Parallel Old GC、ParNew GC
- CMS（并发）垃圾收集器：CMS GC，作用在老年代
- G1：作用在新生代和老年代
### 6. G1垃圾回收器
- 将堆内存分成了多个小的内存区域，每个区域都能成为伊甸园、幸存者、老年代，初始时，所有区域都是空闲的
- 创建一些对象，挑选出一些空闲区域作为伊甸园存储这些对象（占比是5%~6%）
- 当伊甸园需要垃圾回收时，会挑选出一个空闲区域成为幸存者区，然后进行标记，把存活的对象复制到幸存者中，释放伊甸园，这个过程会暂停用户进程
- 当伊甸园的内存又满了之后，挑选出一个**新的幸存者区**，标记伊甸园和原来幸存者的存活的对象，将存活时间较长的对象晋升到老年代，剩余的复制到新的幸存者区中，然后将伊甸园和原来的幸存者释放
- 当老年代占用内存超过45%之后，触发并发标记，用户线程不会暂停
- 并发标记之后，混合收集，优先收集存活对象少的老年代，将这种老年代里存活的对象复制到新的老年代，将伊甸园、幸存者的存活的对象复制到新的幸存者中，并将存活时间较长的对象复制到新的老年代中，然后释放内存，这个过程会暂停用户线程
- 如果并发标记失败，即回收速度赶不上对象创建的速度则会进行fullgc，标记整体的区域进行回收
- 经过多轮混合收集之后，进入新一轮的新生代回收
- 如果一个对象太大，会分配一块或连续的几块huge区存储
## 四. JVM参数
### 1. 调优参数
#### 内存与堆（重点）

| 参数                               | 说明             | 示例                             |
| -------------------------------- | -------------- | ------------------------------ |
| `-Xms<size>`                     | 初始堆大小          | `-Xms512m`                     |
| `-Xmx<size>`                     | 最大堆大小          | `-Xmx2g`                       |
| `-Xmn<size>`                     | 新生代大小          | `-Xmn512m`                     |
| `-XX:MaxDirectMemorySize=<size>` | 最大直接内存大小（NIO用） | `-XX:MaxDirectMemorySize=256m` |
| `-XX:MetaspaceSize=<size>`       | 元空间初始大小（JDK8+） | `-XX:MetaspaceSize=128m`       |
| `-XX:MaxMetaspaceSize=<size>`    | 元空间最大值         | `-XX:MaxMetaspaceSize=512m`    |
#### 垃圾回收器选择参数

|参数|说明|
|---|---|
|`-XX:+UseSerialGC`|单线程收集器，适合小内存|
|`-XX:+UseParallelGC`|吞吐量优先，默认并行收集器|
|`-XX:+UseConcMarkSweepGC`|CMS 收集器（JDK9弃用）|
|`-XX:+UseG1GC`|G1 收集器（推荐 JDK8 之后）|
|`-XX:+UseZGC`|ZGC（低延迟，JDK11+）|
|`-XX:+UseShenandoahGC`|红帽 Shenandoah（低停顿，JDK12+）|
#### 垃圾回收日志相关参数

| 参数                                             | 说明              |
| ---------------------------------------------- | --------------- |
| `-verbose:gc`                                  | 简单输出GC日志        |
| `-XX:+PrintGCDetails`                          | 输出GC详细信息        |
| `-XX:+PrintGCDateStamps`                       | 输出GC时间戳         |
| `-Xloggc:<file>`                               | 将GC日志写入文件（JDK8） |
| `-Xlog:gc*:file=gc.log:time,uptime,level,tags` | JDK9+ 新日志系统     |
#### JVM 性能与诊断参数（重点）

| 参数                                | 说明                              |
| --------------------------------- | ------------------------------- |
| `-XX:+PrintFlagsFinal`            | 打印所有JVM参数及默认值                   |
| `-XX:+HeapDumpOnOutOfMemoryError` | OOM时生成堆转储文件，文件搭配visualVM的装入功能查看 |
| `-XX:HeapDumpPath=<path>`         | 指定 OOM 转储文件路径                   |
| `-XX:+PrintCompilation`           | 打印JIT编译信息                       |
| `-XX:+PrintClassHistogram`        | 打印类直方图（用于诊断内存）                  |
| `-XX:+UseCompressedOops`          | 压缩普通对象指针（默认开启）                  |
| `-XX:+UseCompressedClassPointers` | 压缩类指针（默认开启）                     |
#### JIT 编译相关参数

|参数|说明|
|---|---|
|`-XX:+TieredCompilation`|分层编译（默认启用）|
|`-XX:CompileThreshold=<n>`|控制热点代码触发编译的阈值|
|`-XX:+PrintInlining`|打印内联优化信息|
#### 线程与栈设置

|参数|说明|
|---|---|
|`-Xss<size>`|每个线程的栈大小，默认1M|
#### 系统稳定性保障

| 参数                             | 说明                   |
| ------------------------------ | -------------------- |
| `-XX:+ExitOnOutOfMemoryError`  | OOM时立即退出JVM（而不是尝试恢复） |
| `-XX:+CrashOnOutOfMemoryError` | OOM时生成错误日志           |
### 2. JVM内存泄漏排查
```cmd
# 查 PID
jps -l

# Dump堆文件，文件搭配visualVM的装入功能查看
jmap -dump:format=b,file=heap.hprof <pid>

# 实时内存监控
jstat -gc <pid> 1000 10

# 强制 Full GC
jcmd <pid> GC.run

# 查看类加载情况
jcmd <pid> GC.class_histogram
```
### 3. CPU飙高
```linux
top # 查看cpu的进程占用情况
ps H -eo pid,tid,%cpu | grep [pid]  # 查看指定进程的所有线程，和线程的cpu使用情况，找到占用较高的线程
jstack [pid]  # 跟进指定进程，找到占用高的线程，查看代码问题
```
# 设计模式
## 一. 工厂模式
### 1. 简单工厂
用一个“工厂类”来封装对象的创建过程，客户端只需要告诉工厂“我想要哪种类型”，工厂就会返回对应的实例
```txt
          +----------------+
          |  Factory 工厂类 |
          +----------------+
                   |
                   | 根据条件（传参）选择创建哪个产品
                   ↓
        +----------+-----------+
        |                      |
+---------------+     +---------------+
|  ProductA类    |     |  ProductB类    |
+---------------+     +---------------+
```
```java
package simpleFactory;  
  
public interface Coffee {  
  
    String getName();  
  
    void addMilk();  
  
    void addSugar();  
  
    class goodCoffee implements Coffee {  
  
        private final String name;  
  
        public goodCoffee(String name) {  
            this.name = name;  
        }  
  
        @Override  
        public String getName() {  
            return name;  
        }  
  
        @Override  
        public void addMilk() {  
            System.out.println("Adding milk to " + name);  
        }  
  
        @Override  
        public void addSugar() {  
            System.out.println("Adding sugar to " + name);  
        }  
    }  
    class badCoffee implements Coffee {  
  
        private final String name;  
  
        public badCoffee(String name) {  
            this.name = name;  
        }  
  
        @Override  
        public String getName() {  
            return name;  
        }  
  
        @Override  
        public void addMilk() {  
            System.out.println("Adding milk to " + name);  
        }  
  
        @Override  
        public void addSugar() {  
            System.out.println("Adding sugar to " + name);  
        }  
    }  
}
```
```java
public class simpleCoffeeFactory {  
    public Coffee createCoffee(String type, String name) {  
        if ("good".equalsIgnoreCase(type)) {  
            return new Coffee.goodCoffee(name);  
        } else if ("bad".equalsIgnoreCase(type)) {  
            return new Coffee.badCoffee(name);  
        } else {  
            throw new IllegalArgumentException("Unknown coffee type: " + type);  
        }  
    }  
}
```
```java
public class CoffStore{  
    public Coffee OrderCoffee(String type, String name) {  
        simpleCoffeeFactory factory = new simpleCoffeeFactory();  
        return factory.createCoffee(type, name);  
    }  
}
```
- 客户端无需知道具体类名，只需传入“标识”，**降低耦合**
- 集中管理创建逻辑，**便于维护和修改**
- **便于扩展**（初期版本，适合产品种类较少）
- 一旦子类种类过多，if-else分支会非常臃肿，不利于扩展，违背了 **开闭原则（对扩展开放，对修改关闭）**
### 2. 工厂方法设计模式
工厂方法模式的核心是 **将“创建对象的职责”从“工厂类”中抽象出来交给子类实现**
**每种产品有自己的工厂，每个工厂只负责创建一种产品**
```txt
      +-----------------+
      |  Product 接口   |
      +-----------------+
             ▲
     +-------+--------+
     |                |
+-----------+   +-----------+
| ProductA  |   | ProductB  |
+-----------+   +-----------+

      +---------------------+
      | Factory 接口        |
      +---------------------+
             ▲
     +-------+--------+
     |                |
+------------+  +-------------+
| FactoryA   |  | FactoryB    |
+------------+  +-------------+
```
```java
public interface CoffeeFactory {  
    Coffee createCoffee();  
}
```
```java
public class goodCoffeeFactory implements CoffeeFactory {  
    @Override  
    public Coffee createCoffee() {return new Coffee.goodCoffee("Good Coffee");  
    }  
}

public class badCoffeeFactory implements CoffeeFactory {  
    @Override  
    public simpleFactory.Coffee createCoffee() {  
        return new simpleFactory.Coffee.badCoffee("Bad Coffee");  
    }  
}
```
```java
public class CoffeeStore {  
  
    private final CoffeeFactory coffeeFactory;  
  
    public CoffeeStore(CoffeeFactory coffeeFactory) {  
        this.coffeeFactory = coffeeFactory;  
    }  
  
    public Coffee orderCoffee() {  
        return coffeeFactory.createCoffee();  
    }  
}
```
- 每个产品有自己的工厂，**清晰职责划分**
- 新增产品时只需新增对应工厂类，不改原有逻辑，**符合开闭原则**
- 易于组合其他设计模式（如模板方法、策略）
- 类的数量增加
- 客户端需要知道具体工厂类（可通过配置、反射解耦）
### 3.  抽象工厂模式
**抽象工厂模式（Abstract Factory）** 提供一个接口，**用于创建“一系列相关/依赖的对象”，而不指定它们具体的类**
```txt
        +--------------------------+
        | AbstractFactory 抽象工厂 |
        +--------------------------+
              /           \
   +----------------+   +----------------+
   | MacFactory     |   | WindowsFactory |
   +----------------+   +----------------+
        |                      |
  ----------------      ------------------
  |              |      |                |
Button         Checkbox Button         Checkbox
```
```java
//产品接口
public interface Button {
    void click();
}

public interface Checkbox {
    void check();
}
```
```java
//具体产品
public class MacButton implements Button {
    public void click() {
        System.out.println("Mac按钮点击");
    }
}

public class WindowsButton implements Button {
    public void click() {
        System.out.println("Windows按钮点击");
    }
}

public class MacCheckbox implements Checkbox {
    public void check() {
        System.out.println("Mac复选框勾选");
    }
}

public class WindowsCheckbox implements Checkbox {
    public void check() {
        System.out.println("Windows复选框勾选");
    }
}
```
```java
//抽象工厂接口，定义生产所有“种类”（父类产品接口）的方法
public interface GUIFactory {
    Button createButton();
    Checkbox createCheckbox();
}
```
```java
//产品族工厂
public class MacFactory implements GUIFactory {
    public Button createButton() {
        return new MacButton();
    }
    public Checkbox createCheckbox() {
        return new MacCheckbox();
    }
}

public class WindowsFactory implements GUIFactory {
    public Button createButton() {
        return new WindowsButton();
    }
    public Checkbox createCheckbox() {
        return new WindowsCheckbox();
    }
}
```
## 二. 策略模式
### 1. 策略模式
策略模式：**定义一系列算法（策略），把它们一个个封装起来，并且使它们可以互相替换**
```txt
        +------------------+
        |   Strategy 接口   |
        +------------------+
           ▲         ▲
           |         |
+----------------+  +----------------+
| ConcreteStrategyA | ConcreteStrategyB |
+----------------+  +----------------+

        +------------------+
        |    Context类      |
        +------------------+
        | - strategy:Strategy |
        +------------------+
        | +setStrategy(...) |
        | +executeStrategy()|
        +------------------+
```
```java
//则略规则
public interface PaymentStrategy {
    void pay(double amount);
}
```
```java
//具体策略实现
public class AlipayStrategy implements PaymentStrategy {
    public void pay(double amount) {
        System.out.println("使用支付宝支付：" + amount + "元");
    }
}

public class WeChatStrategy implements PaymentStrategy {
    public void pay(double amount) {
        System.out.println("使用微信支付：" + amount + "元");
    }
}
```
```java
//上下文类，可以切换策略
public class PaymentContext {
    private PaymentStrategy strategy;

    public void setStrategy(PaymentStrategy strategy) {
        this.strategy = strategy;
    }

    public void execute(double amount) {
        if (strategy == null) {
            throw new IllegalStateException("还没设置支付策略");
        }
        strategy.pay(amount);
    }
}
```
```java
public class Client {
    public static void main(String[] args) {
        PaymentContext context = new PaymentContext();

        context.setStrategy(new AlipayStrategy());
        context.execute(100.0);  // 支付宝支付

        context.setStrategy(new WeChatStrategy());
        context.execute(200.0);  // 微信支付
    }
}
```
## 三. 责任链模式
把多个对象用链条串起来，让请求沿着链传递，每个对象都可以选择处理请求或放行

| 角色                      | 职责                           |
| ----------------------- | ---------------------------- |
| `Handler` 抽象处理者         | 定义处理请求的接口，通常包含一个指向下一个处理者的引用。 |
| `ConcreteHandler` 具体处理者 | 实现处理逻辑，判断是否处理请求，或者传递给下一个处理者。 |
| `Client` 请求者            | 创建处理链并提交请求。                  |
```java
// 抽象处理者
abstract class Handler {
    protected Handler next;

    public void setNext(Handler next) {
        this.next = next;
    }

    public abstract void handleRequest(String request);
}

// 具体处理者A
class ConcreteHandlerA extends Handler {
    public void handleRequest(String request) {
        if (request.contains("A")) {
            System.out.println("ConcreteHandlerA 处理了请求: " + request);
        } else if (next != null) {
            next.handleRequest(request);
        }
    }
}

// 具体处理者B
class ConcreteHandlerB extends Handler {
    public void handleRequest(String request) {
        if (request.contains("B")) {
            System.out.println("ConcreteHandlerB 处理了请求: " + request);
        } else if (next != null) {
            next.handleRequest(request);
        }
    }
}

// 客户端
public class Main {
    public static void main(String[] args) {
        Handler h1 = new ConcreteHandlerA();
        Handler h2 = new ConcreteHandlerB();
        h1.setNext(h2);

        h1.handleRequest("包含A的请求");
        h1.handleRequest("包含B的请求");
        h1.handleRequest("未知请求");
    }
}
```
# 实践
## 一. 单点登录
在多个系统中，**用户只需要登录一次**，就可以访问其他所有相互信任的系统，而无需重复登录
### 1. 基于 Cookie 的 SSO（同域名或父子域名）
- 系统之间共享一级域名（如 `a.example.com`、`b.example.com`）
- 登录时设置父域名 Cookie（如 `.example.com`），所有子系统都能带上它
- 依赖浏览器自动传 Cookie 的特性
- 首次登录时保存jsessionId到公共域名下，访问子系统时，通过请求拦截器判断携带的cookie里有没有对应的jsessionId
- 适用于子系统处于同一域名下的情况
```java
//配置jsessionId的作用域和名称
@Bean  
public CookieSerializer cookieSerializer() {  
    DefaultCookieSerializer defaultCookieSerializer = new DefaultCookieSerializer();  
    //放大作用域，让不同域名的存储的cookie可以共享  
    defaultCookieSerializer.setDomainName(CookieConstant.JSESSIONID_DOMAIN);  
    defaultCookieSerializer.setCookieName(CookieConstant.JSESSIONID_NAME);  
    return defaultCookieSerializer;  
}  
  
/**  
 *配置redis存储session的序列化方式  
 */  
@Bean  
public RedisSerializer<Object> springSessionDefaultRedisSerializer() {  
    return new GenericJackson2JsonRedisSerializer();  
}
```
```java
@Override  
public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {  
  
    UserInfoVo userInfoVo = new UserInfoVo(); 
    //会自动通过jsessionId获取对应的session对象 
    HttpSession session = request.getSession();  
    MemberDTO loginUser = (MemberDTO)session.getAttribute(redisConstant.LOGIN_USER);  
    if (loginUser!= null){  
        //如果登录，用户信息就应该包含用户id，后面将根据用户id查询购物车信息  
        userInfoVo.setUserId(loginUser.getId());  
    }  
  
    //从cookie中获取离线的购物车的cookie  
    Cookie[] cookies = request.getCookies();  
    if (cookies != null){  
        for (Cookie cookie : cookies){  
            if (cookie.getName().equals(CartConstant.TEMP_USER_COOKIE_NAME)){  
                userInfoVo.setUserKey(cookie.getValue());  
                userInfoVo.setTempUser(true);  
                break;  
            }  
        }  
    }  
  
    //如果没有相关的离线状态的购物车cookie，就创建一个，  
    // 又因为cookie是随机的而且每台电脑上浏览器保存的都不一样，保证了，每个浏览器上都是自己的离线购物车  
    if(userInfoVo.getUserKey() == null){  
        userInfoVo.setUserKey(UUID.randomUUID().toString());  
    }  
  
    threadLocal.set(userInfoVo);  
  
    return HandlerInterceptor.super.preHandle(request, response, handler);  
}
```
### 2. 基于 Token + 认证中心 的 SSO（跨域支持）
|角色|说明|
|---|---|
|用户系统（Client）|各个需要登录的子系统|
|SSO认证中心|负责登录校验、签发令牌（如JWT或sessionId）|
|Token/Cookie|用户登录成功后的“通行证”|
|存储中心（可选）|存放session、token黑名单等（可选 Redis、JWT自身携带）|
```java
@Configuration  
@EnableWebSecurity  
public class AuthorizationConfig {  
  
    /**  
     * 注册客户端信息  
     * @return RegisteredClientRepository  
     */    @Bean  
    public RegisteredClientRepository registeredClientRepository() {  
        RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString())  
                .clientId("AuthorizationServer")  
                .clientSecret("{noop}123456")  
                .authorizationGrantType(AuthorizationGrantType.AUTHORIZATION_CODE)  
                .redirectUri("http://localhost:8080/login/oauth2/code/AuthorizationServer")  
                .scope("read")  
                .build();  
        return new InMemoryRegisteredClientRepository(registeredClient);  
    }  
  
    /**  
     * 自定义 OAuth2UserService 以处理用户信息  
     * @return OAuth2UserService  
     */    @Bean  
    public OAuth2UserService<OAuth2UserRequest, OAuth2User> customOAuth2UserService() {  
        return userRequest -> (OidcUser) new DefaultOAuth2UserService().loadUser(userRequest);  
    }  
  
    /**  
     * 配置安全过滤链  
     * @param http  HttpSecurity 对象  
     * @param customOAuth2UserService   自定义 OAuth2UserService  
     * @return  过滤器链  
     */  
    @Bean  
    public SecurityFilterChain securityFilterChain(HttpSecurity http, OAuth2UserService<OAuth2UserRequest, OAuth2User> customOAuth2UserService) throws Exception {  
        http.authorizeHttpRequests(auth -> auth.requestMatchers("/public/**").permitAll().anyRequest().authenticated())  
                .oauth2Login(oath -> oath.loginPage("login").userInfoEndpoint(userInfo -> userInfo.userService(customOAuth2UserService)));  
        return http.build();  
    }  
  
    /**  
     * 配置授权服务器设置  
     * @return AuthorizationServerSettings  
     */    @Bean  
    public AuthorizationServerSettings authorizationServerSettings() {  
        return AuthorizationServerSettings.builder()  
                .issuer("http://localhost:9000") // 设置授权服务器的 issuer                .build();  
    }  
  
    /**  
     * 生成 JWKSource，用于 JWT 编码器  
     */  
    @Bean  
    public JWKSource<SecurityContext> jwkSource() throws NoSuchAlgorithmException {  
        KeyPair keyPair = KeyPairGenerator.getInstance("RSA").generateKeyPair();  
        RSAKey key = new RSAKey.Builder((RSAPublicKey) keyPair.getPublic())  
                .privateKey((RSAPrivateKey) keyPair.getPrivate())  
                .build();  
        return (jwkSelector, ctx) -> jwkSelector.select(new JWKSet(key));  
    }  
  
    /**  
     * JWT 编码器 Bean  
     * @param jwkSource JWKSource<SecurityContext> 用于提供 JWK  
     * @return  
     */  
    @Bean  
    public JwtEncoder jwtEncoder(JWKSource<SecurityContext> jwkSource) {  
        return new NimbusJwtEncoder(jwkSource);  
	    }  
}
```
# AI
## 一. prompt工程
- 具体、丰富
- 明确的输入输出
	- 包括格式，输入输出长度，字段约束
	- 给出例子格式
- 对于不同的大模型，由于它训练的数据不一样，需要优化不同的prompt
- 定义角色，在开头将问题的领域收窄，减少二义性
	- 定义语气
- 核心思路
	- 把输入的自然语言对话，转化成结构化表示（NLU所做的事情）
	- 从结构化的表示生成策略（DST到Policy，DST保存多轮对话的状态，Policy根据DST状态生成对应的执行策略）
	- 把策略结果转化成自然语言输出
- 防止prompt注入
	- 强调角色和输入输出格式不可改变
## 二. RAG
### 1. transformer
```txt
输入序列
   │
   ▼
[Embedding] ──► [Positional Encoding]
   │
   ▼
╔════════════════════════════════════╗
║             Encoder                ║
║ ┌───────────────────────────────┐  ║
║ │ Multi-Head Self-Attention      │  ║
║ └───────────────────────────────┘  ║
║            │                        ║
║            ▼                        ║
║ ┌───────────────────────────────┐  ║
║ │ Feed Forward Network (FFN)     │  ║
║ └───────────────────────────────┘  ║
║            │                        ║
║          (残差 + LayerNorm)        ║
╚════════════════════════════════════╝
               │
               ▼
         Encoder 输出
               │
               ▼
╔════════════════════════════════════╗
║             Decoder                ║
║ ┌───────────────────────────────┐  ║
║ │ Masked Multi-Head Attention    │◄─目标序列 (已生成)  
║ └───────────────────────────────┘  ║
║            │                        ║
║            ▼                        ║
║ ┌───────────────────────────────┐  ║
║ │ Cross Attention (看 Encoder)   │◄─ Encoder 输出
║ └───────────────────────────────┘  ║
║            │                        ║
║            ▼                        ║
║ ┌───────────────────────────────┐  ║
║ │ Feed Forward Network (FFN)     │  ║
║ └───────────────────────────────┘  ║
║            │                        ║
║          (残差 + LayerNorm)        ║
╚════════════════════════════════════╝
               │
               ▼
           [Softmax]
               │
               ▼
        下一个 Token 概率
```
- 输入处理
	- 把词（token）转成向量（Embedding）
	- 加上 **位置编码**（因为 Transformer 本身没有顺序感）
- 核心机制：自注意力（Self-Attention）
	- 每个词都会生成 **Q（查询）**、**K（键）**、**V（值）** 向量
	- 用 Q 和所有 K 做相似度，得到注意力权重
	- 用这些权重加权 V，得到新的词表示，这样每个词都能“看见”并吸收其他词的信息
- 多头注意力（Multi-Head Attention）
	- 同时运行多个注意力机制，每个学习不同的关系（比如主谓、修饰）
	- 把结果拼接起来，更丰富
- 前馈网络 + 残差 + LayerNorm
	- 每个词向量再经过全连接网络（FFN）
	- 加上残差连接和归一化，保证训练稳定
- Encoder-Decoder 结构
	- **Encoder**：输入序列经过 N 层堆叠（自注意力 + FFN）
	- **Decoder**：生成时也有自注意力，但带 **Mask**（防止偷看未来），并结合 Encoder 的输出
- 输出
	- 最终通过 **Softmax** 得到下一个词的概率分布
	- 逐个生成，直到结束
```txt
用户输入: "今天天气怎么样"
        │
        ▼
分词 (Tokenizer)
["今天", "天气", "怎么样"]
        │
        ▼
Embedding + Positional Encoding
[x1, x2, x3]
        │
        ▼
自注意力 (Self-Attention)
 ┌─────────────────────────────┐
 │  每个 token 计算 Q,K,V       │
 │  "怎么样" ↔ "天气" 权重较高   │
 └─────────────────────────────┘
        │
        ▼
多头注意力 (Multi-Head Attention)
[丰富的上下文表示 z1, z2, z3]
        │
        ▼
前馈网络 + 残差 + LayerNorm
[更稳定的表示]
        │
        ▼
Encoder 输出 (语义表示)
        │
        ▼
Decoder (生成回答)
Masked Self-Attention + Encoder 输出
        │
        ▼
Softmax 概率分布
["晴天"(0.6), "下雨"(0.3), "多云"(0.1)]
        │
        ▼
生成第一个词: "晴天"
        │
        ▼
自回归生成 → "晴天。"
```
分词 → 向量化 → 注意力机制聚合语义 → 多层 Encoder 提取语义 → Decoder 按概率逐字生成回答（比如“晴天。”），Encoder负责理解问题，Decoder处理问题。
### 2. 优势
|角度|优势|说明|
|---|---|---|
|**知识覆盖**|解决大模型知识过时问题|大模型训练数据是静态的，而 RAG 可以接入最新的数据库/文档/搜索引擎，动态获取外部知识。|
|**准确性**|降低幻觉（hallucination）|模型不是“凭空编造”，而是结合检索结果来回答，答案更可验证。|
|**可控性**|回答有据可依|检索结果可溯源，可以告诉用户“答案来自哪里”，方便解释和追责。|
|**成本效率**|降低训练和推理成本|不必频繁训练或微调大模型，只需维护一个知识库，模型只负责理解和组织回答。|
|**灵活性**|支持领域定制|通过更换知识库，模型可以快速适配金融、医疗、电商等不同领域，而不用重新训练。|
|**可扩展性**|知识库可扩展|知识库不断更新，系统能力也随之增强，不影响模型本身。|
|**用户体验**|回答更贴近需求|结合检索结果，模型能提供结构化、实时、上下文相关的答案，而不是泛泛之谈。|


# Redis
## 一. 缓存
### 1. 缓存击穿
#### 原因
查询一个缓存和数据库都没有的数据时，会穿过缓存直接查询数据库，且不会写回到缓存中
#### 解决
（1） 允许缓存存储null值，若不存在数据的key过多会导致缓存内存占用较大
（2）添加布隆过滤器，判断一个元素是否存在于集合中，实现原理是，布隆过滤器是一个bitmap，存储二进制的数组，加载数据到缓存中时，对key进行多次hash函数运算将得到的索引对应的元素置为1，当进行查询缓存时，会对key进行相同的hash运算判断结果索引处的值是否都是1，如果不是则直接返回缓存中没有这个key的数据，但是查询的key进行hash运算的结果会和其他key的运算结果有重复，导致不存在数据的key误判为有数据，产生误差
### 2. 缓存穿透
#### 原因
热点key刚好过期，且有大量请求进入查询这个key的数据，导致数据库压力过大宕机
#### 解决
（1）添加互斥锁（分布式锁） 线程一---->缓存中key过期---->添加互斥锁---->查询数据库并写回缓存---->释放锁
其他线程只能不断重试  > 查询缓存+尝试抢夺互斥锁  这个过程
低可用，高一致
（2）逻辑删除  维护缓存数据中的过期字段，当线程发现缓存数据已经过期会添加互斥锁，并开启异步线程进行数据库的查询，写回缓存并重置过期时间，释放锁，线程在开启异步线程之后会直接返回旧数据，其他线程若没有抢占到互斥锁也会直接返回旧数据，高可用，低一致
### 3. 缓存雪崩或服务器宕机
#### 原因
大量key在同一时间同时过期，大量请求涌入，导致数据库压力过大宕机
#### 解决
（1）给不同的key设置随机的TTL
（2）设计多级缓存
（3）降级限流，流量削峰，减少服务器压力
（4）部署集群，提高服务高可用性
### 4. 双写一致性
#### 原因
缓存数据和数据库数据不一致
#### 解决
强一致：（1）延迟双删   先删缓存，再更新数据库，延迟一定时间后再次删除缓存，有延迟时间是因为主从库数据同步需要一定时间，保证二次删除缓存后进入数据库查询的数据是最新的，因为延迟的时间不好把握，所以仍然会有一定的不一致
		先删缓存再更新数据库  线程 一在删除完缓存后，数据库更新未完成，线程二进入，会因缓存被删进入数据库查询出旧数据并写回缓存，产生脏数据
		先更新再删缓存  线程一更新的数据恰好在缓存中已经过期，在线程一更新数据完成之前，线程二进入，会因缓存过期进入数据库查询得到旧数据，在将数据写回缓存之前，线程一完成更新并删除了缓存，存入缓存的仍然是旧的，产生脏数据
	（2）添加读写锁  通过redisson获得同一个读写锁，读锁可以共享读，但是不能写，写锁既不能读也不能写，保证强一致
	
延迟一致：（1）添加消息中间件  当数据在业务层进行修改，发送消息到MQ，并由监听修改消息队列的业务更新缓存
		（2）Canal  使用Canal监听数据库的binglog日志，并将更新数据发送给业务，由业务进行更新缓存	

### 5.  持久化
#### RDB
定时对内存数据进行快照保存到磁盘中（在redis.conf文件中配置为多少时间有多少个key被修改就保存一次），数据存储在物理内存中，主进程操作的是虚拟内存，由页表将虚拟内存和物理内存进行映射，当进行bgsave时，子进程会拷贝一份主进程的页表，得到映射关系，读取物理内存的数据并写进磁盘中，当主进程进行写操作时，会将物理内存 的数据的状态改为readonly，并将要修改的数据拷贝一份，主进程将对拷贝的数据进行读写，避免脏数据
体积小，恢复速度快
#### AOF
将写命令直接保存在aof文件中（在redis.conf中进行配置开启，配置为立即记录写命令/每秒记录一次/由操作系统决定记录时间），由于只有最后一次的写命令才有效，所以有aof文件重写机制，保存最有效的写命令，触发机制有当前aof文件相比之前增长了百分之多少/相比于之前增长了多大体积
体积大，恢复速度慢
### 6. 数据过期策略
#### 惰性删除
key过期后先不进行删除，只有当查询这个key时才进行过期判断，如果过期直接删除，没有过期则返回值
#### 定期删除
定时遍历一些key进行过期检查，删除其中过期的
slow模式，默认是10HZ，每次清理耗时不超过25ms，尽量少去影响主进程操作（在配置文件中调整hz选项进行调整）
fast模式，两次间隔大于2ms，每次不超过1ms
### 7. 数据淘汰策略

当Redis内存已经达到上限，进行的数据删除的策略
LRU：优先删除最近最少使用的数据。用当前时间减去最近一次使用的时间，值越大越容易被淘汰
LFU：优先删除访问频率最小的数据
默认使用的是不接受新的key，当内存已经达到上限，存入新数据会直接报错
一般使用的是allkeys-lru，删除最近最少访问的key，保留热点数据
## 二. 分布式锁
### 1.  setnx
```java
set lock value NX EX 10;
```
通过redis命令存值设置锁并设置过期时间，保证原子性和锁会最终释放
会因业务执行时间过长导致提前解锁，通过根据业务和手动续锁来解决
### 2. redisson
#### 获取锁
通过redission添加分布式锁，底层是setnx和lua脚本执行redis命令保证原子性
```java
Rlock lock=redissonClient.getLock("lt");
boolen isLock=lock.tryLock(10,30,TimeUnit.SECOND);
boolen isLock=lock.tryLock(10,TimeUnit.SECOND);
boolen isLock=lock.tryLock();
```
没有抢占到锁的线程会循环不断尝试获取锁
会有一个watch dog线程监听当前抢占到锁的线程，并不断给锁续期（默认是10秒续期一次），直到手动释放锁

方法一：参数10是其他线程尝试获取锁的最大循环时间，参数30是最终锁的过期自动释放时间，不会自动续期，到期直接释放
方法二：同上，因为没有自动释放时间会自动续期
方法三：默认是每隔10秒给锁重新续期到30秒
#### 锁的可重入
```java
add1(){
	getLock("lt");
	add2();
	...
	unlock();
}
add2(){
	getLock("lt");
	...
	unlock();
}
```
redis里通过hash结构存储当前线程占有锁的情况
Lock | Tread | value
lt |    tr1    | 2
redis会根据当前站有锁的线程，对锁的重入累加value值，每当有一个重入的锁进行释放value值减一
#### 主从一致性
当线程占有锁之后，主节点会将锁的信息同步给从节点，但是如果完成同步之前，主节点宕机，从节点当选主节点没有锁的信息，其他线程也会抢占到锁，导致两个线程都持有锁
redisson无法解决主从一致性
RedLock可以。通过将锁的信息同时存到一半数量以上的节点保证锁的信息不会丢失，性能会很差
zookeeper可以保持强一致
## 三. 其他

### 1. 主从复制
单点redis并发能力有限，通过搭建主从集群实现读写分离，主节点负责写操作，从节点负责读，主节点将数据修改同步给从节点

Replication Id：判断数据集是否一致，每个主节点有自己唯一的id，从节点继承主节点的id
offset：偏移量，记录已经执行到或更新到的repl baklog 文件的位置
#### 全量同步
从节点请求连接主节点并发送rpid和offset，主节点根据rpid判断从节点是不是第一次同步，如果是，则进行bgsave，生成RDB文件，并在生成文件期间将进行操作的命令记录在repl baklog文件中，之后主节点将RDB文件发送给从节点，从节点清除本地数据，加载RDB文件，之后主节点发送repl baklog的命令，从节点执行命令
#### 增量同步
如果不是第一次同步，则主节点会根据发送offset和自己的offset比较，发送两者相差的命令给从节点，让从节点进行执行
### 2. 哨兵机制
在主从复制的基础上添加哨兵集群监控节点情况，提高可用性
#### 选主原理
哨兵会定时向节点发送ping命令，如果节点返回pang说明节点健康
如果某个哨兵向主节点发送命令没有响应，属于主观主节点宕机，如果右超过一半数量以上的哨兵认为主节点主观宕机，则主节点客观宕机，哨兵会通知客户端新的主节点更改的消息
和主节点断开连接时间越短的从节点，offset越大的从节点越容易当选主节点，当旧 主节点恢复会成为当前主节点的从节点
#### 脑裂
当主节点和从节点和哨兵处于不同网络下时，客户端仍然能连接到旧主节点，哨兵认为主节点宕机，会从从节点中重新选举主节点，旧主节点收到的数据无法同步到其他节点，当网络恢复，旧主节点降级为新主节点的从节点，和新主节点进行数据同步，清空了本地数据，丢失了网络中断时客户端的数据
可以通过配置最小从节点数量和主从同步最大延迟时间来让修改数据命令直接拒绝解决
### 3. 分片集群
#### 原理
集群中有多个主节点，每个主节点有多个从节点，主节点之间互相进行心跳检测充当哨兵作用
每个主节点存储不同的数据，通过将一万多个hash槽分配给集群中的主节点，并对请求的key进行有效值的hash运算，将客户端的请求路由到相应的主节点
```java
set name value lt;
set {aaa}name value lt;
```
{ }内的值就是计算hash值的有效值，如果没有，key就是有效值
### 4. 执行速度
#### 原因
redis是基于内存存储的，读写速度很快
redis是单线程的，避免了不必要的上下文切换
采用了I/O多路复用的模型
#### I/O模型
Liunx系统将一个进程分为了用户空间和内核空间，用户空间只能执行受限的命令，通过调用内核空间的接口调用系统资源，内核空间可以直接调用系统资源，为了提高性能会在用户空间和内核空间内加入缓冲区
用户进程在写数据时会将自身数据拷贝一份到内核进程的缓冲区，然后写入硬件
在进行读数据时会将硬件数据加载到内核进程的缓冲区，然后将数据拷贝到用户进程缓冲区
所以影响redis速度的是网络传输，而不是执行效率
##### 阻塞式I/O
```txt
用户进程-----------调用recvfrom函数------------>内核进程
												|
												|
											  等待数据
											    |
											    |
   <-------------写入用户进程缓冲----------------数据就绪
```
阶段一：用户进程调用recvfrom函数，请求内核进程读取数据，如果没有则内核进程等待数据，此时用户进程处于阻塞状态
阶段二：当数据准备就绪后，用户进程会等待内核进程将数据拷贝到自己的缓冲区，此时用户进程依然是阻塞状态
##### 非阻塞式I/O
```txt
用户进程-----------调用recvfrom函数------------>内核进程
												|     循环此过程
												|
	  <-------------返回error-----------------等待数据
											    |
											    |
   <-------------写入用户进程缓冲----------------数据就绪
```
阶段一：用户进程调用recvfrom函数，如果没有数据，内核会直接返回error，用户进程会一直循环尝试请求数据，直到数据准备就绪，此时用户进程处于非阻塞状态
阶段二：当数据准备就绪后，用户进程等待数据拷贝，此时用户进程处于阻塞状态
##### I/O多路复用
```txt
用户进程-----------调用select函数-------------->内核进程
												|      
												|
											  等待数据   一旦某个socket数据就绪
											    |
											    |
   <-----------------readable----------------数据就绪
												|
												|
   <-------------写入用户进程缓冲--------------数据就绪
```
阶段一：用户进程调用select函数，发送要监听的socket集合，内核监听指定的socket集合，一个或者多个socket可读可写时，内核会返回readable，此阶段用户进程是阻塞状态
阶段二：用户进程循环遍历socket集合找到已经就绪的，并依次调用recvfrom函数读取数据，内核将数据拷贝到用户进程缓冲区
###### 实现方式
select，poll，epoll
前两者用户进程是不知道哪个socket就绪的，需要遍历寻找，后者在返回readable时会将socket信息写入用户进程缓冲区
#### redis的I/O模型
通过I/O多路复用和事件派发机制，还有连接应答处理器，命令回复处理器，命令请求处理器完成
6.0版本之后redis加入了多线程在命令回复处理器和命令请求处理器的接收参数和命令转化部分，执行部分依然是单线程的
# MySQL
## 一. 优化
### 1. 定位慢查询
#### 常见慢查询
聚合查询：聚合函数无法使用索引
多表联查：join字段如果没有索引或者索引覆盖不完全会触发回表查询
数据量过大
分页过深：例如
```sql
SELECT * FROM table 
ORDER BY xxx
LIMIT 1000000, 10;

```
实际上是对前1000010条数据进行顺序扫描加排序，然后丢掉前1000000条数据只保留10条，分页越深排序的数据就越多，order by字段如果有索引可以优化排序
#### 解决
##### 使用运维工具
如普罗米修斯，skywalking，监控方法的执行时间和各阶段耗时
##### 开启慢查询
在/etc/my.cnf中进行配置
```config
slow_query_log=1 # 开启慢查询日志
slow_query_time=2 # 指定超时时间，超过指定时间记录为慢查询
```
### 2. 分析慢查询
通过explain关键字查看语句的执行情况
possible_key：可能用到的索引
key和key_len：实际用到的索引和索引的长度
type：语句的类型，可以通过它判断语句是否有优化空间，const通过主键查询，ref全索引扫描，all全盘扫描
extra：优化建议，如果是回表查询，可以添加索引或者修改返回字段
### 3. 索引
#### 什么是索引
帮助MySQL获取数据的数据结构，在innodb存储引擎中用B+树存储索引
提高查询效率，减少IO消耗
通过索引对数据进行排序，降低排序成本
#### B+树优势
每个父节点可以拥有多个子节点，分支更多则层级更少，查询路径更短
磁盘读写代价更少，B+树的非叶子节点只存储索引，叶子节点存储数据，且叶子节点是一个双向链表，适合进行范围查询和全库扫描
B+树的节点大小通常与一个磁盘页对其（4kb），一个磁盘页可以一次性读入多个 key 和指针，快速定位key的位置，最大化利用磁盘带宽，这使得每次磁盘 I/O 能读取更多内容，从而**显著减少访问次数和等待时间**
#### 聚集索引
又称聚簇索引，每张表只能有一个，特点是叶子节点挂着的是这一行的整行数据，如果表有主键，主键索引就是聚集索引，如果没有主键，第一个唯一索引就是聚集索引，如果没有合适的唯一索引，会自动生成一个隐藏的rowid字段作为聚集索引
#### 二级索引
又称非聚集索引，每张表有多个，叶子节点挂着的是对应的主键
#### 回表查询
如果二级索引没有需要查询的所有数据，需要通过叶子结点的id到聚簇索引查询需要的数据，通过创建覆盖索引来解决
#### 覆盖索引
在查询使用的索引中可以获得所有需要的字段
#### 超大分页查询
```sql
select * from sku a,(select id from sku order by id limit 9000000 10) b
where a.id=b.id;
```
通过覆盖索引加子查询进行优化
#### 创建索引原则
1.对于数据量大的表创建索引
2.有一些字段频繁用于查询条件，如where，order by
3.尽量使用区分度高，唯一的字段创建索引，如性别就不适合创建索引
4.对于较长的string字段创建前缀索引
5.尽量创建联合索引，减少单列索引，避免回表查询
6.控制数量
#### 索引失效
1.违法最左前缀法则，查询条件字段跳过了联合索引从左往右的某个字段
2.范围查询条件字段右边的查询条件字段无法使用索引
3.查询条件字段上进行了运算，字段的值改变无法使用索引
4.查询的字符串没加单引号，发生类型转换，原索引无法比较
5.以%开头的模糊查询会使索引失效
### 4.sql优化
#### 表的设计优化
选择合适的字段数据类型
#### sql语句优化
指定select的字段名称，避免使用 * 导致回表查询
避免索引失效的写法
用union all替换union，union会多一次过滤操作
尽量使用inner join不用left/right join，如果必须使用，要使用小表作为驱动（外表），减少内外表的连接次数
不要在where子句使用表达式
#### 主从复制，读写分离
#### 分库分表
## 二. 其他
### 1. 事务
原子性：不可分割，最小单位，全部成功或全部失败
一致性：事务完成后，所有数据必须保持一致
隔离性：事务在不受外界环境影响下并发执行
持续性：对数据库的修改是永久的
#### 并发问题
脏读：一个事务读到了另一个事务的未提交的数据
不可重复读：一个事务两次读取同一条记录，但两次数据不一致
幻读：事务在查询一条记录时，没有对应的数据，但是插入的时候却发现该条记录已经存在
#### 隔离级别
读未提交
读已提交：解决脏读
可重复读（默认）：解决脏读和不可重复读
串行化：可解决所有问题，一个事务完成之后再执行其他事务
#### undo log和redo log
缓冲池：主内存中的一个区域，里面可以存储磁盘上经常增删改查的数据，在进行操作时，先操作缓冲池里面的数据，然后以一定频率刷新到磁盘减少IO消耗，加快处理速度
数据页：innodb引擎中最小的管理单元，每个页16kb，里面存储的是行数据
##### redo log
由重做日志缓冲和重做日志文件组成，前者在主内存中后者在磁盘中，记录的是事务提交产生的数据页的物理修改，当重写日志缓冲区内容发生变化会将内容同步到日志文件中，当脏页刷新到磁盘发生错误时，可以用来数据恢复
##### undo log
记录逻辑日志，提供回滚和MVCC，当事务回滚时，可以通过逆操作恢复到原来的数据
#### MVCC
MySQL的多版本并发控制。指的是维护数据的多个版本，使读写操作没有冲突
##### 隐藏字段
每张表有两个隐藏字段
事务id：记录每一次操作的事务id，是自增的
回滚指针：指向上一个数据版本的事务版本记录地址
##### undo log
当数据被修改时，会将当前数据记录在undo log日志文件中，修改后的数据的回滚指针就会指向文件中上一版本的数据地址，形成版本控制链表，同时修改后数据的事务id会加1
##### readView
解决事务查询的数据版本问题
包含四个字段：创建readview的事务id，当前活跃的事务（未提交的事务）的id集合，最小活跃事务id，预制事务id（最大活跃事务id加1）
会根据四条规则和readview去版本控制链中查找对应版本的数据
在读已提交事务隔离级别下，事务的每次查询都会根据当前事务情况重新生成readview
在可重复读隔离级别下，各个事务内部的readview都是重用第一次生成的，但是使用时还是要根据规则比较来获取版本数据
### 2. 主从复制原理
主从复制的核心是binlog二进制日志文件
当主库的数据发生了修改，会专门有一个线程将修改的sql语句或者修改的数据记录在binlog日志文件中，从库有一个IO线程连接主库，并发起请求接收binlog文件内容，并将接收的内容写入自己的中继文件relay log中，然后有一个sql线程来重做中继文件的内容，实现数据同步，如果主从复制是行模式，那么二进制文件存储得就是对应行发生的数据变更，如果是sql模式记录的是使数据发生变化的sql语句
同时从库会记录主库的binlog文件名称和文件内偏移量，以便发生网络波动后能够定位binlog文件读取到的位置
### 3. 分库分表
#### 垂直分库
根据不同的业务将不同的表存储到不同的库
#### 垂直分表
以字段为依据，根据字段属性将不同字段拆分到不同的表中，把不常用的或大字段拆分到单独的一张表
#### 水平分库
将一个库的数据拆分到多个库中，每个库都有相同的表但是存储的数据不一样，合起来才是完整的数据
根据id取模找到对应数据存储的数据库，hash运算取模分库，范围分库（一个库存到了上限再存到下一个库），时间分库（每个月的数据存到对应的一个数据库里）
```xml
<?xml version="1.0" encoding="UTF-8"?>
<mycat:schema xmlns:mycat="http://io.mycat/">

    <!-- 定义逻辑库 -->
    <schema name="order_db" checkSQLschema="false" sqlMaxLimit="1000">
        <!-- 逻辑表 -->
        <table name="order" dataNode="dn0,dn1,dn2,dn3"
               rule="sharding_rule" />
    </schema>

    <!-- 定义物理库和数据节点 -->
    <dataNode name="dn0" dataHost="ds0" database="order_db_0" />
    <dataNode name="dn1" dataHost="ds0" database="order_db_0" />
    <dataNode name="dn2" dataHost="ds1" database="order_db_1" />
    <dataNode name="dn3" dataHost="ds1" database="order_db_1" />

    <!-- 数据源配置 -->
    <dataHost name="ds0" maxCon="1000" minCon="10" balance="0"
              writeType="0" dbType="mysql" dbDriver="native">
        <heartbeat>select 1</heartbeat>
        <writeHost host="hostM1" url="127.0.0.1:3306" user="root" password="123456" />
    </dataHost>

    <dataHost name="ds1" maxCon="1000" minCon="10" balance="0"
              writeType="0" dbType="mysql" dbDriver="native">
        <heartbeat>select 1</heartbeat>
        <writeHost host="hostM2" url="127.0.0.2:3306" user="root" password="123456" />
    </dataHost>

</mycat:schema>
```
在代码层面通过使用mycat中间件，在mycat中配置物理库的逻辑库和库中的逻辑表（逻辑表和物理表的结构一样），代码面对逻辑表操作，请求实际上由mycat根据逻辑表的路由规则进行路由到对应的库中的物理表，结果由mycat进行整合返回给应用
#### 水平分表
将一张表的数据拆分到多个表中（可以在同一个库里）
减少锁表的几率
### 4. 主键问题
不推荐使用主键自增
#### 原因
自增主键是顺序的，容易被猜到，遭到攻击
会向B+树的最后一页添加数据，页分裂，锁竞争，主内存的缓冲区数据刷脏压力全在末尾数据
对于分库分表，每个库都有自增主键很容易出现主键重复的情况
在数据迁移或合并的时候，因为id冲突需要重新映射主键
# Spring
## 一. Bean
### 1. IOC容器
#### 原理及流程
基本思想是控制反转，将对象的创建和管理由程序员变成了IOC容器，由它来创建对象，注入依赖，管理生命周期，bean的创建和初始化是串行执行的，一个bean完成全部流程才会继续下一个
##### 容器启动
```java
public void refresh() throws BeansException, IllegalStateException {
    // 1. 预处理
    prepareRefresh();
    // 2. 获取 BeanFactory（核心容器）
    ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
    // 3. BeanFactory 的准备工作
    prepareBeanFactory(beanFactory);
    // 4. 注册BeanDefinition（核心）
    invokeBeanFactoryPostProcessors(beanFactory);
    // 5. 注册BeanPostProcessor
    registerBeanPostProcessors(beanFactory);
    // 6. 实例化单例Bean
    finishBeanFactoryInitialization(beanFactory);
    // 7. 完成 refresh
    finishRefresh();
}

```
##### BeanDefinition 解析
```java
//注册
beanDefinitionRegistry.registerBeanDefinition(beanName, beanDefinition);
//存储到容器
Map<String, BeanDefinition> beanDefinitionMap;
```
通过@ComponentScan扫描包
解析到@Component、@Bean等注解
将其转换成BeanDefinition，并注册到容器里（此时还没有立即创建对象）
##### 实例化 Bean
```java
Object beanInstance = doCreateBean(beanName, mbd, args);
```
Spring根据按需创建 + 懒加载原则（`@Component`、`@Service`、`@Controller`这些默认单例，在容器初始化时创建，其他 scope参数，比如`prototype`是多例，是用到时才创建），通过反射创建出对象，也就是bean的实例，注意此时bean的内部的属性是没有值的，相当于使用无参构造器创建出来的实例
##### 依赖注入（DI核心）
```java
protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {
    // 处理 @Autowired、@Resource
    for (InjectionElement element : injectionMetadata.getInjectedElements()) {
        element.inject(bean, beanName, pvs);
    }
}
```
通过反射将这个依赖bean作为属性的值注入到使用了这个bean的对象里
```java
field.setAccessible(true);
field.set(beanInstance, injectedValue);
```
##### BeanPostProcessor 扩展（AOP钩子）
```java
//applyBeanPostProcessorsBeforeInitialization负责调用所有实现了`BeanPostProcessor`接口的`postProcessBeforeInitialization`方法
Object wrappedBean = applyBeanPostProcessorsBeforeInitialization(bean, beanName);
//最后的初始化，调用bean的初始化方法
invokeInitMethods(beanName, wrappedBean, mbd);
//如果bean实现了postProcessAfterInitialization方法，`applyBeanPostProcessorsAfterInitialization` 负责调用所有实现了`BeanPostProcessor`接口的`postProcessAfterInitialization`方法
applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);
```
执行bean内部的`@PostConstruct` / @afterPropertiesSet这类init方法，对bean进行最后的初始化，如果bean没有实现postProcessAfterInitialization方法，spring的AOP组件其实已经实现了，它会判断是否要为这个bean生成代理对象，例如是否使用了事务注解
```java
// spring的aop组件默认postProcessAfterInitialization方法实现源码
@Override
public Object postProcessAfterInitialization(Object bean, String beanName) {
    // 1. 跳过基础类型、自己不代理自己等判断
    if (shouldSkip(bean, beanName)) {
        return bean;
    }
    // 2. 根据配置创建代理
    Object cacheKey = getCacheKey(bean.getClass(), beanName);
    Object proxy = this.cachedProxy(cacheKey);
    if (proxy == null) {
        proxy = createProxy(bean, beanName);
        cacheProxy(cacheKey, proxy);
    }
    return proxy;
}
protected Object createProxy(Object bean, String beanName) {
    Class<?> beanClass = bean.getClass();
    // 1. 先获取所有要织入的切面（Advisor）
    List<Advisor> advisors = findEligibleAdvisors(beanClass, beanName);

    if (advisors.isEmpty()) {
        return bean;
    }

    // 2. 根据代理策略创建代理
    ProxyFactory proxyFactory = new ProxyFactory();
    proxyFactory.copyFrom(this);
    proxyFactory.setTarget(bean);
    proxyFactory.setInterfaces(beanClass.getInterfaces());
    proxyFactory.addAdvisors(advisors);
    proxyFactory.setProxyTargetClass(isProxyTargetClass());

    // 3. 生成代理对象（JDK动态代理或CGLIB代理）
    return proxyFactory.getProxy(getProxyClassLoader());
}
```
```java
for (BeanPostProcessor processor : postProcessors) {
    currentBean = processor.postProcessAfterInitialization(currentBean, beanName);
}
```
根据spring的责任链模式，返回的东西会继续被处理，如果bean实现的方法返回的是代理对象，spring就不会继续为这个bean代理，所以如果生成代理的逻辑有问题会导致逻辑重复，代理嵌套或终止spring自带的事务代理
##### 单例池管理
`singletonObjects` 是 Spring 的单例池：
```java
Map<String, Object> singletonObjects;
```
所有创建好的 Bean 会放进去，后续直接取：
```java
getSingleton(beanName);
```
将bean存储在内存中，后续需要直接从内存里取出
### 2. 单例bean线程安全
对于bean中的无状态成员属性（无法修改状态的属性）是线程安全的，可以修改的成员属性，在多线程情况下会有线程安全
### 3. 三级缓存
Spring IOC 容器里用于管理 Bean 的缓存，主要有**三级缓存**，当需要依赖注入时从一级开始寻找
需要注意到，三级缓存只能解决bean初始化的循环依赖问题，在创建bean时，如果有**有参构造器**是无法解决的，因为在创建实例阶段缓存里是没有东西的，无法注入依赖，但是可以通过懒加载，也就是需要的时候再去注入，可以将bean的创建延迟到初始化时用三级缓存的函数和一二级的缓存bean解决
```java
// 一级缓存：真正初始化完的单例
private final Map<String, Object> singletonObjects = new ConcurrentHashMap<>();

// 二级缓存：半成品对象（已经提前暴露的引用）
private final Map<String, Object> earlySingletonObjects = new HashMap<>();

// 三级缓存：ObjectFactory（延迟生成代理的工厂）
private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<>();
```
```java
public class A{
	privite B b;
	public A(@lazy B b){
		this.b=b;
	}
}
```
#### 一级缓存
singletonObjects：存储真正**完成了初始化（内部依赖已经注入）的bean实例**
#### 二级缓存
earlySingletonObjects：**没有完成初始化的bean实例**，这种是不能拿来直接用的（不能作为依赖直接注入到其他bean里），只能提前暴露引用，解决循环依赖问题
暴露引用，这个引用可能是原始对象或代理对象，可能是由三级缓存的函数生产的
#### 三级缓存
```java
// 提前暴露引用（三级缓存）
if (mbd.isSingleton()) {
	//getEarlyBeanReference延迟调用的函数，生成对象引用（可能是代理对象或者原始对象）
    addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, bean));
}
```
singletonFactories：ObjectFactory，提供创建 Bean 的工厂，用于**产生**提前暴露对象（如代理）

### 4. AOP
面向切面编程，用于将那些与业务无关的，但对多个对象产生影响的代码，抽取成公共块复用，降低代码耦合
可以通过环绕通知记录日志等
Spring的声明式事务就是使用AOP对方法进行了拦截，来开启事务，提交或回滚事务
### 5. 事务失效
#### 异常捕获处理
如果在方法内部将异常捕获后，**自行处理且没有继续向外抛出**，那么在发生异常后，代理对象的catch部分是无法被触发的，导致事务失效
#### 抛出检查异常
事务默认是catch运行时异常，如果**抛出的是检查时异常**，就无法正常检测
#### 非public方法
**只有方法是public方法，事务才能生效**，AOP本身只能拦截public方法，因为jdk动态代理的是接口，而接口里的方法都是public，CGLIB代理虽然可以代理类，但默认也只拦截 public 方法，因为 Spring 规范里事务注解是用于业务逻辑层（Service 层）公共 API 的事务控制。
## 二. SpringMVC
### 1. 执行流程
#### 视图阶段（JSP）
```txt
请求 -> DispatcherServlet -> HandlerMapping -> HandlerExecutionChain
       -> HandlerAdapter -> Controller -> ModelAndView -> ViewResolver
       -> View -> 渲染 HTML -> 返回给客户端
```
1. 用户发出请求会先到达前端控制器
2. 前端控制器会调用一个或多个处理器映射器
	1. 根据请求路径找到对应的处理器（controller中的某个方法）
	2. 同时处理器映射器会返回处理器执行链HandlerExecutionChain，其包含：handler，所有的拦截器
	3. **随后前端控制器顺序执行一次拦截器，出现false直接拒绝请求**
3. 前端控制器调用处理器适配器
	1. 前端控制器传入HandlerExecutionChain
	2. 调用对应的处理器适配器执行handler
	3. 处理器适配器进行参数解析，调用controller方法，返回ModelAndView给前端控制器，包含视图名称和模型数据
	4. **前端控制器逆序执行一遍拦截器**
4. 视图解析
	1. 前端控制器将ModelAndView传入视图解析器，
	2. 根据视图名称找到对应的jsp文件，返回一个view对象
5. 视图渲染
	1. 前端控制器调用view.render方法
	2. 将模型数据和jsp模板进行合并、渲染（如EL表达式）
	3. 最终生成HTML返回给浏览器

#### 前后端分离阶段
```txt
        浏览器/前端JS
             ↓
      DispatcherServlet
             ↓
     HandlerMapping  — 找到Controller方法
             ↓
     HandlerAdapter   — 调用目标方法
             ↓
     HttpMessageConverter
     （比如返回 JSON）
             ↓
     响应写回给前端
```
前面步骤都一致，在adaptor调用完controller方法之后会进行返回值处理，转换成json，封装进response，通过网络返回给前端
## 三. Springboot
### 1. 自动装配
```java
@Configuration
@EnableAutoConfiguration
@ComponentScan
public @interface SpringBootApplication { }
```
```java
@Target({ElementType.TYPE})  
@Retention(RetentionPolicy.RUNTIME)  
@Documented  
@Inherited  
@AutoConfigurationPackage  
@Import({AutoConfigurationImportSelector.class})  
public @interface EnableAutoConfiguration { }
```
1. 关键注解在于启动注解内的@**EnableAutoConfiguration**，它会触发自动装配流程
2. 它的@**Import({AutoConfigurationImportSelector.class})** 向spring容器中导入一个组件（configuration类）
3. spring通过调用AutoConfigurationImportSelector的selectImports方法，读取META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports自动装配文件
4. 逐个判断这个自动装配类是否满足装配条件:
```java
@AutoConfiguration  //xxxAutoConfiguration自动装配类的特征
@ConditionalOnClass({OllamaApi.class})  
@EnableConfigurationProperties({OllamaConnectionProperties.class}) //导入配置属性类
```
```java
@ConfigurationProperties("spring.ai.ollama.chat") //配置属性类特征，定义配置前缀
```
```java
@ConditionalOnClass：classpath 中有该类才生效
@ConditionalOnMissingBean：如果没有用户定义的 Bean，才注入默认 Bean
@ConditionalOnProperty：配置了某个属性才生效
@ConditionalOnBean：存在某个 Bean 才生效
```
5. 如果某个xxxAutoconfiguration满足所有条件就会将其内部定义的bean注入到ioc容器中
# Mybatis/Mybatis-plus
## 一 . Mybatis
### 1. 执行流程
```txt
     ┌─────────────┐
     │ SpringBoot  │（注入 Mapper、配置）
     └──────┬──────┘
            ↓
     ┌───────────────┐
     │ MapperProxy   │（动态代理 Mapper 接口）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ DefaultSqlSession│（真正执行 SQL 的类）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ Executor（执行器）│
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ StatementHandler │（预编译 SQL）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ ParameterHandler │（设置参数）
     └──────┬────────┘
            ↓
     ┌───────────────┐
     │ ResultSetHandler │（处理结果）
     └────────────────┘
```
- springboot启动后，mybatis的自动配置类会先读取mybatis.config文件配置，包括Mapper接口和Mapper文件的映射，数据库的连接信息
- Mapper接口在启动时被MapperScannerRegistrar扫描，创建出MapperFactoryBean，并由MapperFactoryBean生成一个代理对象MapperProxy，调用接口方法实际上是MapperProxy#invoke()方法执行sql：
```java
public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
    MapperMethod mapperMethod = cachedMapperMethod(method);
    return mapperMethod.execute(sqlSession, args);
}
```
- MapperProxy中会缓存每个Mapper的方法的方法名和参数
```java
public <T> T selectOne(String statement, Object parameter) {
    List<T> list = this.selectList(statement, parameter);
    return list.size() == 1 ? list.get(0) : null;
}
```
- 在execute中调用全局的sqlsession对象的selectOne方法，在selectList内部调用底层的Executor执行sql
- 根据方法签名找到对应的MappedStatement（xml文件中的sql标签）
- 创建PreparedStatementHandler对象进行预编译sql
- 调用ParameterHandler设置sql参数，将Java对象转换成sql数据
- 执行sql
- 调用ResultSetHandler解析结果集，封装成Java对象
## 二. Mybatis-plus
### 1. 执行流程
```java
public interface BaseMapper<T> {
    T selectById(Serializable id);
    int insert(T entity);
    ...
}
```
- 托管了BaseMapper的动态代理，封装了大量的CURD方法
- 项目启动时会将通用CURD方法注入到Mapper的代理对象中
- 自定义 Wrapper 构造器（QueryWrapper、UpdateWrapper）
## 三. 注意点
### 1. sql标签内$、#的区别
在执行mapper接口方法时，最后会创建PreparedStatementHandler对象进行预编译sql，这时如果sql标签内参数的占位符是$，会将方法传入的参数直接拼接进sql语句里不会进行预编译，这种方式会导致sql注入
如果使用的是#，会将原始sql的参数占位符替换成？占位符，然后进行预编译，之后再进行参数设置，相当于使用jdbc底层的prepareStatement方法进行参数传入，可以有效防止sql注入
### 2. 延迟加载
```xml
<resultMap id="userMap" type="User">
    <id property="id" column="id"/>
    <result property="name" column="name"/>
    
    <!-- collection 设置延迟加载,fetchType延迟加载字段，select延迟加载方法，可来自另外的接口 -->
    <collection property="orders"
                ofType="Order"
                select="selectOrdersByUserId"
                column="id"
	            延迟加载字段
                fetchType="lazy"/>
</resultMap>

<select id="selectUserById" resultMap="userMap">
    SELECT * FROM user WHERE id = #{id}
</select>

<select id="selectOrdersByUserId" resultType="Order">
    SELECT * FROM orders WHERE user_id = #{id}
</select>
```
关闭时，会将result里的额外字段一起加载，开启后只有在调用目标结果的get方法时才会调用延迟方法进行查询，然后通过set方法写入
### 3. 一、二级缓存
#### 一级缓存
```java
Sqlsession sqlsession =new Sqlsession();
UserMapper1 u1=sqlsession.getMapper(UserMapper.class);
UserMapper1 u2=sqlsession.getMapper(UserMapper.class);
u1.getbyid(1);
//第二个查询和第一个相同，因为在同一个sqlsession下，是不会重复查询而是从一级缓存里面取
u1.getbyid(1);
```
默认开启
本质是HashMap
作用域是sqlsession，在同一个sqlsession下的缓存数据就是一级缓存，相同的查询语句会优先去一级缓存里面找，当sqlsession进行flush或者close后，里面的缓存就会被清空
#### 二级缓存
默认关闭，除了要在配置文件配置外，还要给mapper文件添加 **<cache/>** ，标记此mapper接口开启二级缓存
作用域是mapper，和session无关，同一个接口的不同对象会在所属的session提交或关闭后将一级缓存数据缓存在二级缓存里，二级缓存的数据必须实现序列化接口
#### 清除
在某一个作用域（session作用域或者mapper作用域）的数据发生增删改，之后会将对应作用域的缓存数据清除
# 微服务

**五大组件：注册中心，负载均衡，远程调用，服务熔断，网关**
## 一. 注册中心
### 1. Nacos
##### 服务注册表结构
微服务将自己注册到Nacos后，会将自己的信息保存到注册表中，通过多级的map结构实现
```yaml
┌────────────────────────────────────────────────────────────┐
│                       Nacos 注册表                         │
│      registry: Map<namespaceId, Map<group@@service, Service>> │
└────────────────────────────────────────────────────────────┘
                             │
                             ▼
┌───────────────┐
│ Namespace: public（或自定义） │
└───────────────┘
       │
       ▼
┌────────────────────────────┐
│ Service: DEFAULT_GROUP@@user-service │
└────────────────────────────┘
       │
       ▼
┌────────────────────────────────────────┐
│ ClusterMap:                            │
│   ┌────────────────────────────────┐   │
│   │ Cluster: DEFAULT   可以配置多   │   │
│   │  ├─ metadata: {...}            │   │
│   │  ├─ HealthChecker: {...}       │   │
│   │  └─ instances: List<Instance>  │   │
│   └────────────────────────────────┘   │
└────────────────────────────────────────┘
       │
       ▼
┌─────────────────────────────────────────────────────┐
│ Instance:                                           │
│  ├─ ip: 192.168.1.100                               │
│  ├─ port: 8080                                      │
│  ├─ healthy: true                                   │
│  ├─ ephemeral: true                                 │
│  ├─ metadata: {version=1.0, env=prod}               │
│  └─ weight: 1.0                                     │
└─────────────────────────────────────────────────────┘

```
- namespace：环境隔离（test、pro，dev），包含多个service，不同namespace的服务实例不能互相发现
- service：一个微服务在一个namespace下的抽象表示，service中多个服务实例挂在它的集群Cluster中
- Cluster：每个service默认只有一个，可以手动扩展为多个，每个Cluster承载对应集群的实例
- Instance：服务实例，每个节点（ip+端口）对应一个实例，可以将其分配在同一service下的不同Cluster中
#### 支撑大量注册压力
```txt
[客户端发起注册请求]
           │
           ▼
[服务端接收（如 ServerA）]
  ├─ 解析参数，构建 Instance
  ├─ 本地注册表内存中添加 Instance
  │    └── registry.put(serviceKey, instance)
  └─ 创建一个【同步任务 SyncTask】

           ▼
[将 SyncTask 放入任务阻塞队列中]
           │
           ▼
【线程池（如 DistroTaskEngine）**异步单线程**消费任务】
  ├─ 从任务队列中取出任务
  ├─ 判断任务类型（Distro / Raft）
  |- 更新本地注册表
  └─ 执行集群注册表同步逻辑：
        ├─ 构造同步数据包
        ├─ HTTP/gRPC 推送给其他节点
        └─ 其他节点更新自身内存注册表

           ▼
[同时：将任务放入阻塞队列后主线程立即响应客户端注册成功 ✅]
```
为了应对注册压力，设置nacos集群，某个节点的service实例进行注册后，不会立即更新，会先将本地的旧的service实例和新注册的实例进行合并，放入缓存中，之后直接响应客户端，实际上放入缓存之后会开启异步任务，将更新任务放入阻塞队列中，利用线程池读取任务，异步单线程更新本地和其他nacos节点的注册表
#### 并发读写处理
copyOnwrite
```txt
[客户端注册 / 注销 / 修改实例]
           │
           ▼
[ServiceManager 接口层]
  ├─ 检查是否存在对应 Service / Cluster
  ├─ **使用同步锁保护关键注册流程**
  │     └── synchronized (Service.class) 或 ReentrantLock
  └─ 修改注册表：添加/删除/更新 Instance
           │
           ▼
	    加入阻塞队列中
		   │
           ▼
[任务线程获取一个同步任务，进行单线程异步处理 SyncTask]
           │
           ▼
【阶段1：读取本地注册表】
  └─ 取出当前 Service / Cluster 的 instances 列表（旧视图）

           │
           ▼
【阶段2：复制旧列表 + 合并新数据】
  ├─ 将旧列表 deep copy 一份（为了并发读写隔离）
  ├─ 把新同步来的 instances 与本地进行合并：
  │     ├─ 找出需要删除的（旧有但新数据中不存在）
  │     ├─ 找出需要更新的（IP相同，状态/metadata不同）
  │     └─ 找出需要新增的（新数据中有但本地没有）
  └─ 构造一个“新版本的 instances 列表”

           │
           ▼
【阶段3：将 Cluster 实例列表替换为新列表】
  └─ `cluster.setInstances(newInstanceList);`
           │
           ▼
【此操作为原子性写入，替换掉旧视图】
  → 内存中注册表正式更新
  → 对外暴露读接口时，读到的就是合并之后的数据
```
接取任务后先将本地的、其他nacos节点同步过来的实例信息进行copy并合并成一个新的副本，对其中相较于原来减少的进行删除、状态改变的修正状态、不变的保持不变、新增的进行添加。在此期间，客户端进行读，读到的是旧的注册表，在完成副本的处理后直接将旧的cluster/service进行替换，注意到异步任务是单线程处理的，避免并发执行出现脏数据
此方法在没有加大粒度锁的情况下，解决了读写冲突问题，也没有影响性能
#### Nacos和Eureka的区别
##### 实例类型
nacos有临时实例和永久实例，eureka只有临时实例
##### 健康检测
nacos会将临时实例和永久实例注册到两个不同的列表中
临时实例客户端会有一个向nacos发送心跳的任务，nacos判断当前发送心跳的时间戳和上一次发送心跳的时间戳间隔，如果超过了正常实例发送心跳任务规定的时间（正常心跳周期），就会将其标记为不健康实例，此外nacos也有一个定时的轮询任务，遍历临时列表的实例，判断当前时间戳和最近一次发送心跳的时间戳之间的间隔，如果超过了允许发送心跳的最大时间（最大心跳超过时间），就会将其标记为异常，对于异常的临时实例，nacos会直接剔除
对于永久实例，nacos中的一个线程池会轮询永久实例列表并主动发起请求询问实例是否存活，如果在规定时间返回响应说明就是健康的，如果超过了规定时间就会被标记会不健康，如果没有响应会标记为异常，对于异常的永久实例，nacos不会直接剔除

eureka只支持实例的心跳机制
##### 服务拉取
nacos支持定时拉取和订阅推送两种模式
定时拉取是指，客户端定时向服务端发送请求获取最新的服务信息，订阅推送是在服务信息发生变更时nacos会用udp套接字和客户端建立连接，将变更的信息广播给所有订阅的微服务，微服务会将变更的服务信息缓存到本地服务列表，下一次就会优先从缓存读取，缓存没有，再去nacos拉取

eureka只会进行定时拉取
## 二. 负载均衡
在客户端拉取到要调用的服务列表信息后，会使用负载均衡组件选择一个服务调用
注意在版本的spring boot已经弃用了ribbon，建议使用loadbalance
### 1. Ribbon
#### 负载均衡策略
- 简单轮询，对拉取到的服务挨个进行调用
- 按权重选择，响应时间越长的，权重越低
- 随机调用
- 以区域可用的服务器为基础进行选择，使用Zone对服务器进行分区，Zone可以理解为一个机房、一个机架，然后对Zone内多个服务进行轮询调用（默认）
- 忽略短路的服务，选择并发数较低的服务
- 针对一个服务进行重试机制，直到调用成功
- 可用性敏感策略，先过滤非健康的，选择连接数较小的
#### 自定义负载均衡策略
##### Bean配置
```java
@Configuration
public class RibbonClientConfig {

    @Bean
    public IRule ribbonRule() {
        return new CustomWeightRule();  // 自定义策略
    }
}
```
##### 配置文件配置
```yml
my-service: # 你想配置的服务名，必须和 @LoadBalanced 中使用的名称一致
  ribbon:
    NFLoadBalancerRuleClassName: com.example.ribbon.rule.CustomWeightRule
```
### 2. LoadBalancer
#### 自定义负载均衡策略
##### bean配置
```java
public class RandomLoadBalancer implements ReactorServiceInstanceLoadBalancer {

    private final String serviceId;
    private final ServiceInstanceListSupplier supplier;
    private final Random random = new Random();

    public RandomLoadBalancer(ServiceInstanceListSupplier supplier, String serviceId) {
        this.serviceId = serviceId;
        this.supplier = supplier;
    }

    @Override
    public Mono<Response<ServiceInstance>> choose(Request request) {
        return this.supplier.get().map(instances -> {
            if (instances.isEmpty()) return new EmptyResponse();
            int index = random.nextInt(instances.size());
            return new DefaultResponse(instances.get(index));
        });
    }
}
```
```java
@Configuration
public class LoadBalancerConfig {

    @Bean
    public ReactorServiceInstanceLoadBalancer randomLoadBalancer(
            ObjectProvider<ServiceInstanceListSupplier> supplier) {
        // 注意这里的 serviceId 必须与你访问的服务名一致
        return new RandomLoadBalancer(supplier.getIfAvailable(), "my-service");
    }
}
```
##### 配置文件配置
```yaml
spring:
  cloud:
    loadbalancer:
      ribbon:
        enabled: false  # 确保禁用 Ribbon
    loadbalancer:
      retry:
        enabled: true
    loadbalancer:
      hint: # 若使用灰度/标签，可扩展
        my-service: version=beta
```
### 3. 注意点
#### feign调用
feign调用实际上是new出一个客户端向远程服务发起请求，但是new出来的requestTemplate（请求模板）对象是只有参数没有请求上下文的请求头的，所以业务中会出现请求头丢失无法通过远程服务拦截器的情况
```java
@Component  
public class FeignRequestInterceptor implements RequestInterceptor {  
    @Override  
    public void apply(RequestTemplate requestTemplate) {  
  
        // 从当前请求上下文获取请求头  
        ServletRequestAttributes attributes =  
                (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();  
  
        //获取浏览器向服务器发送的请求，并获取请求头信息  
        if (attributes != null) {  
            HttpServletRequest request = attributes.getRequest();  
            requestTemplate.header("Cookie",request.getHeader("Cookie"));  
        }  
  
        //配置seata分布式事务的xid，用于分布式事务的传递，全局事务的分支事务需要xid才能注册到TC  
        String xid = RootContext.getXID();  
        requestTemplate.header(RootContext.KEY_XID, xid);  
    }  

```
在feign的代理对象发送request请求之前会过滤一遍RequestInterceptor的apply方法，所以可以通过实现RequestInterceptor接口的apply方法，从上下文中获取请求头设置进requestTemplate对象中
## 三. 服务降级/熔断
### 1. Hystrix
#### 服务雪崩
一个服务的异常导致整个服务链路的调用失败
#### 服务降级
服务自我保护或保护下游服务的逻辑，一般用于下游服务响应慢、不可用、错误频发等情况，通过降级策略避免系统调用链路雪崩
针对的是某个服务的接口
```java
@FeignClient(
    name = "user-service",              // 服务名
    fallback = UserClientFallback.class // 降级处理类
)
public interface UserClient {

    @GetMapping("/user/info")
    String getUserInfo();
}
```
```java
@Component
public class UserClientFallback implements UserClient {

    @Override
    public String getUserInfo() {
        return "【服务降级】用户服务不可用，稍后重试";
    }
}
```
```yml
feign:
  hystrix:
    enabled: true # 开启 Feign 的 Hystrix 降级支持

hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 3000
```
#### 熔断
防止某个服务频繁调用失败导致系统调用雪崩
针对的是整个服务
```java
@SpringBootApplication
@EnableFeignClients
@EnableCircuitBreaker // 开启 Hystrix 熔断（Spring Cloud Netflix）
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```
默认关闭需要手动打开，如果检测到10秒内请求失败超过50%，就会触发熔断机制，会立即短路调用，不再执行原调用方法，而是执行降级逻辑，每隔5秒会尝试放行一个请求，如果服务仍然不能响应，则继续熔断，否则关闭熔断，恢复正常请求
## 四. 服务限流
### 1. nginx漏桶算法限流
桶中存储的是请求，不管请求进入的流量是多少，始终按照一定的速率进行处理，如每秒处理5个，未被处理到的请求会在桶里等待，超过容量的请求会被舍弃或等待，处理速度平滑
```nginx
# nginx.config
http {
    # 1. 定义一个名为 one 的限速区域，这种限流配置必须在总配置文件配置
    limit_req_zone $binary_remote_addr zone=one:10m rate=5r/s;
    # 包含所有子配置
    include /etc/nginx/conf.d/*.conf;
}
```
```nginx
# gulimall.conf
	# 随后便可以在gulimall.conf这种针对于服务的反向代理文件里的server里使用one这个限流配置
	# 以下是使用实例
    server {
        listen 80;
        server_name gulimall.com;

		# 路由匹配
        location /api/ {
            # 2. 应用限速规则
            limit_req zone=one burst=10 nodelay;
            proxy_set_header Host $host;
			# 反向代理的服务器ip
            proxy_pass http://gulimall.com;
        }
    }
```
- binary_remote_addr：基于客户端的IP限流
- Zone定义一个共享存储区存储访问信息
- rate：最大访问速率，每秒只处理5个请求
- burst：桶的大小，超过容量之后，多余的请求会等待或直接拒绝
### 2. 网关令牌桶限流
桶中存储的是令牌，以一定速率生成令牌，请求进入时先申请获取令牌才能被处理，速度较为波动，默认使用redis存储令牌
```pom
<!-- Spring Cloud Gateway -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>

<!-- Redis 支持 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis-reactive</artifactId>
</dependency>
```
```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: user-api
          uri: http://localhost:8081 # 或注册中心的服务名称
          predicates:
            - Path=/api/user/**
          filters:
            - name: RequestRateLimiter
              args:
                key-resolver: '#{@ipKeyResolver}'  # 按请求来源的IP限流（自定义 Bean）
                redis-rate-limiter.replenishRate: 5  # 每秒填充5个令牌
                redis-rate-limiter.burstCapacity: 10 # 桶最大容量10个令牌
```
```java
@Configuration
public class RateLimiterConfig {
    @Bean
    public KeyResolver ipKeyResolver() {
        return exchange -> {
            String ip = exchange.getRequest()
                                 .getHeaders()
                                 .getFirst("X-Forwarded-For");
            if (ip == null) {
                ip = exchange.getRequest().getRemoteAddress().getAddress().getHostAddress();
            }
            return Mono.just(ip);
        };
    }
}
```
## 五. 服务安全校验
### 客户端配置
```pom
客户端依赖导入
<!-- Spring Security -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
</dependency>

<!-- Spring Security OAuth2 Client -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-client</artifactId>
</dependency>

<!-- Spring Cloud OpenFeign -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```
```java
//客户端注册
@Configuration
public class AuthorizationServerConfig {

    @Bean
    public RegisteredClientRepository registeredClientRepository() {
        RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString())
            .clientId("product-service")                          // 客户端ID
            .clientSecret("{noop}s3cr3tK3y!")                    // 客户端密钥，{noop}表示不编码
            .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS) // 授权模式
            .scope("read")                                        // 授权范围
            .build();

        // 这里使用内存存储，也可以用数据库存储
        return new InMemoryRegisteredClientRepository(registeredClient);
    }
}
```
```yaml
配置文件配置客户端信息
spring:
  security:
    oauth2:
      client:
        registration:
          product-service:
            client-id: product-service
            client-secret: s3cr3tK3y!
            authorization-grant-type: client_credentials
            scope: read
            provider: auth-server 
        provider:
          auth-server:
            token-uri: http://localhost:9000/oauth2/token


```
```java
//配置OAuth2AccessTokenInterceptor，向请求头中添加token的过滤器
@Configuration
public class FeignOAuth2Config {

	@Bean
    public OAuth2AuthorizedClientManager authorizedClientManager(
            ClientRegistrationRepository registrations,
            OAuth2AuthorizedClientRepository clients) {

        OAuth2AuthorizedClientProvider provider =
                OAuth2AuthorizedClientProviderBuilder.builder()
                        .clientCredentials()
                        .build();

        DefaultOAuth2AuthorizedClientManager manager =
                new DefaultOAuth2AuthorizedClientManager(registrations, clients);

        manager.setAuthorizedClientProvider(provider);

        return manager;
    }
}

    @Bean
    public RequestInterceptor oauth2FeignRequestInterceptor(
            OAuth2AuthorizedClientManager authorizedClientManager) {
        return new OAuth2AccessTokenInterceptor(authorizedClientManager);
    }
}
```
### 认证服务器搭建
```pom
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.security</groupId>
    <artifactId>spring-security-oauth2-authorization-server</artifactId>
    <version>1.1.0</version> <!-- 请确认最新版本 -->
</dependency>

<dependency>
    <groupId>org.springframework.security</groupId>
    <artifactId>spring-security-oauth2-jose</artifactId>
</dependency>
```
```java
//拦截规则
@Configuration
public class ResourceServerSecurityConfig {

    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http
            .authorizeHttpRequests(authorize -> authorize
                .requestMatchers("/public/**").permitAll() // 不拦截
                .anyRequest().authenticated()              // 其他都需要带 token
            )
            .oauth2ResourceServer(oauth2 -> oauth2.jwt()); // 指定用 JWT 方式认证

        return http.build();
    }
}
```
```java
@Configuration
public class AuthorizationServerConfig {

    @Bean
    public RegisteredClientRepository registeredClientRepository() {
        RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString())
                .clientId("product-service")
                .clientSecret("{noop}s3cr3tK3y!")
                .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS)
                .scope("read")
                .tokenSettings(TokenSettings.builder()
                    .accessTokenTimeToLive(Duration.ofHours(1))
                    .build())
                .build();

        return new InMemoryRegisteredClientRepository(registeredClient);
    }

    @Bean
    public SecurityFilterChain authorizationServerSecurityFilterChain(HttpSecurity http) throws Exception {
        OAuth2AuthorizationServerConfiguration.applyDefaultSecurity(http);
        return http.formLogin().and().build();
    }

    // 生成RSA密钥对（用于签发JWT）
    @Bean
    public KeyPair keyPair() {
        try {
            KeyPairGenerator generator = KeyPairGenerator.getInstance("RSA");
            generator.initialize(2048);
            return generator.generateKeyPair();
        } catch (Exception e) {
            throw new IllegalStateException(e);
        }
    }

    // JWT 编码器
	@Bean
	public JWKSource<SecurityContext> jwkSource(KeyPair keyPair) {
	    RSAKey rsaKey = new RSAKey.Builder((RSAPublicKey) keyPair.getPublic())
	            .privateKey(keyPair.getPrivate())
	            .keyID(UUID.randomUUID().toString())
	            .build();
	    JWKSet jwkSet = new JWKSet(rsaKey);
	    return (jwkSelector, securityContext) -> jwkSelector.select(jwkSet);
	}

	@Bean
	public JwtEncoder jwtEncoder(JWKSource<SecurityContext> jwkSource) {
	    return new NimbusJwtEncoder(jwkSource);
	}

    // JWT 解码器（资源服务器用）
    @Bean
    public JwtDecoder jwtDecoder(KeyPair keyPair) {
        return NimbusJwtDecoder.withPublicKey((RSAPublicKey) keyPair.getPublic()).build();
    }

    @Bean
    public ProviderSettings providerSettings() {
        return ProviderSettings.builder()
                .issuer("http://localhost:9000")  // 你的认证服务器地址
                .build();
    }
}
```
```yml
spring:
  security:
    oauth2:
      resourceserver:
        jwt:
          jwk-set-uri: http://localhost:9000/oauth2/jwks
```
## 六. CAP和BASE
### CAP
- 分布式系统节点通过网络进行连接，由于网络问题一定会出现分区问题（P）
- 当分区出现，系统的一致性（C）和可用性（A）就无法同时满足
### BASE
- 基本可用
- 软状态
- 最终一致：各分支事务完成之后进行提交，如果有不一致的情况，再想办法恢复数据，存在中间状态，占用资源少，可用性高
- 强一致：各分支事务完成后先不进行提交，彼此等待执行结果，然后统一进行提交或回滚，不存在中间状态，占用资源多，一致性强，可用性差
## 七. 分布式事务
### 1. seate
```txt
+------------------+            +------------------+            +------------------+
|                  |            |                  |            |                  |
|       TM         |  ——Begin→  |       TC         |  ——Reg→    |       RM         |
| (事务发起者)      |             | (事务协调者)     |             |  (资源操作员)    |
|                  |  ←Result—— |                  |  ←Branch—  |                  |
+------------------+            +------------------+            +------------------+
         |                            ↑      ↑                         ↑
         |                            |      |                         |
         |——commit()/rollback()——→    |      |——→ prepare/commit/rollback()
```

| 组件                              | 所属  | 作用                          |
| ------------------------------- | --- | --------------------------- |
| **TM（Transaction Manager）**     | 客户端 | 管理全局事务的生命周期，决定事务总体的开启、提交、回滚 |
| **RM（Resource Manager）**        | 客户端 | 管理本地资源（数据库、消息等），向 TC 注册分支事务 |
| **TC（Transaction Coordinator）** | 服务端 | 协调、监控和维护全局事务状态，调度分支提交/回滚    |
执行流程

| 步骤  | 参与者    | 行为                                     |
| --- | ------ | -------------------------------------- |
| 1   | **TM** | 开启全局事务，向 **TC** 注册，获取 `XID`            |
| 2   | **RM** | 各个微服务中远程调用时，用 `XID` 向 TC 注册分支事务        |
| 3   | **TM** | 所有远程服务都调用完毕，告诉 **TC** 统一提交 or 回滚       |
| 4   | **TC** | 协调所有 **RM** 做 commit 或 rollback（两阶段提交） |
| 5   | **RM** | 根据 UNDO 日志等信息真正提交或回滚数据库事务              |
#### XA（强一致性）
RM中执行完业务sql先不进行提交，等待各个分支事务完成之后，将执行状态统一报告给TC，TC检查各分支事务的执行状态全部成功通知RM提交事务，如果有失败则通知RM全部回滚
#### AT（最终一致）
各个RM执行完直接提交，并会记录执行前后的undo_log数据快照，之后将执行状态报告TC，TC检查执行状态，全部成功删除RM的undo_log，如果有失败则根据undo_log恢复执行事务前的数据，没有过多占用资源
#### TCC
需要手动在代码层面实现try、confirm、cancel方法，代码侵入高，耦合度高
1. try：先进行资源的检测和预留，RM向TC报告预留状态
2. Confirm/Cancel：如果全部成功，则真正执行业务并提交，如果有失败则释放锁定的资源
## 八. 接口幂等性
### 1. 数据库添加唯一索引
### 2. token+redis
```java
String script = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";  
Long execute = redisTemplate.execute(new DefaultRedisScript<>(script, Long.class), Arrays.asList(OrderConstant.ORDER_TOKEN_PREFIX + userInfo.getId()),orderToken);
```
在生成订单页面同时生成一个唯一token保存在redis中，并将这个token连带订单页面信息一同返回给前端，当前端提交订单时会将这个token带上，之后使用lua脚本判断是否存在这个token并删除（保证原子性，防止并发状况导致多次提交），如果成功则执行业务，否则说明已经处理过了直接返回，解决订单防刷和网络波动等问题
### 3. 分布式锁
## 九. xxl-job
### 1. 路由规则
- 轮询
- 故障转移：依次检测心跳，如果心跳正常，则选择当前实例执行
- 分片广播：广播所有实例执行一次任务，按照任务数对实例数取模运算分配任务
### 2. 任务执行失败
- 路由策略选择故障转移，让健康的实例执行任务
- 设置任务重试次数
- 查看日志+邮件通知
### 3. 大数据量任务执行
部署多个实例，路由选择分片广播
# 消息中间件
## 一. RabbitMQ
### 1. 消息不丢失
```txt
  [Producer]
      |
      | 发送消息 (publish)
      v
  +-----------+
  |  Broker   |
  | (RabbitMQ)|
  +-----------+
      |
      |  路由消息
      v
  +-----------+
  | Exchange  |<-- 交换机（Direct/Topic/Fanout/Headers）
  +-----------+
      |
      | 根据绑定规则 (Binding)
      v
  +-----------+
  |   Queue   |<-- 消息队列
  +-----------+
      |
      | 消费消息 (consume)
      v
  [Consumer]
```
投递消息到消费消息过程中都有可能丢失消息
```yaml
rabbitmq:  
  host: 192.168.88.101  
  port: 5672  
  virtual-host: /  
  username: guest  
  password: guest  
  publisher-confirm-type: correlated # 发送者启用confirm模式  
  publisher-returns: true # 启用returnCallback  
  listener:  
    simple:  
      acknowledge-mode: manual # 手动ack  
      auto-startup: true  
      retry:  
        enabled: true # 开启重试机制  
        max-attempts: 3 # 最大重试次数  如果仍然接收不到消息则投递到异常队列
  template:  
    mandatory: true # 强制指定消息发送成功
```
配置发送者confirm消息投递到broker，returnCallback由exchange路由到queue的回调函数
```java
@Configuration  
@Slf4j  
public class PublisherCallback {  
  
    @Autowired  
    private RabbitTemplate rabbitTemplate;  
  
    @PostConstruct
    public void init() {  
        rabbitTemplate.setMandatory(true); // ❗确保 returnCallback 被触发  
  
        //消息投递到Broker的回调函数，confirmCallback  
        //ack表示是否成功，cause包含失败原因  
        rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -> {  
            if (ack) {  
                log.info("消息发送成功,correlationData[{}]", correlationData);  
            } else {  
                log.error("消息发送失败,correlationData[{}],cause[{}]", correlationData, cause);  
            }  
        });  
  
        //消息没有成功由交换机路由到队列的回调函数，returnCallback  
         rabbitTemplate.setReturnsCallback(returnedMessage -> {  
            log.error("消息没有路由到队列,returnedMessage[{}]", returnedMessage);  
        });  
    }  
}
```
消费者手动确认消息是否被消费
```java
//Ack确认消息被消费
channel.basicAck((Long) message.getHeaders().get("amqp_deliveryTag"), false);
//Nack消费失败
channel.basicNack(  
        (Long) message.getHeaders().get("amqp_deliveryTag"),  //消息的唯一标识
        false,  //是否批量拒绝，如果为true，则会一次性拒绝deliveryTag小于等于传入值的消息；如果为false，则只拒绝传入值的消息。
        true/false//是否重新入队
);
```
持久化交换机、队列和消息,消息默认存储在内存中，需要在创建消息的时候将其设置为持久化
```java
@Configuration  
public class MQConfig {  
  
    public Queue orderSeckillOrderQueue() {  
        return new Queue("order.seckill.order.queue", true, false, false);  
    }  
    @Bean  
    public Exchange orderEventExchange() {  
        return new TopicExchange("order-event-exchange", true, false, null);  
    }  
    @Bean  
    public Binding OrderSeckillOrderBinding() {  
        return new Binding("order.seckill.order.queue", Binding.DestinationType.QUEUE, "order-event-exchange", "order.seckill.order", null);  
    }  
}
```
```java
public static Message generateMessage(RabbitTemplate rabbitTemplate, Object messageBody) {  
    MessageProperties messageProperties = new MessageProperties();  
    //设置消息的属性  
    //设置消息的id，此id用于将消息保存到redis中，检查幂等性  
    messageProperties.setMessageId(UUID.randomUUID().toString());  
    //设置消息持久化，保证rabbitmq重启后消息不丢失  
    messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT);  
    return rabbitTemplate.getMessageConverter().toMessage(messageBody, messageProperties);  
}
```
### 2. 消息重复消费
发送消息时，为每条消息设置唯一的id，并存储在redis中，消费者校验id是否存在，如果存在则已经消费，否则没有消费或其他监听者消费失败
### 3. 延迟队列
ttl+死信交换机，把消息投递给交换机，由这个交换机根据路由键把消息路由给死信队列，但是这个死信队列没有监听者消费，超时之后会将消息投递给死信交换机，由死信交换机根据死信路由键把消息路由给另一个和死信交换机绑定的队列
```java
@Bean  
public Queue orderDelayQueue() {  
    Map<String, Object> arguments = new HashMap<>();  
    arguments.put("x-dead-letter-exchange", "order-event-exchange");//死信交换机  
    arguments.put("x-dead-letter-routing-key", "order.release.order");//死信路由键，注意它的意思是死信交给死信交换机前死信的路由键就会变成这个，它必须是和死信交换机绑定的队列的路由键一样  
    arguments.put("x-message-ttl", 1800000);//消息存活时间，单位毫秒，这里是30分钟  
    return new Queue("order.delay.queue", true, false, false, arguments);  
}
@Bean  
public Queue orderReleaseOrderQueue() {  
    return new Queue("order.release.order.queue", true, false, false);  
}
@Bean  
public Binding OrderCreateOrderBinding() {  
    return new Binding("order.delay.queue", Binding.DestinationType.QUEUE, "order-event-exchange", "order.create.order", null);  
}
@Bean  
public Binding OrderReleaseOrderBinding() {  
    return new Binding("order.release.order.queue", Binding.DestinationType.QUEUE, "order-event-exchange", "order.release.order", null);  
}
```
### 4. 消息堆积
- 增加更多消费者去消费
- 在消费者内部开启线程池加快处理速度
- 增加队列容积，采用惰性队列（消息存储在磁盘中）
### 5. 高可用
#### 普通集群
```txt
  ┌────────┐      ┌────────┐      ┌────────┐
  │ Node A │<---->│ Node B │<---->│ Node C │
  └────────┘      └────────┘      └────────┘
```
每个节点共享交换机信息和部分队列信息，队列绑定在哪个节点数据就存储在哪个节点，其他节点只有这个队列的引用信息，当客户端访问的节点没有对应队列的数据时，队列所在节点会把数据发给当前节点返回给客户端
#### 镜像集群
```txt
          (同步复制机制)
        ┌─────────────────────┐
        │                     │
  ┌────────┐   ┌────────┐   ┌────────┐
  │ Node A │<->│ Node B │<->│ Node C │
  └────────┘   └────────┘   └────────┘
      ▲             ▲             ▲
      │             │             │
     主队列       镜像副本     镜像副本
    （Master）   （Slave）     （Slave）
```
队列数据自动同步到其他镜像节点，当主节点宕机副本自动成为新的master，高可用，但同步数据开销大，性能下降
#### 仲裁模式
```txt
    (使用 Raft 协议强一致复制)
        ┌────────┐
        │Client  │
        └───┬────┘
            │
        ┌───▼────┐
        │ Leader │  ←  写操作、投票主节点
        └───┬────┘
     ┌──────┴──────┐
     ▼             ▼
┌────────┐     ┌────────┐
│Follower│     │Follower│
└────────┘     └────────┘
```
主从同步采用raft协议、强一致，使用简单

| 模式          | 数据副本 | 容灾能力 | 性能  | 官方推荐 | 备注            |
| ----------- | ---- | ---- | --- | ---- | ------------- |
| 普通集群        | 无    | 差    | 高   | ❌    | 队列挂在哪个节点算谁的   |
| 镜像队列集群      | 手动配置 | 高    | 中-低 | ⚠️弃用 | 同步成本高、复杂      |
| Quorum 队列集群 | 自动控制 | 高    | 中   | ✅推荐  | Raft强一致，适合新项目 |
## 二. kafka
### 1. 消息不丢失
# 基础
## 一. 常见集合
### 1. 数组
#### 为什么索引下标从0开始
通过索引访问元素实际上是通过 **数组首地址+索引 * 数组数据类型长度** 得到的，如果下标从1开始，索引要额外进行减1运算，增加了cpu的运算
#### 插入/修改/删除
都是O( n )复杂度
### 2. ArrayList
#### 成员属性、构造函数、add方法
```java
//默认的初始化容量
private static final int DEFAULT_CAPACITY = 10;  

//两个容量是0的缓冲区，用来区分有参和无参创建出的list集合，在首次扩容时会有区别
private static final Object[] EMPTY_ELEMENTDATA = {}; 

private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};  

//短暂性存储数据的数组，在扩容时是直接进行数组拷贝+替换，地址会改变
transient Object[] elementData;

//元素个数并非容量
private int size;

//有参构造器，创建一个指定容量的list，如果参数是0，直接将EMPTY_ELEMENTDATA成员变量
//赋给elementData
public ArrayList(int initialCapacity) {  
    if (initialCapacity > 0) {  
        this.elementData = new Object[initialCapacity];  
    } else if (initialCapacity == 0) {  
        this.elementData = EMPTY_ELEMENTDATA;  
    } else {  
        throw new IllegalArgumentException("Illegal Capacity: "+  
                                           initialCapacity);  
    }  
}  

//无参构造，直接将DEFAULTCAPACITY_EMPTY_ELEMENTDATA赋给elementData
public ArrayList() {  
    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;  
}  

//接收collection参数，将其直接赋给elementData，或将其元素拷贝+替换给elementData
public ArrayList(Collection<? extends E> c) {  
    Object[] a = c.toArray();  
    if ((size = a.length) != 0) {  
        if (c.getClass() == ArrayList.class) {  
            elementData = a;  
        } else {  
            elementData = Arrays.copyOf(a, size, Object[].class);  
        }  
    } else {  
        // 如果参数长度为0，则为 EMPTY_ELEMENTDATA
        elementData = EMPTY_ELEMENTDATA;  
    }  
}
```

| 字段名                                 | 含义             | 用途                                                                 |
| ----------------------------------- | -------------- | ------------------------------------------------------------------ |
| `EMPTY_ELEMENTDATA`                 | 真正的空数组         | 通过 `new ArrayList(0)` 创建时用它，表示**容量就是 0**                           |
| `DEFAULTCAPACITY_EMPTY_ELEMENTDATA` | 空数组，占位用，懒初始化时用 | 通过 `new ArrayList()` 创建时用它，表示**初始容量为默认值（10），但尚未分配** ，在首次添加元素之后分配空间 |

```java
public boolean add(E e) {  
    modCount++;  
    add(e, elementData, size);  
    return true;  
}
private void add(E e, Object[] elementData, int s) {  
    if (s == elementData.length)  
        elementData = grow();  
    elementData[s] = e;  
    size = s + 1;  
}
private Object[] grow() {  
    return grow(size + 1);  
}
private Object[] grow(int minCapacity) {  
    int oldCapacity = elementData.length;  
    if (oldCapacity > 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {  
        int newCapacity = ArraysSupport.newLength(oldCapacity,  
                minCapacity - oldCapacity, /* minimum growth */  
                oldCapacity >> 1           /* preferred growth */);  
                //拷贝并替换
        return elementData = Arrays.copyOf(elementData, newCapacity);  
    } else {  
    //如果是`DEFAULTCAPACITY_EMPTY_ELEMENTDATA`且首次添加，则直接扩容到10
        return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)];  
    }  
}
```
当所需最小容量超过当前容量时，触发扩容，比较 **当前容量 * 1.5和所需最小容量，取较大值** 成为新elementData的长度，且将原来的元素copy成新的数组并替换原来的
但是通过 **new ArrayList()** 创建的list **初始默认容量是10**，但实际上还没有真正分配空间，实际大小是0，在首次添加元素时，会利用 **DEFAULTCAPACITY_EMPTY_ELEMENTDATA** 判断是否是由无参构造创建的，如果是则直接扩容到默认的初始大小10
#### list和数组转换
通常使用Arrays.asList( T... a )方法将数组转成list
```java
public static <T> List<T> asList(T... a) {  
    return new ArrayList<>(a);  
}

private static class ArrayList<E> extends AbstractList<E>  
    implements RandomAccess, java.io.Serializable{
	private final E[] a;
	ArrayList(E[] array) {  
	    a = Objects.requireNonNull(array);  
	}
}
```
注意这个返回的ArrayList是Arrays内部的一个静态类，通过它的构造方法，判断传入的数组是否为空，如果不为空就直接赋给了内部的成员变量，也就是实际存储数据的变量，数组和成员变量指向同一个地址，所以当数组内容发生改变，转成的list也是会变化的

使用toArray((T[] a)方法将list转成数组
```java
public <T> T[] toArray(T[] a) {  
    int size = size();  
    if (a.length < size)  
	    //拷贝this.a
        return Arrays.copyOf(this.a, size,  
                             (Class<? extends T[]>) a.getClass());  
    System.arraycopy(this.a, 0, a, 0, size);  
    if (a.length > size)  
        a[size] = null;  
    return a;  
}
```
把list内的a，也就是实际存储数据的数组，copy元素进传入的数组参数中（浅拷贝），然后将copy完成的参数数组返回，两者没有指向同一个地址，所以list变化影响不到数组
#### ArrayList和LinkedList区别
##### 底层结构
ArrayList底层是Object[ ]数组，LinkedList底层是双向链表
##### 效率
- ArrayList支持索引查询，LinkedList不支持
- 查询未知元素两者都需要遍历，O(n)
- ArrayList尾部插入和删除是O(1)，其他位置需要遍历是O(n)
- LinkedList头尾插入和删除是是O(1)，其他位置需要遍历是O(n)
##### 空间
ArrayList使用数组，空间连续，占用内存小，LinkedList使用链表，节点还包含双向指针，占用内容大
##### 线程安全
都不是线程安全的
可以只在方法内创建并使用list
```java
List<Integer> list = Collections.synchronizedList(thereIsNoParametricStructure);
public static <T> List<T> synchronizedList(List<T> list) {  
    return (list instanceof RandomAccess ?  
            new SynchronizedRandomAccessList<>(list) :  
            new SynchronizedList<>(list));  
}

static class SynchronizedList<E>  
    extends SynchronizedCollection<E>  
    implements List<E> {  
    
    @SuppressWarnings("serial") // Conditionally serializable  
    final List<E> list;  
  
    SynchronizedList(List<E> list) {  
        super(list);  
        //直接赋
        this.list = list;  
    }
}
```
可以使用Collections.synchronizedList方法使其线程安全，本质上是给原集合加上了sync锁，封装成了SynchronizedList集合返回，其内部的list变量和传入方法的原list指向同一个地址
### 3. HashMap
#### 实现原理
使用数组+链表或红黑树的结构（hash表），数组的元素是链表或红黑树
存储时，根据key计算它的hash值得到数组下标，如果出现hash值相同的情况，key相同则覆盖原来的值，key不同则放入链表或红黑树中
查找时，计算hash值得到下标，在根据key到链表或红黑树中判断key是否一致，查找对应的值
jdk8之前只有数组+链表，之后才是数组+链表或红黑树
##### 链表变为红黑树
当数组长度大于等于64，某个元素的链表长度大于等于8，则会将该元素的链表转换为红黑树
#### put方法
##### 执行流程
```txt
Start
 |
 |---> 1. key == null ?
 |         |
 |         |-- Yes --> 插入或替换 table[0]（链表/树结构）
 |         |
 |         |-- No --> 计算 key 的 hash 值（hash(key)）
 |
 |---> 2. 计算索引位置 index = (n - 1) & hash
 |
 |---> 3. table[index] 是否为 null？
 |         |
 |         |-- Yes --> 创建新节点，直接插入
 |         |
 |         |-- No --> 冲突处理：
 |                |
 |                |-- 节点 key 相同（equals 判断）？
 |                |       |
 |                |       |-- Yes --> 替换旧值
 |                |       |
 |                |       |-- No --> 遍历链表/树
 |                |                 |
 |                |                 |-- 查到重复 key？替换旧值
 |                |                 |-- 否，尾部插入新节点
 |                |
 |                |-- 如果链表长度 ≥ TREEIFY_THRESHOLD（默认 8）
 |                        |
 |                        |-- 是 --> 转换为红黑树
 |
 |---> 4. size++
 |
 |---> 5. 判断 size > threshold？
 |         |
 |         |-- 是 --> resize() 扩容
 |
End
```
##### 成员变量和构造函数
```java
//默认的初始容量
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
//最大容量
static final int MAXIMUM_CAPACITY = 1 << 30;
//默认负载因子
static final float DEFAULT_LOAD_FACTOR = 0.75f;
//链表转换成红黑树的长度临界值
static final int TREEIFY_THRESHOLD = 8;
//红黑树退化成链表的临界值
static final int UNTREEIFY_THRESHOLD = 6;
//触发链表转换成红黑树的数组长度最小要求
static final int MIN_TREEIFY_CAPACITY = 64;
//存储k，v的数组，哈希表
transient Node<K,V>[] table;
//存储元素的多少
transient int size;
//触发扩容的阈值，当前最大容量*负载因子
int threshold;
```
之所以临界值和默认负载因子要设置成这样是因为出于经验考虑和泊松分布统计而来，当负载因子为0.75时空间浪费不严重，且哈希冲突次数较少，如果因子较小则空间浪费严重，较大则哈希冲突次数变多。链表长度大于8时查找性能就会从O(1)下降到O(n)，转换成红黑树查找效率能得到提升，如果转换临界值小于8则过早转换浪费大量空间（红黑树耗费空间），大于8则查找效率低下
```java
//无参构造，设置负载因子为默认的，注意这种情况下扩容阈值为0
public HashMap() {  
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted  
}
public HashMap(int initialCapacity) {  
	//传入指定容量和默认负载因子
    this(initialCapacity, DEFAULT_LOAD_FACTOR);  
}
//有参构造
public HashMap(int initialCapacity, float loadFactor) {  
    if (initialCapacity < 0)  
        throw new IllegalArgumentException("Illegal initial capacity: " +  
                                           initialCapacity);
	 //指定容量大于最大容量，取最大容量
    if (initialCapacity > MAXIMUM_CAPACITY)  
        initialCapacity = MAXIMUM_CAPACITY;  
    if (loadFactor <= 0 || Float.isNaN(loadFactor))  
        throw new IllegalArgumentException("Illegal load factor: " +  
                                           loadFactor);  
    this.loadFactor = loadFactor; 
    //提前计算出初始化容量大小，只不过赋值给了阈值变量，由此看出有参构造初始化时，扩容阈值就不会是0，和无参构造区分开了，而其真正的阈值会在第一次put是才真正计算
    this.threshold = tableSizeFor(initialCapacity);  
}
//由于hashmap要求容量只能是2的幂次，所以会将真实容量设置为大于等于有参构造传入参数的最小2的幂次
static final int tableSizeFor(int cap) {  
    int n = -1 >>> Integer.numberOfLeadingZeros(cap - 1);  
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;  
}
```
##### put方法
```java
public V put(K key, V value) {  
    return putVal(hash(key), key, value, false, true);  
}
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,  
               boolean evict) {  
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    //先判断table是否为空或者长度为0，如果是就要初始化容量  
    if ((tab = table) == null || (n = tab.length) == 0)  
        n = (tab = resize()).length;
    //判断key要插入的位置是否为空，为空直接插入  
    if ((p = tab[i = (n - 1) & hash]) == null)  
        tab[i] = newNode(hash, key, value, null);  
    else {  
        Node<K,V> e; K k;  
        //查找桶中第一个元素，是否key相同，相同则进行覆盖
        if (p.hash == hash &&  
            ((k = p.key) == key || (key != null && key.equals(k))))  
            e = p;  
        else if (p instanceof TreeNode)  
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);  
        else {  
	        //不相同则进入链表进行遍历
            for (int binCount = 0; ; ++binCount) {  
	            //如果找到末尾仍然没有匹配的则插入到尾部
	            //如果链表长度大于8则转换成红黑树
                if ((e = p.next) == null) {  
                    p.next = newNode(hash, key, value, null);  
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  
                        treeifyBin(tab, hash);  
                    break;  
                }  
                //找到匹配节点直接退出
                if (e.hash == hash &&  
                    ((k = e.key) == key || (key != null && key.equals(k))))  
                    break;  
                p = e;  
            }  
        }  
        //如果找到的节点为空，更新节点
        if (e != null) { // existing mapping for key  
            V oldValue = e.value;  
            if (!onlyIfAbsent || oldValue == null)  
                e.value = value;  
            afterNodeAccess(e);  
            return oldValue;  
        }  
    }  
    //增加修改次数
    ++modCount;  
    //判断元素个数是否超过阈值，超过则进行扩容，如果是新增才会触发++，覆盖旧的不会
    if (++size > threshold)  
        resize();  
    afterNodeInsertion(evict);  
    return null;  
}
```
#### 扩容
```java
final Node<K,V>[] resize() {  
	//引用table
    Node<K,V>[] oldTab = table; 
    //如果为空容量为0，否则为哈希表的长度 
    int oldCap = (oldTab == null) ? 0 : oldTab.length;  
    //记录当前扩容阈值
    int oldThr = threshold;  
    //定义新的容量和扩容阈值
    int newCap, newThr = 0;  
    //如果当前容量大于0
    if (oldCap > 0) {  
		//容量已经达到最大容量，设置扩容阈值，返回当前哈希表，表示不再扩容
        if (oldCap >= MAXIMUM_CAPACITY) {  
            threshold = Integer.MAX_VALUE;  
            return oldTab;  
        }  
        //没有到最大容量，则将容量翻倍，同时扩容阈值也因此翻倍
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&  
                 oldCap >= DEFAULT_INITIAL_CAPACITY)  
            newThr = oldThr << 1; // double threshold  
    }  
    //如果当前容量为0，且扩容阈值大于0（哈希表没有初始化），将容量设置为当前扩容阈值
    //注意，此种情况只有使用的是有参构造才会出现，传了初始容量，在构造方法里提前计算了初始化容量赋给了阈值变量
    else if (oldThr > 0) // initial capacity was placed in threshold  
        newCap = oldThr;  
    else {               // zero initial threshold signifies using defaults  
	    //如果容量和阈值都为0，则使用默认容量16和阈值
	    //此种情况使用的是无参构造才会出现，因为无参构造没有传初始容量，则阈值计算出来才是0
        newCap = DEFAULT_INITIAL_CAPACITY;  
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);  
    }  
    //计算扩容阈值
    if (newThr == 0) {  
        float ft = (float)newCap * loadFactor;  
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?  
                  (int)ft : Integer.MAX_VALUE);  
    }  
    //更新阈值
    threshold = newThr;  
    @SuppressWarnings({"rawtypes","unchecked"}) 
    //创建新的哈希表，长度为扩容之后的长度 
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];  
    //直接替换掉旧的哈希表
    table = newTab;  
    //把旧的哈希表的数据拷贝过去
    if (oldTab != null) {  
        for (int j = 0; j < oldCap; ++j) {  
            Node<K,V> e;  
            if ((e = oldTab[j]) != null) {  
                oldTab[j] = null;  
                if (e.next == null)  
                    newTab[e.hash & (newCap - 1)] = e;  
                else if (e instanceof TreeNode)  
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);  
                else { // preserve order  
                    Node<K,V> loHead = null, loTail = null;  
                    Node<K,V> hiHead = null, hiTail = null;  
                    Node<K,V> next;  
                    do {  
                        next = e.next;  
                        if ((e.hash & oldCap) == 0) {  
                            if (loTail == null)  
                                loHead = e;  
                            else  
                                loTail.next = e;  
                            loTail = e;  
                        }  
                        else {  
                            if (hiTail == null)  
                                hiHead = e;  
                            else  
                                hiTail.next = e;  
                            hiTail = e;  
                        }  
                    } while ((e = next) != null);  
                    if (loTail != null) {  
                        loTail.next = null;  
                        newTab[j] = loHead;  
                    }  
                    if (hiTail != null) {  
                        hiTail.next = null;  
                        newTab[j + oldCap] = hiHead;  
                    }  
                }  
            }  
        }  
    }  
    return newTab;  
}
```
#### 寻址方式
```java
static final int hash(Object key) {  
    int h;  
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);  
}
```
先通过hashCode方法得到哈希值，然后将其向右位移16位的值和自己做异或运算进行二次哈希，之所以要进行二次哈希是为了让哈希值更均匀
```java
newTab[e.hash & (newCap - 1)]

(e.hash & oldCap) == 0
 ```
根据哈希值计算索引时是用哈希值对数组长度取模，但是cup的取余运算会有多步操作，如果数组长度是2的幂次可以将其等价为**hash&(长度-1)**，只需要一次运算，增加了性能
而且在扩容时需要重新计算哈希值对应的索引，如果数组长度是2的幂次，可以直接通过**hash&oldCap**的运算快速判断元素是否要留在原来的位置还是新的位置（当前位置+旧的数组长度）
#### 1.7HashMap多线程死循环
1.7的hashmap进行数据迁移使用头插法将链表元素移动，相当于迁移之后链表发生颠倒，在多线程情况下，线程二完成了迁移链表颠倒，线程一对链表头部的引用仍然是没有颠倒之前的，如之前是
A->B，线程二之后成了B->A，线程一对链表头部的引用仍然是A而不是B，next是B，B的next又是A，造成循环A->B->A
## 二. 常见类
### 1. Integer
#### 自动装箱
```java
//java代码
Integer a=123;
//编译后的字节码文件
Integer a=Integer.valueOf(123);
```
int类型的值能自动被封装成Integer对象，是因为在编译后的class文件调用了valueOf方法
```java
Integer a=123;  
Integer b=123;  
int c=a+b;
//编译之后
int c=a.intValue()+b.intValue();
```
包括两个对象相加能得出int类型的值，是在编译之后调用了intValue进行了拆箱
#### 缓存机制
```java
//常量，自动装箱的int原值
private final int value;
//得到Integer对象
public static Integer valueOf(int i) {  
	//判断是否是缓存池中范围的数字，如果是则直接从缓存池中取出
	//不是则用构造函数new一个
    if (i >= IntegerCache.low && i <= IntegerCache.high)  
        return IntegerCache.cache[i + (-IntegerCache.low)];  
    return new Integer(i);  
}

//静态内部类，所有Integer对象共享，缓存池对
private static class IntegerCache {  
	//规定的缓存池的下限
    static final int low = -128;  
    //缓存池上限
    static final int high;  
    //真实缓存
    static final Integer[] cache;
    //归档缓存  
    static Integer[] archivedCache;  
	//初始化静态代码块
    static {  
        //初始化
        int h = 127;  
        //从JVM参数中读取配置设置high，没有不抛异常
        String integerCacheHighPropValue =  
            VM.getSavedProperty("java.lang.Integer.IntegerCache.high");  
        if (integerCacheHighPropValue != null) {  
            try {  
                h = Math.max(parseInt(integerCacheHighPropValue), 127);  
                // Maximum array size is Integer.MAX_VALUE  
                h = Math.min(h, Integer.MAX_VALUE - (-low) -1);  
            } catch( NumberFormatException nfe) {  
                // If the property cannot be parsed into an int, ignore it.  
            }  
        }  
        high = h;  
        //CDS（Class Data Sharing） 是 JVM 为了加快类加载速度和节省内存的一种共享机制
        //如果启用了 CDS（一般在模块化 JVM 中开启），JVM 会将常见类（如 Integer、String）预缓存到归档文件中，下次启动可复用这些缓存，不必重新初始化
		//从归档文件中恢复 IntegerCache 的缓存。如果归档中存在有效的缓存数据，它会加载这些数据并初始化 IntegerCache.archivedCach
        CDS.initializeFromArchive(IntegerCache.class);
        //当前缓存的大小
        int size = (high - low) + 1;  

		//如果没有缓存数据，或者新的上下限超过了原来的缓存数据，则进行更新
        if (archivedCache == null || size > archivedCache.length) {  
            Integer[] c = new Integer[size];  
            int j = low;  
            for(int i = 0; i < c.length; i++) {  
                c[i] = new Integer(j++);  
            }  
            //重复new一个数组，范围从是新的上下限，然后设置值，把原来的归档缓存替换
            archivedCache = c;  
        }  
        //设置新的真实缓存
        cache = archivedCache;  
        assert IntegerCache.high >= 127;  
    }  
  
    private IntegerCache() {}  
}
```
由此可见可以通过`-XX:AutoBoxCacheMax=<size>` JVM参数设置上限大小
### 2. String
#### 字符串常量池
```java
String a = "hello";
String b = "hello";
System.out.println(a == b); // true
```
- **字符串字面量（双引号）** 会自动放入JVM的方法区的常量池
- 如果池中已有该字符串，JVM 不会重新创建，而是复用地址
- **但是注意**如果不是字面量字符串而是new出来的，会放进堆中，不管有没有相同字符串值的对象
```java
String s1 = "abc";
String s2 = new String("abc");
System.out.println(s1 == s2); // false ❗
```
#### String 是不可变的
```java
//内部存储字符串的数组，因为字符串本身就是一个字符数组，Java9之后改成了byte数组
@Stable  
private final byte[] value;
```
- 安全（多线程下不需要加锁）
- 可缓存（做 hash 缓存）
- 可被作为 Map 的 key
- 注意对String对象或者String字面量进行操作，改变的只是当前这个引用变量的地址，原本的字符串和对象并没有改变，操作后形成的新字符串或对象会放进方法区的常量池里或堆里
```java
String a = "hello";
//因为不知道a这个变量到底是常量池的地址引用。还是堆的地址引用，则一律将新的结果放入堆中，b是堆中string对象的地址引用
String b = a + "world";
//但是"helloworld"是常量池中的，两个虽然值一样，但是地址不一样所以是false
System.out.println(b == "helloworld"); // false ❌
```
#### 拼接优化
```java
String a = "hello" + "world"; // 编译期常量优化
String b = "hello";
String c = b + "world";       // 运行期拼接
```
对于两个字面量字符串拼接，编译后会被优化成一个整串，放进常量池中（如果没有）
对于对象+常量或对象+对象的拼接，编译后优化成`new StringBuilder().append(b).append("world").toString()` 使用api进行拼接形成新的String对象，放入堆中（不管有没有）
#### intern() 方法
```java
String a = new String("abc");
String b = a.intern();
String c = "abc";
System.out.println(b == c); // true ✅
```
把字符串放进常量池（如果还没放的话），返回**池中的引用**

# 多线程
## 一. 基础
### 1. 进程和线程
#### 进程
一个程序运行的实例，将程序的指令和数据加载到内存中，一个进程可以包含多个线程
#### 线程
线程来执行指令，同一进程下的线程共享资源，分别执行任务
#### 上下文切换
当cup在执行A线程任务时切换到B线程会保存A线程运行时的程序和临时数据，并加载B线程的程序和数据
### 2. 并行和并发
#### 并发
同一时间应对多件事情的能力，多个线程轮流使用一个或多个cup的能力
#### 并行
同一时间同时处理多件事情的能力，多个线程同时使用cup的能力
### 3. 创建线程的方式
#### 实现Runable
```java
public class MyRunable implements Runnable {  
    @Override  
    public void run() {  
        System.out.println("Runnable is running");  
    }  
  
    public static void main(String[] args) {  
        MyRunable runnable = new MyRunable();  
        //本质上是Runable任务交给线程去执行  
        Thread thread = new Thread(runnable);  
        thread.start();  
	        //注意：如果在同一个线程对象上调用start()方法多次，会抛出IllegalThreadStateException异常，因为这个线程对象的生命周期已经结束
        thread.start();  
    }  
}
```
实现Runable接口实现run方法，交给一个线程对象去执行这个任务
#### 继承Thread，修改run方法逻辑
```java
public class MyThread extends Thread {  
    @Override  
    public void run() {
	    //super.run(); 执行初始的run逻辑也就是执行runable任务  
        System.out.println("Thread is running");  
    }  
    public MyThread(Runnable task){  
        super(task);  
    }  
    public MyThread() {  
        super();  
    }  
  
    public static void main(String[] args) {  
        MyThread thread = new MyThread();  
        //注意到两次执行任务，一次是重写的run方法，一次是通过构造函数传入的Runnable任务  
        //但是结果都是"Thread is running"，因为run方法被重写了  
        thread.start();  
        new MyThread(new MyRunable()).start();  
    }  
}
```
继承Thread重写run方法，然后就可以启动这个线程对象执行run方法内容，可以注意到两次的执行结果一致，都是重写的run方法，没有执行Runable接口的实现的run方法，因为Tread原本的start的逻辑就是在run方法内执行一个runable任务，通过继承它重写run方法把原本的run逻辑覆盖了，逻辑就成了直接执行重写方法内的内容，所以Runable的run没有执行
**注意**
**可以在重写的run方法里加上==super.run()==，这样就能执行子类和父类的两种run方法逻辑了**
#### 实现Callable接口
```java
public class MyCallable implements Callable<String> {  
    @Override  
    public String call() throws Exception {  
        return "Callable is running";  
    }  
  
    public static void main(String[] args) throws ExecutionException, InterruptedException {  
        MyCallable callable = new MyCallable();  
        //创建一个单线程执行器  
        ExecutorService executorService = Executors.newSingleThreadExecutor();  
        //提交Callable任务到执行器，并获取Future对象  
        Future<String> future = executorService.submit(callable);  
        //获取Callable任务的执行结果  
        System.out.println(future.get());  
        //执行器执行完毕后需要关闭  
        executorService.shutdown();  
    }  
}
```
Callable也是一个线程可执行的任务，但是需要创建线程池处理器去处理，**可以得到任务返回的结果**
#### 多线程执行器
```java
public class MyExecutor implements Runnable{  
    @Override  
    public void run() {  
        System.out.println("Executor is running");  
    }  
  
    public static void main(String[] args) {  
        //创建一个固定大小的线程池执行器  
        ExecutorService executorService = Executors.newFixedThreadPool(3);  
        for (int i = 0; i < 10; i++) {  
            //提交任务到执行器  
            executorService.submit(new MyExecutor());  
        }  
        executorService.shutdown();  
    }  
}
```
创建一个固定大小的线程池处理器，执行任务，注意到**线程池处理器可以执行Runable和Callable两种任务**
#### 注意
Runbale抛出的异常只能在内部处理，不允许继续向上抛，但是Callable可以
**Thread的start方法是开启一个线程，在线程里执行run方法，直接运行它的run方法不会开启线程，就只是一个普通方法**
### 4. 线程状态
#### NEW
新建状态，新创建出来的线程对象，尚未调用start方法启动
#### RUNNABLE
可运行状态，线程已经准备就绪正在抢夺cup的执行权，抢到了就能执行代码，没有抢到可能进入其他状态
#### BLOCKED
阻塞状态，等待获得锁，之后重新进入RUNNABLE状态
#### WAITING
等待状态，被唤醒之后进入进入RUNNABLE状态
#### TIMED_WAITING
计时等待，计时完成进入RUNNABLE状态
#### TERMINATED
执行完成，死亡状态
### 5. 线程顺序执行
```java
public class test1 {  
    public static void main(String[] args) {  
        Thread t1 = new Thread(() -> System.out.println("Thread 1 is running"));  
        Thread t2 = new Thread(() -> {  
            try {  
                t1.join();  
            } catch (InterruptedException e) {  
            }  
            System.out.println("Thread 2 is running after Thread 1");  
        });  
        Thread t3 = new Thread(() -> {  
            try {  
                t2.join();  
            } catch (InterruptedException e) {  
            }  
            System.out.println("Thread 3 is running after Thread 2");  
        });  
        t1.start();  
        t2.start();  
        t3.start();  
    }  
}
```
可以在线程任务中使用**其他线程对象的join()方法**，使当前线程处于阻塞状态，保证当前线程会在其他线程执行之后才执行
### 6. wait和sleep

| 特性    | `wait()`                            | `sleep()`                  |
| ----- | ----------------------------------- | -------------------------- |
| 所属类   | `Object` 类的方法                       | `Thread` 类的静态方法            |
| 使用前提  | 线程必须持有该对象的锁（即在 `synchronized` 代码块内） | 无需任何同步前提                   |
| 是否释放锁 | ✅ 会释放当前对象的**监视器锁（monitor）**         | ❌ 不会释放锁                    |
| 唤醒方式  | `notify()` / `notifyAll()` 或超时      | 自动在指定时间后唤醒                 |
| 常用场景  | 多线程协调（如生产者/消费者）                     | 简单的延迟，如定时器、轮询、节流等          |
| 抛出异常  | 抛出 `InterruptedException`           | 也抛出 `InterruptedException` |
wait方法必须搭配synchronized代码块使用，调用wait方法之后会释放锁，让其他线程去使用，
sleep调用不会释放锁就只是让线程睡觉
`notify()` / `notifyAll()`方法实际上是通知所有正在wait、阻塞在这个锁对象的线程可以抢占锁了，但是其他线程开始抢占的**前提是通知的线程之后进行了wait或执行完了synchronized内的内容，锁才会释放**
### 7. 停止一个正在运行的线程
```java
public class stopThread {  
    public static void main(String[] args) throws InterruptedException {  
        //中断阻塞的线程  
        Thread thread = new Thread(() -> {  
            try {  
                Thread.sleep(10000);  //阻塞
            } catch (InterruptedException e) {  
                System.out.println("线程被中断了");  
                throw new RuntimeException(e);  
            }  
        });  
        thread.start();  
        Thread.sleep(1000);  
        thread.interrupt();//直接中断正在阻塞的线程，同时会抛出异常  
  
        //打断正常的线程，实际上是改变线程的中断状态，来退出线程的代码  
        Thread thread1 = new Thread(() -> {  
            while (true) {  
                boolean interrupted = Thread.currentThread().isInterrupted();  
                if (interrupted) {  
                    System.out.println("状态被中断了");  
                    break;  
                }  
            }  
        });  
        thread1.start();  
        Thread.sleep(1000);  
        thread1.interrupt();  
    }  
}
```
## 二. 线程安全
### 1. synchronized
`synchronized` 的实现依赖 JVM 中的**对象头（Mark Word）和Monitor（监视器锁）**
#### Mark Word
| 位数（64-bit JVM） | 内容说明                     |
| -------------- | ------------------------ |
| 25 bits        | 对象哈希码（hashcode）          |
| 4 bits         | GC 分代年龄                  |
| 1 bit          | 是否是偏向锁标志                 |
| 2 bits         | 锁标志位（轻量锁、偏向锁、重量锁、无锁）     |
| 32/64 bits     | 指向 Monitor 的指针或线程ID（锁竞争） |

|状态|Mark Word 内容|
|---|---|
|无锁|对象Hashcode、GC分代年龄等|
|偏向锁|ThreadID + Epoch时间戳 + 偏向锁标志|
|轻量锁|指向线程栈中 Lock Record 的指针（即 Mark Word 被线程占用）|
|重量锁|指向 Monitor 对象的指针|
|GC标记|专门给 GC 暂用，表示对象是否可回收等信息|
#### 四种锁的状态
|锁状态|线程安全|性能|特点|
|---|---|---|---|
|无锁|否|高|普通对象|
|偏向锁|是|高|适用于线程不竞争|
|轻量锁|是|中|适用于线程间存在少量竞争|
|重量锁|是|低|多线程竞争激烈|#
##### 偏向锁
- 在jdk1.6之后引入
- 首次加锁时线程会将自己的Thread Id写入对象的对象头中
- 之后如果没有其他线程使用这个锁，这个锁就偏向这个线程，即当加锁的线程再次申请加锁时会直接成功省去了检查和加锁的时间
- 当另一个线程尝试获取锁时，偏向锁撤销，会将锁升级为轻量锁
##### 轻量锁
- 用于线程之间交替进行并无真正冲突情况发生
- 线程创建Lock Record（锁记录，拷贝了Mark Word）入自己的栈
- CAS尝试将对象头替换成Lock Record地址，即锁标记为轻量锁
- 如果失败，则进入竞争队列，升级为重量锁
##### 重量锁
- 多线程竞争时升级为重量锁
- 线程处于阻塞状态，会消耗大量资源
#### Montior
**实现了重量锁**
```c
ObjectMonitor {
    Object* object;       // 指向被锁定的对象
    Thread* owner;        // 拥有者线程
    int     recursions;   // 重入次数
    List    EntryList;    // 竞争队列（阻塞线程）
    List    WaitSet;      // 等待队列（wait线程）
}
```
在 `synchronized(obj)` 中，JVM 会执行以下动作：
- CAS尝试将Lock Record的地址和obj的对象头进行交换
- 如果成功，线程持有锁
- 如果失败，进入竞争队列等待持有者释放锁，此时就会升级为重量锁
##### 重入锁
Montior记录了当前持有锁的线程和重入次数，如果持有的线程再次申请获得锁，会增加重入次数
### 2. JMM内存结构
每个线程有自己的工作空间，在自己的工作空间的变量是没有线程安全问题的，空间中还会有引用主线程变量的副本，当一个线程对主线程的变量修改之后会将数据同步到主线程，之后由主线程把数据同步到其他引用了这个主线程变量的线程
### 3. CAS
全称是compare and swap先比较再交换，采用的是**乐观锁的思想**，在无锁状态下保证线程操作的原子性
当一个线程修改了共享变量之后，先会将**修改前的数据和主内存的共享变量比较**，如果一样则把修改后的数据进行同步，如果不一样则进行自旋，即**重新拉取主存里的共享变量然后重新操作修改之后重新比较**这个过程
#### 乐观锁
认为其他线程一般不会修改，所以不加锁，在提交的时候再验证数据有没有被其他线程修改过
#### 悲观锁
始终认为其他线程会来修改变量，所以每次操作之前先加锁，确保当前线程独占资源，其他线程等待或阻塞，直到锁释放
### 4. volatile
#### 线程可见性
```java
import java.util.concurrent.atomic.AtomicInteger;  
  
public class test {  
    static volatile Integer i = 0;  
//    static Integer i = 0;  
  
    public static void main(String[] args) {  
        new Thread(() -> {  
            try {  
                Thread.sleep(100);  
                i = 1;  
            } catch (InterruptedException e) {  
                throw new RuntimeException(e);  
            }  
        }, "t1").start();  
  
        new Thread(() -> {  
            try {  
                Thread.sleep(500);  
                System.out.println("i = " + i);  
            } catch (InterruptedException e) {  
                throw new RuntimeException(e);  
            }  
        }, "t2").start();  
  
        new Thread(() -> {  
            int j = 0;
            //变量的修改对于其他线程是可见的  
            while (i != 1) {  //对于共享变量的判断可以会被JIT直接优化成true或false
                j++;  
            }  
        }, "t3").start();  
    }  
  
}
```
被volatile修饰的变量在线程之间是可见的，包括修改之后的新值也是可见的，它可以禁止JIT对修饰变量的代码优化
#### 禁止指令重排序
使用volatile修饰的变量会在读写时加入不同的屏障，对于写操作，变量之前的写不能向下执行，对于读操作，变量之后的不能向上执行，阻止其他读写操作越过屏障
### 5. AQS
全称是 `AbstractQueuedSynchronizer`，是 JDK 提供的一个**用于构建锁和同步器的框架**，它通过一个**FIFO 的等待队列（CLH 队列变种）+ 一个原子状态字段 state** 来实现线程的阻塞与唤醒
#### 成员变量和方法
```java
//AbstractQueuedSynchronizer的内部类，每一个没有抢到锁的线程都会封装成一个node节点
abstract static class Node {
	//前驱节点
    volatile Node prev;
    //后继节点       
    volatile Node next;      
    //正在等待的节点
    Thread waiter; 
    //节点的状态字段，如不再等待、竞争，后继节点需要被唤醒
    volatile int status;
}
```
```java
//FIFO等待队列，队头节点
private transient volatile Node head;  

//队尾节点
private transient volatile Node tail;  

//状态字段，在不同的子类有不同的含义
private volatile int state;  

//读写state字段的原子操作方法
protected final int getState() {  
    return state;  
}  
  
protected final void setState(int newState) {  
    state = newState;  
}  
//CAS原子修改  
protected final boolean compareAndSetState(int expect, int update) {  
    return U.compareAndSetInt(this, STATE, expect, update);  
}
```
- status字段对于不同的子类有不同的含义
	- 对于 `ReentrantLock`：state 表示加锁的次数（重入次数）
		- 0，锁是空闲的
		- 1，锁被一个线程占用
		- >1，重入次数，一个线程多次获得锁
	- 对于 `Semaphore`：state 表示当前可用的许可证数量
- 当一个线程获取资源失败后，会被构造成一个node节点插入FIFO双向等待队列的尾部
- 当前持有锁的线程释放锁之后会唤醒head的下一个节点，让它去获取资源，获取资源后，这个线程成为新的head
- 对于ReentrantLock（CIL队列加AQS）有两种锁，非公平锁，即队列中的线程和队列外的线程能一起抢占资源，公平锁，只有队列中的线程能抢占锁
```txt
尝试获取锁
  ↓失败
构造Node并入队
  ↓
设置前驱状态为 SIGNAL
  ↓
挂起当前线程（LockSupport.park）
  ↓
被唤醒后重新尝试获取锁

```
#### 两种锁模式及对应的抽象方法
##### 独占模式
```java
protected boolean tryAcquire(int arg) // 独占式获取资源
protected boolean tryRelease(int arg) // 独占式释放资源
```
由一个线程占有锁，其他线程等待或阻塞
##### 共享模式
```java
protected int tryAcquireShared(int arg) // 共享式获取资源
protected boolean tryReleaseShared(int arg) // 共享式释放资源
```
多个线程共享资源
### 6. synchronized和Lock的区别
| 对比维度          | `synchronized`                  | `Lock`（如 `ReentrantLock`）                      |
| ------------- | ------------------------------- | ---------------------------------------------- |
| **基本用途**      | 内置关键字，用于加锁同步代码块或方法              | 显式锁，通过调用 `lock()` 和 `unlock()` 控制              |
| **使用方式**      | 隐式获取与释放锁（JVM 自动管理）              | 需显式获取与释放，代码更灵活但也需更小心                           |
| **类别**        | 悲观锁                             | 悲观锁                                            |
| **可重入性**      | 支持，可重入（同一线程可以多次进入）              | 支持，可重入（`ReentrantLock` 就是可重入锁）                 |
| **可中断性**      | 不支持中断等待锁的线程                     | 支持中断等待（`lockInterruptibly()`）                  |
| **是否公平锁**     | 不支持公平性选择（默认非公平）                 | 可选择公平或非公平（构造函数中指定）                             |
| **是否可定时**     | 不支持超时等待锁                        | 支持超时等待（`tryLock(long timeout)`）                |
| **读写锁支持**     | 不支持读写分离                         | 支持（通过 `ReentrantReadWriteLock`）                |
| **条件变量支持**    | 不支持                             | 支持多个 `Condition` 对象用于线程间通信（比 `wait/notify` 灵活） |
| **性能表现（轻载）**  | 由于是 JVM 内置锁，在低竞争下性能优秀           | 略逊色于 synchronized，需额外维护状态                      |
| **性能表现（高竞争）** | JVM 优化有限（但从 JDK1.6 开始引入偏向锁、轻量锁） | 使用 AQS 高性能队列支持，在高并发场景下表现更佳                     |
| **内存开销**      | 无需显式对象开销，语法级别支持                 | 需要维护锁对象和内部状态，开销略高                              |
| **适用场景**      | 简单同步场景，代码简洁                     | 对并发行为控制要求更高的场景（中断、公平、定时等）                      |
##### lock可打断
```java
public static void main(String[] args) throws InterruptedException {  
    ReentrantLock lock = new ReentrantLock();  
    Thread t1 = new Thread(() -> {  
            try {  
                lock.lockInterruptibly();  
            } catch (InterruptedException e) {  
                System.out.println("等待获取锁的过程中被中断了");  
                throw new RuntimeException(e);  
            }  
            try{  
                System.out.println("获取锁成功，开始执行任务");  
            }finally {  
                lock.unlock();  
            }  
    }, "t1");  
    lock.lock();  
    t1.start();  
    Thread.sleep(1000);  
    t1.interrupt();//直接打断线程  
}
```
`lock.lockInterruptibly()`会阻塞等待获取锁，但是可以被线程的中断而打断

##### lock超时等待
```java
public static void main(String[] args) throws InterruptedException {  
    ReentrantLock lock = new ReentrantLock();  
    Thread t1 = new Thread(() -> {  
        try {  
	        //lock.tryLock()无参方法，只尝试获取一次锁，不会阻塞等待，不会重复尝试
            if (!lock.tryLock(2, TimeUnit.SECONDS)) {// 尝试获取锁，最多等待2秒  
                System.out.println("尝试获取锁失败");  
                return;  
            }  
        } catch (InterruptedException e) {  
            throw new RuntimeException(e);  
        }  
        try {  
            System.out.println("线程1获取锁成功");  
        } finally {  
            lock.unlock();  
            System.out.println("线程1释放锁");  
        }  
    }, "线程1");  
    lock.lock();  
    t1.start();  
    Thread.sleep(3000);//超出等待时间  
}
```
`lock.tryLock()`只尝试获取一次锁，不会阻塞等待
`lock.tryLock(2, TimeUnit.SECONDS)`在指定时间内获取锁，超时之后不会再次尝试获取，不会阻塞

##### lock条件变量
```java
public static void main(String[] args) throws InterruptedException {  
    ReentrantLock lock = new ReentrantLock();  
    Condition c1 = lock.newCondition();  
    Condition c2 = lock.newCondition();  
    Thread t1 = new Thread(() -> {  
        lock.lock();  
        System.out.println("t1获得锁");  
        try {  
            c1.await();//相当于是synchronized的wait方法会释放锁  
            System.out.println("t1被唤醒");  
            lock.unlock();  
        } catch (InterruptedException e) {  
            throw new RuntimeException(e);  
        }  
    });  
    Thread t2 = new Thread(() -> {  
        lock.lock();  
        System.out.println("t2获得锁");  
        try {  
            c2.await();//相当于是synchronized的wait方法会释放锁  
            System.out.println("t2被唤醒");  
            lock.unlock();  
        } catch (InterruptedException e) {  
            throw new RuntimeException(e);  
        }  
    });  
    Thread t3 = new Thread(() -> {  
        lock.lock();  
        c1.signal();  
        c2.signal();  
        lock.unlock();//释放锁  
    });  
    t1.start();  
    t2.start();  
    TimeUnit.SECONDS.sleep(1000); // 确保t1和t2已经开始并等待  
    t3.start();  
}
```
#### lock的读写锁
```java
ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
Lock readLock = lock.readLock();
Lock writeLock = lock.writeLock();

// 获取读锁，可以多个线程拥有
readLock.lock();
readLock.unlock();

// 获取写锁，只能一个线程拥有
writeLock.lock();
writeLock.unlock();
```
当线程占有写锁时其他线程不能占有写锁或读锁，占有读锁时其他线程可以共享读锁
### 7. 死锁
当多个线程持有、抢夺多个锁时有可能抢夺的锁是别的线程正在持有的，造成死锁
```cmd
jps
jstack -l[线程号]
```
在jvm终端运行命令查看线程占有锁的情况
或者使用jdk/bin的jconosl程序查看或visualVM
### 8. ConcurrentHashMap
在jdk1.7之前是数组加链表的结构，在之后是和HashhMap一样的结构
#### 1.7ConcurrentHashMap
```txt
ConcurrentHashMap
      |
      v
+----------------------------+
|        Segment[]          |   （默认长度 16）
+----------------------------+
     |       |       |
     v       v       v
  Segment  Segment  Segment  ...
     |
     v
+------------------------+
|      HashEntry[]      |     （每个 Segment 内部一个桶数组）
+------------------------+
     |      |      |
     v      v      v
  Entry   Entry   Entry   ...
    ↓
  Entry
    ↓
  Entry
（链表结构）
```
- 插入或扩容使用的**只有ReentrantLock**
- Segment的每个元素是一个`HashEntry[]`数组真正存储数据
- 它的每个元素存储桶，Segment数组无法扩容，但是`HashEntry[]`是可以扩容的
- 插入数据或扩容时直接锁住的是一个Segment元素也就是一整个`HashEntry[]`数组，性能低下
#### 1.8ConcurrentHashMap
```txt
ConcurrentHashMap
┌────────────────────────────────────────────────────────────────────────────┐
│                                   table                                    │
│                      (Node<K,V>[]，长度为2的幂次)                           │
├────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┤
│ Node0  │ Node1  │ Node2  │ Node3  │ Node4  │ Node5  │ Node6  │ Node7  │ ...
│  ↓         ↓        ↓        ↓        ↓        ↓        ↓        ↓
│ 链表/树  链表/空  空      链表     树      空      链表     空
│         ↑       ↑                ↑      ↑              ↑
│       (CAS+锁机制，节点扩容/插入时互不阻塞，分段控制)        ...
└────────────────────────────────────────────────────────────────────────────┘
```
```java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;      // key的哈希值
    final K key;
    volatile V val;      // volatile保证可见性
    volatile Node<K,V> next; // 链表结构 or 红黑树 TreeNode
}
```
内部节点的结构和HashMap的node不同，val和next指针是volatile修饰的线程可见
- 插入或扩容过程通过 **CAS + synchronized（锁分段）** 保证线程安全和性能
- 在插入或修改的时候先用CAS进行操作，例如在插入时，如果桶为空，则CAS直接成功
- 如果CAS失败，则把桶的链表的头结点或红黑树的根节点用synchronized锁住再操作
- **在扩容时必定会使用synchronized**，因为会使用**多线程来进行数据迁移**，每个线程分配一段**桶区间**，一个线程在处理区间的时候会用synchronized锁住当前遍历到的桶节点，保证一个桶只能由一个线程来操作
	- 在数据迁移过程在如果一个桶的数据已经迁移完成，则会将这个桶替换成ForwardingNode，它并不存储数据，只是标记这个桶已经完成迁移，其他线程遇到这个ForwardingNode就会直接跳过
- 在**链表转换成红黑树**的时候也会有**synchronized**锁住操作过程

|操作|CAS|synchronized|
|---|---|---|
|get()|❌|❌|
|put() 空桶插入|✅ 尝试CAS|❌|
|put() 非空桶插入|❌|✅ 锁住桶头节点|
|put() 更新已有key|❌|✅ 遍历需要锁，赋值本身无需锁|
|扩容 resize|❌|✅ 分段锁+迁移节点|
|链表转红黑树|❌|✅|
## 三. 线程池
### 1. 线程池的执行原理
```java
public ThreadPoolExecutor(int corePoolSize,  
                          int maximumPoolSize,  
                          long keepAliveTime,  
                          TimeUnit unit,  
                          BlockingQueue<Runnable> workQueue,  
                          RejectedExecutionHandler handler)
```
```java
executor.allowCoreThreadTimeOut(true);//允许销毁核心线程
```
- corePoolSize：核心线程数，不会被销毁，除非调用allowCoreThreadTimeOut方法
- maximumPoolSize：最大线程数，即核心线程数+救急线程数
- keepAliveTime：当没有任务处理时，救急线程的最大存活时间
- unit：存活时间单位
- BlockingQueue：当**没有空闲的核心线程**时，新来的任务会被放入这个阻塞队列，当阻塞队列满时，如果当前线程数没有超过最大线程数，会创建救急线程来处理
- RejectedExecutionHandler：当阻塞队列已满且当前线程数到达最大线程数，会根据拒绝策略处理新来的任务
### 2. 阻塞队列
| 特性              | `LinkedBlockingQueue`                      | `ArrayBlockingQueue`                |
| --------------- | ------------------------------------------ | ----------------------------------- |
| **底层结构**        | 链表（链式节点）                                   | 数组（循环数组）                            |
| **是否有界**        | 默认无界（可设容量）                                 | 必须设定容量（有界）                          |
| **吞吐量**         | 通常较高，适合高并发                                 | 略低，但性能更稳定                           |
| **锁实现**         | **两把锁**，更高并发效率，put时锁住链表尾节点，take时锁住头结点，互不影响 | **一把锁**（put 和 take 互斥）较简单但冲突多，并发效率低 |
| **内存占用**        | 动态增长链表节点，内存占用较高                            | 固定数组大小，内存使用稳定                       |
| **构造时是否必须指定容量** | 否（默认 `Integer.MAX_VALUE`）                  | 是（必须指定）                             |
| **典型使用场景**      | `ExecutorService` 的默认队列                    | 对资源敏感、实时性要求高的系统                     |
| **阻塞行为**        | put 满时阻塞，take 空时阻塞                         | 相同行为                                |
| **并发性能**        | 更优（读写锁分离）                                  | 中等偏上                                |
| **适合场景**        | 任务量不确定、大量生产消费、流式处理                         | 任务量稳定、内存受限的高性能任务队列                  |
SynchronousQueue不存储任务，每个插入操作必须等待一个移出操作完成
DelayedWorkQueue，可以指定任务执行的开始时间
### 3. 确定核心线程数
- 对于IO型任务，如文件读写，db读写，线程数是2n+1，n是cup的核数
- 对于CUP密集型任务，如代码计算，Bitmaap转换等，是n+1
### 4. Executors创建线程池方式
```java
//指定核心线程数，没有救急线程，阻塞队列容量无限
public static ExecutorService newFixedThreadPool(int nThreads) {  
    return new ThreadPoolExecutor(nThreads, nThreads,  
                                  0L, TimeUnit.MILLISECONDS,  
                                  new LinkedBlockingQueue<Runnable>());  
}
//单例线程池，只有一个核心线程处理任务，队列无界
public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {  
    return new AutoShutdownDelegatedExecutorService  
        (new ThreadPoolExecutor(1, 1,  
                                0L, TimeUnit.MILLISECONDS,  
                                new LinkedBlockingQueue<Runnable>(),  
                                threadFactory));  
}
//缓存线程池，全部由救急线程处理任务
public static ExecutorService newCachedThreadPool() {  
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,  
                                  60L, TimeUnit.SECONDS,  
                                  new SynchronousQueue<Runnable>());  
}
//定时处理线程池
public ScheduledThreadPoolExecutor(int corePoolSize) {  
    super(corePoolSize, Integer.MAX_VALUE,  
          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,  
          new DelayedWorkQueue());  
}
```
所以不推荐使用Executors创建线程池，容易出现创建过多线程或存储过多任务的情况，导致OOM
### 5. 使用场景
```java
public static void main(String[] args) throws InterruptedException {  
    CountDownLatch countDownLatch = new CountDownLatch(3);  
    ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) Executors.newFixedThreadPool(3);  
    threadPoolExecutor.execute(new Runnable() {  
        @Override  
        public void run() {  
            System.out.println("哈哈");  
            countDownLatch.countDown();  
        }  
    });  
    threadPoolExecutor.execute(new Runnable() {  
        @Override  
        public void run() {  
            System.out.println("哈哈");  
            countDownLatch.countDown();  
        }  
    });  
    countDownLatch.await();  
}
```
- 利用CountDownLatch等待所有线程任务完成
- 构造函数指定了信号量，每有一个线程调用了countDown方法就相当于减少了一个信号量
- await方法类似于sleep方法，当信号量减少到0则线程被唤醒
- 底层使用AQS来减少信号量
- 例如可以利用线程池把数据库数据迁移到es的过程，划分成多个线程任务，每个任务迁移一页数据，将任务交给线程池去执行，利用 await方法判断是否执行完成
```java
public static void main(String[] args) throws InterruptedException {  
    ExecutorService executorService = Executors.newFixedThreadPool(3);  
    try {  
        CompletableFuture<String> stringCompletableFuture = new CompletableFuture<String>().completeAsync(() -> "l",executorService);  
        System.out.println(stringCompletableFuture.get());  
    } catch (Exception e) {  
        throw new RuntimeException(e);  
    }  
}
```
可以使用异步任务加线程池进行数据整合
### 6. ThreadLocal
- 实现线程对象隔离，让每个现线程使用各自的资源，避免发生线程安全
- 每个线程对象内部有一个ThreadLocalMap类型的成员变量，是真正存储数据的地方
- 当调用set方法时，就是以当前的ThreadLocal为键将值存入进去的
- get方法就是以当前TreadLocal作为键找出对应的值
- remove方法会删除以当前ThreadLocal为键的所有值
```java
static class ThreadLocalMap {  
  static class Entry extends WeakReference<ThreadLocal<?>> {   
        Object value;  
        Entry(ThreadLocal<?> k, Object v) {  
            super(k);  
            value = v;  
        }  
    }
}
```
由于ThreadLocalMap实际是以内部的Entry存储数据的，而它继承了`WeakReference<ThreadLocal<?>>`弱引用接口，导致ThreadLocal是弱引用，而val是强引用，导致ThreadLocal在GC之后key失效，但是val却仍然存在，长时间后就会在Map里累积大量无用数据导致OOM
# JVM
## 一. 组成
```txt
┌──────────────────────────────────── JVM ─────────────────────────────────────┐
│                                                                              │
│  ┌────────────── Method Area ───────────────┐     ┌────── Native Method ─────┐│
│  │   类信息（类名、父类名、方法、字段等） │     │   本地方法接口（JNI） ││
│  │   常量池（运行时常量池）               │     │   调用C/C++方法支持    ││
│  │   静态变量、类加载信息等               │     └──────────────────────┘│
│  └─────────────────────────────────────────┘                                │
│                                                                              │
│  ┌────────────── Heap ───────────────┐                                       │
│  │   所有对象实例和数组分配在堆中    │                                       │
│  │   包括：                          │                                       │
│  │   ┌────────── Young Generation ┐ │                                       │
│  │   │ Eden、Survivor From/To区   │ │                                       │
│  │   └────────────────────────────┘ │                                       │
│  │   ┌────────── Old Generation ───┐ │                                       │
│  │   │  长期存活的对象              │ │                                       │
│  │   └─────────────────────────────┘ │                                       │
│  └───────────────────────────────────┘                                       │
│                                                                              │
│  ┌──────────── JVM Stack ─────────────┐                                      │
│  │ 每个线程一个栈，每个方法调用对应  │                                      │
│  │ 一个栈帧（Stack Frame）            │                                      │
│  │ 包含：局部变量表、操作数栈、      │                                      │
│  │ 方法返回地址、异常处理信息等      │                                      │
│  └────────────────────────────────────┘                                      │
│                                                                              │
│  ┌──────────── Program Counter ─────────────┐                                │
│  │ 每个线程一个PC寄存器                  │                                │
│  │ 指向当前线程所执行方法字节码的地址    │                                │
│  └────────────────────────────────────────┘                                │
│                                                                              │
│  ┌────────────── Stack Native (C Stack) ──────────────┐                      │
│  │ 用于支持native方法执行（如JNI调用）               │                      │
│  └────────────────────────────────────────────────────┘                      │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘

```
### 1. 程序计数器
每个线程一个私有的pc寄存器，内部保存字节码的行号，用于记录即将要执行的下一条字节码指令的地址
### 2. 堆
线程共享的区域，保存所有的对象实例和数组，包括伊甸园区，两个幸存者区，一个老年带
在jdk1.7之前Method Area（永久带，包括类信息，常量信息，静态变量）存储在堆中，1.8之后才移至元空间
### 3. 虚拟机栈
	每个线程运行时所需要的内存，就是jvm栈
- 每个线程在启动时，jvm会为它分配一个JVM栈，栈由一组栈帧组成
```txt
┌───────────────────────────────┐
│    局部变量表 (Local Variables)│
│  - 方法参数                    │
│  - 方法内部定义的变量           │
├───────────────────────────────┤
│    操作数栈 (Operand Stack)    │
│  - 用于临时保存计算过程中的中间值 │
│  - 执行指令如 iadd、imul 等     │
├───────────────────────────────┤
│    动态链接 (Dynamic Linking)  │
│  - 指向运行时常量池中当前方法信息 │
│  - 比如方法引用、字段引用等      │
├───────────────────────────────┤
│    方法返回地址 (Return Address)│
│  - 调用者方法的字节码执行位置    │
└───────────────────────────────┘
```
- 每次调用方法时，都会创建一个新的栈帧压栈
- 在一个栈帧执行完成后弹栈，内存释放
- 局部变量表：存放方法参数和方法内局部变量，引用类型对象也会以地址形式存储在这里
- 操作数栈：保存计算过程中的中间值和操作指令
- 动态链接：每个方法在编译时引用的是**常量池中的符号引用，运行时解析成实际地址**，这个信息被存储在动态链接中
- 方法返回地址：当前方法返回后，**继续执行调用者方法的下一条字节码指令的地址**
- 由此可见每调用一次方法都会创建一个栈帧，所以方法内的局部变量如果没有逃离作用范围就是线程安全的，否则就是不安全的
- 栈帧过多、过大都会导致jvm栈内存溢出
### 4. 方法区
- 各个线程共享的内存区域
- 存储类信息、运行时常量池
- 虚拟机开启时创建，关闭时释放
- 如果方法区的内存无法满足分配请求，如类的加载信息放不下了，就会抛出Metaspace内存溢出
- **常量池**可以看作`.class`文件中的一张表，虚拟机指令根据这张表找到要执行的类名，方法名，字面量等，**这些只是描述信息（名字而已）**，**相当于只是一段类路径/方法路径的字符串，不是其本身**
- **运行时常量池**是当类被加载的时，**常量池的信息就会放入运行时常量池，并把符号引用解析为真实地址**，这个解析过程就是**类装载**的过程，由类加载器 → Class 对象 → 方法区，完成解析，得到真实地址
### 5. 直接内存
是 JVM 外的一块内存区域，**不属于堆、也不属于方法区**，是通过 Java 代码（通常是 `ByteBuffer.allocateDirect`）直接向操作系统申请的内存空间
普通的IO操作，需要先将数据批次读到系统内存，再由系统内存写入java堆的缓冲区，java代码无法直接操作系统内存
而直接内存是java代码申请的、可以直接操作的内存，更省时间
## 二. 类加载器
### 1. 概念
**类加载器** 是 JVM 中用来 **将 `.class` 文件读取进内存，并转换为 Class 对象** 的组件，以便jvm能够识别运行
### 2. 双亲委派机制
| 类加载器名       | JVM名称/实现类                       | 加载内容                           |
| ----------- | ------------------------------- | ------------------------------ |
| **引导类加载器**  | `BootstrapClassLoader`（C/C++实现） | 核心类库：`rt.jar`, `java.lang.*` 等 |
| **扩展类加载器**  | `ExtClassLoader`                | JDK 扩展目录下的类（如 `jre/lib/ext/`）  |
| **应用类加载器**  | `AppClassLoader`                | CLASSPATH 下的类（你写的类）            |
| **自定义类加载器** | 你继承 `ClassLoader` 写的            | 动态加载类，热部署，解耦（常见于框架、插件）         |
双亲委派机制就是当一个加载器尝试加载一个类的时候，不会自己去加载，而是委派自己的父加载器去加载，如果父加载器也有自己的父加载器就继续向上委托，如果父加载器没有加载该类时，子加载器才会自己去加载
#### 作用
- 防止核心代码被用户代码替换，例如用户自定义的一个叫String的类会被jdk自带的覆盖
- 避免重复加载，如果父加载器已经加载过，就不会重复加载
- springboot、tomcat或插件会人为打破机制，优先自定义加载器加载，不成功再让父加载器加载
### 3. 类装载执行流程
```txt
加载（Load） → 验证（Verify） → 准备（Prepare） → 解析（Resolve） → 初始化（Initialize） → 使用（Use） → 卸载（Unload）
```
#### 加载
java类在编译之后生成.class文件，加载阶段就是将文件从文件系统中去读取成二进制的字节流，并构建成jvm能操作的Class对象
- 通过类的全限定名，找到二进制数据流
- 解析数据流，在**方法区中存储类的结构信息**，在堆**中开辟空间存储这个类的Class对象**，对象的内部结构中持有对方法区（元空间）中类结构信息的**直接引用（指针）**，形成映射关系，作为方法区这个类的各种数据、方法的**访问入口**
- 之后要创建这个类的对象，就能通过这个Class对象去方法区中获得类的构造函数、方法、字段等信息来创建对象，创建出来的对象的对象头**包含它所属的类的Class对象的引用**，从而形成链条，jvm就是通过这个引用来支持对象的反射、方法查找、字段访问等操作
#### 验证
- 文件格式验证
- 元数据验证
- 字节码验证
- 符号引用验证，Class文件**在其常量池通过字符串（符号引用）** 记录自己将要用到的其他类或者方法，检查它们是否存在
#### 准备
为类变量分配内存并设置初始值
```java
static int a=10;  //实际上在这个阶段的默认值是0
static final int b=10;  //直接赋值，下面一样
static final String c= "hello";  
static final Object d= new Object();
```
- static直接修饰的变量，在准备阶段设置默认值，比如int类型就是0，要给a赋值10要在初始化阶段才会执行
- static修饰的final变量，会在这个阶段直接赋值，因为是常量，值已经确定
- static修饰的final引用变量，在这个阶段也会完成赋值
#### 解析
将符号引用转化为真实地址
#### 初始化
优先初始化父类的静态代码块（也就是执行静态代码块）和静态变量，然后是子类的静态代码块和静态变量
当用**子类访问父类的静态变量时，就只会初始化父类**
## 三. 垃圾回收
### 1. 对象什么时候可以被回收
当堆中的对象没有任何的引用指向它时，就可能被定为垃圾被回收
如果堆中的对象身上只有弱引用，在GC的时候也会被回收
如果身上有强引用，就不会被回收
如果没有强引用有软引用，在GC过程中如果内存不足会被回收
#### 引用计数法
每当对象被引用一次，计数器就会加1，如果计数器为0，就会把对象标记为垃圾
#### 可达性分析法（默认）
JVM 通过从一组被称为 **GC Roots** 的对象开始向下搜索，只要某个对象**能从 GC Roots 直接或间接访问到**，就被认为是“可达的（live）”，否则就是垃圾，等待回收
GC Root 是 JVM 认为“永远活着”的对象起点

| GC Root 类型                  | 说明                                                      |
| --------------------------- | ------------------------------------------------------- |
| ✅ **虚拟机栈（栈帧中的局部变量表）中的引用对象** | 方法正在执行的所有局部变量、参数（包括基本类型的包装对象、引用对象）                      |
| ✅ **方法区中类静态属性引用的对象**        | 如 `static Object obj = new Object()`，只要类还被加载，这个静态引用就是活的 |
| ✅ **方法区中常量引用的对象**           | 如 `final static String s = "abc"`；"abc" 可能会被常量池引用       |
| ✅ **本地方法栈中 JNI 引用的对象**      | native 方法中使用的对象，不受 JVM 自动管理，因此视为根                       |
| ✅ **正在运行的线程对象本身**           | 活跃线程对象、线程上下文类加载器等                                       |
| ✅ **Class 对象本身**            | 每个类对应一个 `java.lang.Class` 对象，存在堆中，被类加载器引用，活着            |
| ✅ **被同步锁（monitor）持有的对象**    | 如果对象作为锁 monitor，也会被视为根，避免在同步中被回收                        |
### 2. 四种引用
#### 引用
每当new出一个对象，就会在堆内存中开辟一段空间用来存储这个对象，返回一个引用值交给变量，相当于是指针但不是裸指针，变量只是对堆中对象的引用或者“指向”

#### 四种引用

| 引用类型    | 是否参与 GC 判断     | 被 GC 回收时机            | 典型用途                                 | 是否影响 GC Root 可达性分析 |
| ------- | -------------- | -------------------- | ------------------------------------ | ------------------ |
| **强引用** | ✅ 是            | 只有没有强引用时才会回收         | 普通对象引用，如 `Object obj = new Object()` | ✅ 是                |
| **弱引用** | ✅ 是            | 只要发生 GC 就会被回收        | ThreadLocal 的 key、元数据缓存              | ✅ 是                |
| **软引用** | ✅ 是            | 内存不足时回收（GC 前判断内存压力）  | 缓存（如图片缓存）                            | ✅ 是                |
| **虚引用** | ❌ 否（无法通过它获取对象） | 被 GC 后会收到通知，但本身不阻止回收 | 管理直接内存（配合 `ReferenceQueue`）          | ❌ 否（不能影响可达性）       |
### 3. 回收垃圾算法
#### 标记清除算法
- 先进行可达性分析，标记出要回收的对象然后将标记的对象进行回收
- 标记和清除速度比较快
- 碎片化严重，内存不连续，没有办法存储较大的数组
#### 标记整理算法
和标记清除算法基本一样，但是在清除之后把存活的对象进行了移动整理，让空间变得连贯
由于花费实时间移动对象，所以效率有一定影响
老年代使用
#### 复制算法
将内存分成两块大小相同的区域，将标记的存活的对象**复制**到一个区域，将另一个区域全部清除，复制的过程就完成了空间的整理
### 4. GC过程的分代回收
- 新建对象都会先分配到伊甸园区，伊甸园内存不足时，触发GC，标记**伊甸园和幸存者from**内存活的对象，用复制算法把存活的对象复制到幸存者to中，之后伊甸园和from内存全部释放
- 之后如果伊甸园区又满了，就会标记**伊甸园和to**的活对象，然后采用复制算法把对象复制到from中，依次类推，如果from和to中的对象经历了n次（默认15次，jvm参数可以改）这样的回收之后就会迁移到老年代中
- 如果新生代GC完仍然放不下就会GC老年代，尝试放进老年代，如果老年代也放不进去，就进行堆整体的GC，如果整体GC完还是放不进去就OOM了
- young GC：发生在新生代，会暂停所有线程进行GC，暂停时间短
- Mixed GC：发生在新生代和部分老年代
- Full GC：发生在新生代和全部老年代，暂停时间长
### 5. 垃圾回收器
- 串行垃圾收集器：Serial GC、Serial Old GC
- 并行垃圾收集器：Parallel Old GC、ParNew GC
- CMS（并发）垃圾收集器：CMS GC，作用在老年代
- G1：作用在新生代和老年代
### 6. G1垃圾回收器
- 将堆内存分成了多个小的内存区域，每个区域都能成为伊甸园、幸存者、老年代，初始时，所有区域都是空闲的
- 创建一些对象，挑选出一些空闲区域作为伊甸园存储这些对象（占比是5%~6%）
- 当伊甸园需要垃圾回收时，会挑选出一个空闲区域成为幸存者区，然后进行标记，把存活的对象复制到幸存者中，释放伊甸园，这个过程会暂停用户进程
- 当伊甸园的内存又满了之后，挑选出一个**新的幸存者区**，标记伊甸园和原来幸存者的存活的对象，将存活时间较长的对象晋升到老年代，剩余的复制到新的幸存者区中，然后将伊甸园和原来的幸存者释放
- 当老年代占用内存超过45%之后，触发并发标记，用户线程不会暂停
- 并发标记之后，混合收集，优先收集存活对象少的老年代，将这种老年代里存活的对象复制到新的老年代，将伊甸园、幸存者的存活的对象复制到新的幸存者中，并将存活时间较长的对象复制到新的老年代中，然后释放内存，这个过程会暂停用户线程
- 如果并发标记失败，即回收速度赶不上对象创建的速度则会进行fullgc，标记整体的区域进行回收
- 经过多轮混合收集之后，进入新一轮的新生代回收
- 如果一个对象太大，会分配一块或连续的几块huge区存储
## 四. JVM参数
### 1. 调优参数
#### 内存与堆（重点）

| 参数                               | 说明             | 示例                             |
| -------------------------------- | -------------- | ------------------------------ |
| `-Xms<size>`                     | 初始堆大小          | `-Xms512m`                     |
| `-Xmx<size>`                     | 最大堆大小          | `-Xmx2g`                       |
| `-Xmn<size>`                     | 新生代大小          | `-Xmn512m`                     |
| `-XX:MaxDirectMemorySize=<size>` | 最大直接内存大小（NIO用） | `-XX:MaxDirectMemorySize=256m` |
| `-XX:MetaspaceSize=<size>`       | 元空间初始大小（JDK8+） | `-XX:MetaspaceSize=128m`       |
| `-XX:MaxMetaspaceSize=<size>`    | 元空间最大值         | `-XX:MaxMetaspaceSize=512m`    |
#### 垃圾回收器选择参数

|参数|说明|
|---|---|
|`-XX:+UseSerialGC`|单线程收集器，适合小内存|
|`-XX:+UseParallelGC`|吞吐量优先，默认并行收集器|
|`-XX:+UseConcMarkSweepGC`|CMS 收集器（JDK9弃用）|
|`-XX:+UseG1GC`|G1 收集器（推荐 JDK8 之后）|
|`-XX:+UseZGC`|ZGC（低延迟，JDK11+）|
|`-XX:+UseShenandoahGC`|红帽 Shenandoah（低停顿，JDK12+）|
#### 垃圾回收日志相关参数

| 参数                                             | 说明              |
| ---------------------------------------------- | --------------- |
| `-verbose:gc`                                  | 简单输出GC日志        |
| `-XX:+PrintGCDetails`                          | 输出GC详细信息        |
| `-XX:+PrintGCDateStamps`                       | 输出GC时间戳         |
| `-Xloggc:<file>`                               | 将GC日志写入文件（JDK8） |
| `-Xlog:gc*:file=gc.log:time,uptime,level,tags` | JDK9+ 新日志系统     |
#### JVM 性能与诊断参数（重点）

| 参数                                | 说明                              |
| --------------------------------- | ------------------------------- |
| `-XX:+PrintFlagsFinal`            | 打印所有JVM参数及默认值                   |
| `-XX:+HeapDumpOnOutOfMemoryError` | OOM时生成堆转储文件，文件搭配visualVM的装入功能查看 |
| `-XX:HeapDumpPath=<path>`         | 指定 OOM 转储文件路径                   |
| `-XX:+PrintCompilation`           | 打印JIT编译信息                       |
| `-XX:+PrintClassHistogram`        | 打印类直方图（用于诊断内存）                  |
| `-XX:+UseCompressedOops`          | 压缩普通对象指针（默认开启）                  |
| `-XX:+UseCompressedClassPointers` | 压缩类指针（默认开启）                     |
#### JIT 编译相关参数

|参数|说明|
|---|---|
|`-XX:+TieredCompilation`|分层编译（默认启用）|
|`-XX:CompileThreshold=<n>`|控制热点代码触发编译的阈值|
|`-XX:+PrintInlining`|打印内联优化信息|
#### 线程与栈设置

|参数|说明|
|---|---|
|`-Xss<size>`|每个线程的栈大小，默认1M|
#### 系统稳定性保障

| 参数                             | 说明                   |
| ------------------------------ | -------------------- |
| `-XX:+ExitOnOutOfMemoryError`  | OOM时立即退出JVM（而不是尝试恢复） |
| `-XX:+CrashOnOutOfMemoryError` | OOM时生成错误日志           |
### 2. JVM内存泄漏排查
```cmd
# 查 PID
jps -l

# Dump堆文件，文件搭配visualVM的装入功能查看
jmap -dump:format=b,file=heap.hprof <pid>

# 实时内存监控
jstat -gc <pid> 1000 10

# 强制 Full GC
jcmd <pid> GC.run

# 查看类加载情况
jcmd <pid> GC.class_histogram
```
### 3. CPU飙高
```linux
top # 查看cpu的进程占用情况
ps H -eo pid,tid,%cpu | grep [pid]  # 查看指定进程的所有线程，和线程的cpu使用情况，找到占用较高的线程
jstack [pid]  # 跟进指定进程，找到占用高的线程，查看代码问题
```
# 设计模式
## 一. 工厂模式
### 1. 简单工厂
用一个“工厂类”来封装对象的创建过程，客户端只需要告诉工厂“我想要哪种类型”，工厂就会返回对应的实例
```txt
          +----------------+
          |  Factory 工厂类 |
          +----------------+
                   |
                   | 根据条件（传参）选择创建哪个产品
                   ↓
        +----------+-----------+
        |                      |
+---------------+     +---------------+
|  ProductA类    |     |  ProductB类    |
+---------------+     +---------------+
```
```java
package simpleFactory;  
  
public interface Coffee {  
  
    String getName();  
  
    void addMilk();  
  
    void addSugar();  
  
    class goodCoffee implements Coffee {  
  
        private final String name;  
  
        public goodCoffee(String name) {  
            this.name = name;  
        }  
  
        @Override  
        public String getName() {  
            return name;  
        }  
  
        @Override  
        public void addMilk() {  
            System.out.println("Adding milk to " + name);  
        }  
  
        @Override  
        public void addSugar() {  
            System.out.println("Adding sugar to " + name);  
        }  
    }  
    class badCoffee implements Coffee {  
  
        private final String name;  
  
        public badCoffee(String name) {  
            this.name = name;  
        }  
  
        @Override  
        public String getName() {  
            return name;  
        }  
  
        @Override  
        public void addMilk() {  
            System.out.println("Adding milk to " + name);  
        }  
  
        @Override  
        public void addSugar() {  
            System.out.println("Adding sugar to " + name);  
        }  
    }  
}
```
```java
public class simpleCoffeeFactory {  
    public Coffee createCoffee(String type, String name) {  
        if ("good".equalsIgnoreCase(type)) {  
            return new Coffee.goodCoffee(name);  
        } else if ("bad".equalsIgnoreCase(type)) {  
            return new Coffee.badCoffee(name);  
        } else {  
            throw new IllegalArgumentException("Unknown coffee type: " + type);  
        }  
    }  
}
```
```java
public class CoffStore{  
    public Coffee OrderCoffee(String type, String name) {  
        simpleCoffeeFactory factory = new simpleCoffeeFactory();  
        return factory.createCoffee(type, name);  
    }  
}
```
- 客户端无需知道具体类名，只需传入“标识”，**降低耦合**
- 集中管理创建逻辑，**便于维护和修改**
- **便于扩展**（初期版本，适合产品种类较少）
- 一旦子类种类过多，if-else分支会非常臃肿，不利于扩展，违背了 **开闭原则（对扩展开放，对修改关闭）**
### 2. 工厂方法设计模式
工厂方法模式的核心是 **将“创建对象的职责”从“工厂类”中抽象出来交给子类实现**
**每种产品有自己的工厂，每个工厂只负责创建一种产品**
```txt
      +-----------------+
      |  Product 接口   |
      +-----------------+
             ▲
     +-------+--------+
     |                |
+-----------+   +-----------+
| ProductA  |   | ProductB  |
+-----------+   +-----------+

      +---------------------+
      | Factory 接口        |
      +---------------------+
             ▲
     +-------+--------+
     |                |
+------------+  +-------------+
| FactoryA   |  | FactoryB    |
+------------+  +-------------+
```
```java
public interface CoffeeFactory {  
    Coffee createCoffee();  
}
```
```java
public class goodCoffeeFactory implements CoffeeFactory {  
    @Override  
    public Coffee createCoffee() {return new Coffee.goodCoffee("Good Coffee");  
    }  
}

public class badCoffeeFactory implements CoffeeFactory {  
    @Override  
    public simpleFactory.Coffee createCoffee() {  
        return new simpleFactory.Coffee.badCoffee("Bad Coffee");  
    }  
}
```
```java
public class CoffeeStore {  
  
    private final CoffeeFactory coffeeFactory;  
  
    public CoffeeStore(CoffeeFactory coffeeFactory) {  
        this.coffeeFactory = coffeeFactory;  
    }  
  
    public Coffee orderCoffee() {  
        return coffeeFactory.createCoffee();  
    }  
}
```
- 每个产品有自己的工厂，**清晰职责划分**
- 新增产品时只需新增对应工厂类，不改原有逻辑，**符合开闭原则**
- 易于组合其他设计模式（如模板方法、策略）
- 类的数量增加
- 客户端需要知道具体工厂类（可通过配置、反射解耦）
### 3.  抽象工厂模式
**抽象工厂模式（Abstract Factory）** 提供一个接口，**用于创建“一系列相关/依赖的对象”，而不指定它们具体的类**
```txt
        +--------------------------+
        | AbstractFactory 抽象工厂 |
        +--------------------------+
              /           \
   +----------------+   +----------------+
   | MacFactory     |   | WindowsFactory |
   +----------------+   +----------------+
        |                      |
  ----------------      ------------------
  |              |      |                |
Button         Checkbox Button         Checkbox
```
```java
//产品接口
public interface Button {
    void click();
}

public interface Checkbox {
    void check();
}
```
```java
//具体产品
public class MacButton implements Button {
    public void click() {
        System.out.println("Mac按钮点击");
    }
}

public class WindowsButton implements Button {
    public void click() {
        System.out.println("Windows按钮点击");
    }
}

public class MacCheckbox implements Checkbox {
    public void check() {
        System.out.println("Mac复选框勾选");
    }
}

public class WindowsCheckbox implements Checkbox {
    public void check() {
        System.out.println("Windows复选框勾选");
    }
}
```
```java
//抽象工厂接口，定义生产所有“种类”（父类产品接口）的方法
public interface GUIFactory {
    Button createButton();
    Checkbox createCheckbox();
}
```
```java
//产品族工厂
public class MacFactory implements GUIFactory {
    public Button createButton() {
        return new MacButton();
    }
    public Checkbox createCheckbox() {
        return new MacCheckbox();
    }
}

public class WindowsFactory implements GUIFactory {
    public Button createButton() {
        return new WindowsButton();
    }
    public Checkbox createCheckbox() {
        return new WindowsCheckbox();
    }
}
```
## 二. 策略模式
### 1. 策略模式
策略模式：**定义一系列算法（策略），把它们一个个封装起来，并且使它们可以互相替换**
```txt
        +------------------+
        |   Strategy 接口   |
        +------------------+
           ▲         ▲
           |         |
+----------------+  +----------------+
| ConcreteStrategyA | ConcreteStrategyB |
+----------------+  +----------------+

        +------------------+
        |    Context类      |
        +------------------+
        | - strategy:Strategy |
        +------------------+
        | +setStrategy(...) |
        | +executeStrategy()|
        +------------------+
```
```java
//则略规则
public interface PaymentStrategy {
    void pay(double amount);
}
```
```java
//具体策略实现
public class AlipayStrategy implements PaymentStrategy {
    public void pay(double amount) {
        System.out.println("使用支付宝支付：" + amount + "元");
    }
}

public class WeChatStrategy implements PaymentStrategy {
    public void pay(double amount) {
        System.out.println("使用微信支付：" + amount + "元");
    }
}
```
```java
//上下文类，可以切换策略
public class PaymentContext {
    private PaymentStrategy strategy;

    public void setStrategy(PaymentStrategy strategy) {
        this.strategy = strategy;
    }

    public void execute(double amount) {
        if (strategy == null) {
            throw new IllegalStateException("还没设置支付策略");
        }
        strategy.pay(amount);
    }
}
```
```java
public class Client {
    public static void main(String[] args) {
        PaymentContext context = new PaymentContext();

        context.setStrategy(new AlipayStrategy());
        context.execute(100.0);  // 支付宝支付

        context.setStrategy(new WeChatStrategy());
        context.execute(200.0);  // 微信支付
    }
}
```
## 三. 责任链模式
把多个对象用链条串起来，让请求沿着链传递，每个对象都可以选择处理请求或放行

| 角色                      | 职责                           |
| ----------------------- | ---------------------------- |
| `Handler` 抽象处理者         | 定义处理请求的接口，通常包含一个指向下一个处理者的引用。 |
| `ConcreteHandler` 具体处理者 | 实现处理逻辑，判断是否处理请求，或者传递给下一个处理者。 |
| `Client` 请求者            | 创建处理链并提交请求。                  |
```java
// 抽象处理者
abstract class Handler {
    protected Handler next;

    public void setNext(Handler next) {
        this.next = next;
    }

    public abstract void handleRequest(String request);
}

// 具体处理者A
class ConcreteHandlerA extends Handler {
    public void handleRequest(String request) {
        if (request.contains("A")) {
            System.out.println("ConcreteHandlerA 处理了请求: " + request);
        } else if (next != null) {
            next.handleRequest(request);
        }
    }
}

// 具体处理者B
class ConcreteHandlerB extends Handler {
    public void handleRequest(String request) {
        if (request.contains("B")) {
            System.out.println("ConcreteHandlerB 处理了请求: " + request);
        } else if (next != null) {
            next.handleRequest(request);
        }
    }
}

// 客户端
public class Main {
    public static void main(String[] args) {
        Handler h1 = new ConcreteHandlerA();
        Handler h2 = new ConcreteHandlerB();
        h1.setNext(h2);

        h1.handleRequest("包含A的请求");
        h1.handleRequest("包含B的请求");
        h1.handleRequest("未知请求");
    }
}
```
# 实践
## 一. 单点登录
在多个系统中，**用户只需要登录一次**，就可以访问其他所有相互信任的系统，而无需重复登录
### 1. 基于 Cookie 的 SSO（同域名或父子域名）
- 系统之间共享一级域名（如 `a.example.com`、`b.example.com`）
- 登录时设置父域名 Cookie（如 `.example.com`），所有子系统都能带上它
- 依赖浏览器自动传 Cookie 的特性
- 首次登录时保存jsessionId到公共域名下，访问子系统时，通过请求拦截器判断携带的cookie里有没有对应的jsessionId
- 适用于子系统处于同一域名下的情况
```java
//配置jsessionId的作用域和名称
@Bean  
public CookieSerializer cookieSerializer() {  
    DefaultCookieSerializer defaultCookieSerializer = new DefaultCookieSerializer();  
    //放大作用域，让不同域名的存储的cookie可以共享  
    defaultCookieSerializer.setDomainName(CookieConstant.JSESSIONID_DOMAIN);  
    defaultCookieSerializer.setCookieName(CookieConstant.JSESSIONID_NAME);  
    return defaultCookieSerializer;  
}  
  
/**  
 *配置redis存储session的序列化方式  
 */  
@Bean  
public RedisSerializer<Object> springSessionDefaultRedisSerializer() {  
    return new GenericJackson2JsonRedisSerializer();  
}
```
```java
@Override  
public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {  
  
    UserInfoVo userInfoVo = new UserInfoVo(); 
    //会自动通过jsessionId获取对应的session对象 
    HttpSession session = request.getSession();  
    MemberDTO loginUser = (MemberDTO)session.getAttribute(redisConstant.LOGIN_USER);  
    if (loginUser!= null){  
        //如果登录，用户信息就应该包含用户id，后面将根据用户id查询购物车信息  
        userInfoVo.setUserId(loginUser.getId());  
    }  
  
    //从cookie中获取离线的购物车的cookie  
    Cookie[] cookies = request.getCookies();  
    if (cookies != null){  
        for (Cookie cookie : cookies){  
            if (cookie.getName().equals(CartConstant.TEMP_USER_COOKIE_NAME)){  
                userInfoVo.setUserKey(cookie.getValue());  
                userInfoVo.setTempUser(true);  
                break;  
            }  
        }  
    }  
  
    //如果没有相关的离线状态的购物车cookie，就创建一个，  
    // 又因为cookie是随机的而且每台电脑上浏览器保存的都不一样，保证了，每个浏览器上都是自己的离线购物车  
    if(userInfoVo.getUserKey() == null){  
        userInfoVo.setUserKey(UUID.randomUUID().toString());  
    }  
  
    threadLocal.set(userInfoVo);  
  
    return HandlerInterceptor.super.preHandle(request, response, handler);  
}
```
### 2. 基于 Token + 认证中心 的 SSO（跨域支持）
|角色|说明|
|---|---|
|用户系统（Client）|各个需要登录的子系统|
|SSO认证中心|负责登录校验、签发令牌（如JWT或sessionId）|
|Token/Cookie|用户登录成功后的“通行证”|
|存储中心（可选）|存放session、token黑名单等（可选 Redis、JWT自身携带）|
```java
@Configuration  
@EnableWebSecurity  
public class AuthorizationConfig {  
  
    /**  
     * 注册客户端信息  
     * @return RegisteredClientRepository  
     */    @Bean  
    public RegisteredClientRepository registeredClientRepository() {  
        RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString())  
                .clientId("AuthorizationServer")  
                .clientSecret("{noop}123456")  
                .authorizationGrantType(AuthorizationGrantType.AUTHORIZATION_CODE)  
                .redirectUri("http://localhost:8080/login/oauth2/code/AuthorizationServer")  
                .scope("read")  
                .build();  
        return new InMemoryRegisteredClientRepository(registeredClient);  
    }  
  
    /**  
     * 自定义 OAuth2UserService 以处理用户信息  
     * @return OAuth2UserService  
     */    @Bean  
    public OAuth2UserService<OAuth2UserRequest, OAuth2User> customOAuth2UserService() {  
        return userRequest -> (OidcUser) new DefaultOAuth2UserService().loadUser(userRequest);  
    }  
  
    /**  
     * 配置安全过滤链  
     * @param http  HttpSecurity 对象  
     * @param customOAuth2UserService   自定义 OAuth2UserService  
     * @return  过滤器链  
     */  
    @Bean  
    public SecurityFilterChain securityFilterChain(HttpSecurity http, OAuth2UserService<OAuth2UserRequest, OAuth2User> customOAuth2UserService) throws Exception {  
        http.authorizeHttpRequests(auth -> auth.requestMatchers("/public/**").permitAll().anyRequest().authenticated())  
                .oauth2Login(oath -> oath.loginPage("login").userInfoEndpoint(userInfo -> userInfo.userService(customOAuth2UserService)));  
        return http.build();  
    }  
  
    /**  
     * 配置授权服务器设置  
     * @return AuthorizationServerSettings  
     */    @Bean  
    public AuthorizationServerSettings authorizationServerSettings() {  
        return AuthorizationServerSettings.builder()  
                .issuer("http://localhost:9000") // 设置授权服务器的 issuer                .build();  
    }  
  
    /**  
     * 生成 JWKSource，用于 JWT 编码器  
     */  
    @Bean  
    public JWKSource<SecurityContext> jwkSource() throws NoSuchAlgorithmException {  
        KeyPair keyPair = KeyPairGenerator.getInstance("RSA").generateKeyPair();  
        RSAKey key = new RSAKey.Builder((RSAPublicKey) keyPair.getPublic())  
                .privateKey((RSAPrivateKey) keyPair.getPrivate())  
                .build();  
        return (jwkSelector, ctx) -> jwkSelector.select(new JWKSet(key));  
    }  
  
    /**  
     * JWT 编码器 Bean  
     * @param jwkSource JWKSource<SecurityContext> 用于提供 JWK  
     * @return  
     */  
    @Bean  
    public JwtEncoder jwtEncoder(JWKSource<SecurityContext> jwkSource) {  
        return new NimbusJwtEncoder(jwkSource);  
    }  
}
```
## 二. 上传数据安全性